{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoVunR-YfYao"
      },
      "source": [
        "# In case, the file import data from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ6JGzB4fpzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d446ab0-6aea-4bca-b43b-b4289e4e8763"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYoemWhpfrUm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "143ec9f6-8409-495c-e18c-6a76310c5649"
      },
      "source": [
        "%cd drive/MyDrive/Colab\\ Notebooks\n",
        "# !ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OgetZCcfr_a",
        "outputId": "eee3d24b-bc01-4208-9ed9-6877fa0e5192"
      },
      "source": [
        "# Install libraries\n",
        "!pip install mne\n",
        "!pip install pyriemann\n",
        "!pip install MOABB\n",
        "!pip install  scipy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.7/dist-packages (1.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from mne) (2.11.3)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.7/dist-packages (from mne) (1.6.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mne) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from mne) (1.21.6)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mne) (3.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mne) (21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mne) (4.64.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mne) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->mne) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mne) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mne) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyriemann in /usr/local/lib/python3.7/dist-packages (0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyriemann) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pyriemann) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyriemann) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyriemann) (1.21.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyriemann) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pyriemann) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pyriemann) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pyriemann) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyriemann) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: MOABB in /usr/local/lib/python3.7/dist-packages (0.4.6)\n",
            "Requirement already satisfied: scipy<2.0,>=1.5 in /usr/local/lib/python3.7/dist-packages (from MOABB) (1.7.3)\n",
            "Requirement already satisfied: PyYAML<6.0,>=5.0 in /usr/local/lib/python3.7/dist-packages (from MOABB) (5.4.1)\n",
            "Requirement already satisfied: pooch<2.0,>=1.6 in /usr/local/lib/python3.7/dist-packages (from MOABB) (1.6.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from MOABB) (1.21.6)\n",
            "Requirement already satisfied: pyriemann>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from MOABB) (0.3)\n",
            "Requirement already satisfied: pandas<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from MOABB) (1.3.5)\n",
            "Requirement already satisfied: h5py<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from MOABB) (3.1.0)\n",
            "Requirement already satisfied: scikit-learn<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from MOABB) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.15.1 in /usr/local/lib/python3.7/dist-packages (from MOABB) (2.23.0)\n",
            "Requirement already satisfied: mne>=0.19 in /usr/local/lib/python3.7/dist-packages (from MOABB) (1.1.1)\n",
            "Requirement already satisfied: coverage<6.0,>=5.5 in /usr/local/lib/python3.7/dist-packages (from MOABB) (5.5)\n",
            "Requirement already satisfied: seaborn>=0.9 in /usr/local/lib/python3.7/dist-packages (from MOABB) (0.11.2)\n",
            "Requirement already satisfied: matplotlib<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from MOABB) (3.2.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.62 in /usr/local/lib/python3.7/dist-packages (from MOABB) (4.64.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py<4.0,>=3.0->MOABB) (1.5.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0,>=3.0->MOABB) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0,>=3.0->MOABB) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0,>=3.0->MOABB) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0,>=3.0->MOABB) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib<4.0,>=3.0->MOABB) (4.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from mne>=0.19->MOABB) (2.11.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from mne>=0.19->MOABB) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mne>=0.19->MOABB) (21.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0->MOABB) (2022.2.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch<2.0,>=1.6->MOABB) (1.4.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyriemann>=0.2.6->MOABB) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib<4.0,>=3.0->MOABB) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.15.1->MOABB) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.15.1->MOABB) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.15.1->MOABB) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.15.1->MOABB) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<2.0,>=1.0->MOABB) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->mne>=0.19->MOABB) (2.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxUttm0PfwLI"
      },
      "source": [
        "# References\n",
        "- EEGANet: Removal of Ocular Artifact from the EEG Signal Using Generative Adversarial Networks\n",
        "    - https://ieeexplore.ieee.org/document/9627782\n",
        "    - https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/GANs/SRGAN\n",
        "    - https://github.com/eriklindernoren/PyTorch-GAN/tree/master/implementations/srgan\n",
        "- Datasets\n",
        "    - http://moabb.neurotechx.com/docs/generated/moabb.datasets.BNCI2014004.html#moabb.datasets.BNCI2014004\n",
        "- Notes\n",
        "    - "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tciqSn9gPh7"
      },
      "source": [
        "## Import libraries and read files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Raw1IZobgPes"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "import mne\n",
        "from mne import find_events, Epochs, pick_types, read_evokeds\n",
        "from mne.preprocessing import ICA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pywt\n",
        "import scipy\n",
        "from mne.preprocessing import (ICA, create_eog_epochs, create_ecg_epochs,\n",
        "                               corrmap)\n",
        "from sklearn.neighbors import KDTree\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "import re\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import warnings\n",
        "mne.set_log_level(\"CRITICAL\")\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "nvCPCbQXvf1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_event_ids = 20\n",
        "selected_data_len = 2000\n",
        "\n",
        "# 60 events/ 1 run/ 3 sessions/ 1 subject\n",
        "batch_size = 10\n",
        "n_subjs = 20\n",
        "events_per_run = 20\n",
        "runs_per_session = 1\n",
        "sessions_for_train = 2\n",
        "sessions_for_eval = 1\n",
        "events_per_subj_for_train = int(events_per_run * runs_per_session * sessions_for_train)\n",
        "events_per_subj_for_eval = int(events_per_run * runs_per_session * sessions_for_eval)\n",
        "train_split = int(events_per_subj_for_train * 0.8)\n",
        "\n",
        "list_subjs_names = [str(f\"Subject {i+1}\") if i < n_subjs else str(f\"All Subjects\")  for i in range(n_subjs+1)]\n",
        "# list_subjs_names"
      ],
      "metadata": {
        "id": "4HrUJup7S7UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EOG_ref = \"wICA_without_ref\"\n",
        "ECG_ref = None\n",
        "\n",
        "# LOAD EEG DATA\n",
        "train_eeg = np.load(f'Datasets/Shin2017A/npy_files/train_eeg_{EOG_ref}-{ECG_ref}.npy')\n",
        "eval_eeg = np.load(f'Datasets/Shin2017A/npy_files/eval_eeg_{EOG_ref}-{ECG_ref}.npy')\n",
        "# LOAD EVENT\n",
        "train_events = np.load(f'Datasets/Shin2017A/npy_files/train_events.npy')\n",
        "eval_events = np.load(f'Datasets/Shin2017A/npy_files/eval_events.npy')"
      ],
      "metadata": {
        "id": "3dnP29bbINLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Events\n",
        "train_events = train_events.copy()\n",
        "eval_events = eval_events.copy()\n",
        "\n",
        "list_epochs_modeling = [train_eeg,\n",
        "                        eval_eeg]\n",
        "\n",
        "print(train_events[:,-1].shape)\n",
        "print(train_events[:,-1][:10])\n",
        "print(eval_events[:,-1].shape)\n",
        "print(eval_events[:,-1][:10])\n",
        "\n",
        "for e_type in list_epochs_modeling:\n",
        "    # print(e_type.get_data().shape)\n",
        "    print(e_type.shape)\n",
        "    print(np.max(e_type))\n",
        "    print(np.min(e_type))\n",
        "    print('-'*100)\n",
        "\n",
        "# print(np.all(train_cont_eeg == train_denoised_eeg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9azDhS2W1RHO",
        "outputId": "2d6b6017-1027-4fb7-9785-735fd275dacb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800,)\n",
            "[1 2 1 2 1 2 1 2 2 1]\n",
            "(400,)\n",
            "[1 2 2 1 2 1 1 2 1 2]\n",
            "(800, 30, 2000)\n",
            "0.9129697680473328\n",
            "-0.8596015572547913\n",
            "----------------------------------------------------------------------------------------------------\n",
            "(400, 30, 2000)\n",
            "0.9012501835823059\n",
            "-0.6993433237075806\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification\n",
        "- 01 = CSP + SVM\n",
        "- 02 = CSP + LDA\n",
        "- 03 = EEGNet\n",
        "    - Note of EEGNET's problems\n",
        "        - FC Layer\n",
        "            x = x.reshape(-1, 4*2*7)\n",
        "        - Label must start with 0\n",
        "    - Data format:\n",
        "        Datatype - float32 (both X and Y) <br>\n",
        "        X.shape - (#samples, 1, #timepoints,  #channels) <br>\n",
        "        Y.shape - (#samples)"
      ],
      "metadata": {
        "id": "tuX126rF0xHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "YMHpJ9AJIkvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_for_EEGNET(input_epochs):\n",
        "    # X.shape - (#epochs, 1, #timepoints, #channels)\n",
        "    output_epochs = []\n",
        "    for e_epoch in input_epochs:\n",
        "        e_epoch = e_epoch.transpose()\n",
        "        e_epoch = np.expand_dims(e_epoch,axis=0)\n",
        "        # print(e_epoch.shape)\n",
        "        output_epochs.append(e_epoch)\n",
        "        # break\n",
        "    return np.array(output_epochs).astype('float32')"
      ],
      "metadata": {
        "id": "_ydzwhmf20TY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EEGNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        # Modify self.T, self.fc1 \n",
        "        super(EEGNet, self).__init__()\n",
        "        self.T = 2000 # #samples per task\n",
        "        \n",
        "        # Layer 1\n",
        "        self.conv1 = nn.Conv2d(1, 16, (1, 30), padding = 0)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(16, False)\n",
        "        \n",
        "        # Layer 2\n",
        "        self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n",
        "        self.conv2 = nn.Conv2d(1, 4, (2, 32))\n",
        "        self.batchnorm2 = nn.BatchNorm2d(4, False)\n",
        "        self.pooling2 = nn.MaxPool2d(2, 4)\n",
        "        \n",
        "        # Layer 3\n",
        "        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n",
        "        self.conv3 = nn.Conv2d(4, 4, (8, 4))\n",
        "        self.batchnorm3 = nn.BatchNorm2d(4, False)\n",
        "        self.pooling3 = nn.MaxPool2d((2, 4))\n",
        "        \n",
        "        # FC Layer\n",
        "        # NOTE: This dimension will depend on the number of timestamps per sample in your data.\n",
        "        # I have 120 timepoints. \n",
        "        self.fc1 = nn.Linear(4*2*125, 1)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        # Layer 1\n",
        "        x = F.elu(self.conv1(x))\n",
        "        x = self.batchnorm1(x)\n",
        "        x = F.dropout(x, 0.25)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        \n",
        "        # Layer 2\n",
        "        x = self.padding1(x)\n",
        "        x = F.elu(self.conv2(x))\n",
        "        x = self.batchnorm2(x)\n",
        "        x = F.dropout(x, 0.25)\n",
        "        x = self.pooling2(x)\n",
        "        \n",
        "        # Layer 3\n",
        "        x = self.padding2(x)\n",
        "        x = F.elu(self.conv3(x))\n",
        "        x = self.batchnorm3(x)\n",
        "        x = F.dropout(x, 0.25)\n",
        "        x = self.pooling3(x)\n",
        "        \n",
        "        # FC Layer\n",
        "        x = x.reshape(-1, 4*2*125)\n",
        "        x = torch.sigmoid(self.fc1(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "net = EEGNet().cuda(0)\n",
        "print(net.forward(Variable(torch.Tensor(np.random.rand(1, 1, 2000, 30)).cuda(0))))\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(net.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df-fHsWHIksX",
        "outputId": "0b440839-4b46-4eaa-b241-c4e0461a2dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3603]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X, Y, params = [\"acc\"]):\n",
        "    results = []\n",
        "    batch_size = 100\n",
        "    \n",
        "    predicted = []\n",
        "    \n",
        "    for i in range(int(len(X)/batch_size)):\n",
        "        s = i*batch_size\n",
        "        e = i*batch_size+batch_size\n",
        "        \n",
        "        inputs = Variable(torch.from_numpy(X[s:e]).cuda(0))\n",
        "        pred = model(inputs)\n",
        "        \n",
        "        predicted.append(pred.data.cpu().numpy())\n",
        "        \n",
        "        \n",
        "    inputs = Variable(torch.from_numpy(X).cuda(0))\n",
        "    predicted = model(inputs)\n",
        "    \n",
        "    predicted = predicted.data.cpu().numpy()\n",
        "    \n",
        "    for param in params:\n",
        "        if param == 'acc':\n",
        "            results.append(accuracy_score(Y, np.round(predicted)))\n",
        "        if param == \"auc\":\n",
        "            results.append(roc_auc_score(Y, predicted))\n",
        "        if param == \"recall\":\n",
        "            results.append(recall_score(Y, np.round(predicted)))\n",
        "        if param == \"precision\":\n",
        "            results.append(precision_score(Y, np.round(predicted)))\n",
        "        if param == \"fmeasure\":\n",
        "            precision = precision_score(Y, np.round(predicted))\n",
        "            recall = recall_score(Y, np.round(predicted))\n",
        "            results.append(2*precision*recall/ (precision+recall))\n",
        "    return results"
      ],
      "metadata": {
        "id": "BtfKU_3xN9OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run"
      ],
      "metadata": {
        "id": "DrlCt2eUQ-Z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx_e_subj in range(3):\n",
        "    train_split = int(events_per_subj_for_train * 0.8)\n",
        "    # Assign data and label for Training, Validation, Evaluation\n",
        "\n",
        "    start_idx_train = int(idx_e_subj * events_per_subj_for_train)\n",
        "    end_idx_train = start_idx_train + int(events_per_subj_for_train * 0.8)\n",
        "    start_idx_val = end_idx_train\n",
        "    end_idx_val = int((idx_e_subj+1) * events_per_subj_for_train)\n",
        "    start_idx_eval = int((idx_e_subj)*events_per_subj_for_eval)\n",
        "    end_idx_eval  = int((idx_e_subj+1)*events_per_subj_for_eval)\n",
        "\n",
        "    print(f\"start_idx_train: {start_idx_train}\")\n",
        "    print(f\"end_idx_train: {end_idx_train}\")\n",
        "    print(f\"start_idx_val: {start_idx_val}\")\n",
        "    print(f\"end_idx_val: {end_idx_val}\")\n",
        "    print(f\"start_idx_eval: {start_idx_eval}\")\n",
        "    print(f\"end_idx_eval: {end_idx_eval}\")\n",
        "    print('='*100)\n",
        "\n",
        "    # break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gvt5M-MiYjFD",
        "outputId": "c19a846f-4541-4e0a-cf63-d22f41292b05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start_idx_train: 0\n",
            "end_idx_train: 32\n",
            "start_idx_val: 32\n",
            "end_idx_val: 40\n",
            "start_idx_eval: 0\n",
            "end_idx_eval: 20\n",
            "====================================================================================================\n",
            "start_idx_train: 40\n",
            "end_idx_train: 72\n",
            "start_idx_val: 72\n",
            "end_idx_val: 80\n",
            "start_idx_eval: 20\n",
            "end_idx_eval: 40\n",
            "====================================================================================================\n",
            "start_idx_train: 80\n",
            "end_idx_train: 112\n",
            "start_idx_val: 112\n",
            "end_idx_val: 120\n",
            "start_idx_eval: 40\n",
            "end_idx_eval: 60\n",
            "====================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_test_subjs = []\n",
        "\n",
        "for idx_e_subj, e_subj in enumerate(list_subjs_names):\n",
        "    print(e_subj)\n",
        "\n",
        "    if e_subj != 'All Subjects':\n",
        "        # Assign data and label for Training, Validation, Evaluation\n",
        "        start_idx_train = int(idx_e_subj * events_per_subj_for_train)\n",
        "        end_idx_train = start_idx_train + int(events_per_subj_for_train * 0.8)\n",
        "        start_idx_val = end_idx_train\n",
        "        end_idx_val = int((idx_e_subj+1) * events_per_subj_for_train)\n",
        "        start_idx_eval = int((idx_e_subj)*events_per_subj_for_eval)\n",
        "        end_idx_eval  = int((idx_e_subj+1)*events_per_subj_for_eval)\n",
        "                        \n",
        "        X_train = train_eeg[start_idx_train:end_idx_train,:,:]\n",
        "        y_train = train_events[start_idx_train:end_idx_train,-1]\n",
        "        X_val = train_eeg[start_idx_val:end_idx_val,:,:]\n",
        "        y_val = train_events[start_idx_val:end_idx_val,-1]\n",
        "        X_test = eval_eeg[start_idx_eval:end_idx_eval,:,:]\n",
        "        y_test = eval_events[start_idx_eval:end_idx_eval,-1]\n",
        "\n",
        "    elif e_subj == 'All Subjects':\n",
        "        # Assign data and label for Training, Validation, Evaluation\n",
        "        start_idx_train = int(0)\n",
        "        end_idx_train = start_idx_train + int(events_per_subj_for_train * 0.8 * n_subjs)\n",
        "        start_idx_val = end_idx_train\n",
        "        end_idx_val = int(events_per_subj_for_train * n_subjs)\n",
        "        start_idx_eval = int(0)\n",
        "        end_idx_eval  = int(events_per_subj_for_eval * n_subjs)\n",
        "\n",
        "        X_train = train_eeg[start_idx_train:end_idx_train,:,:]\n",
        "        y_train = train_events[start_idx_train:end_idx_train,-1]\n",
        "        X_val = train_eeg[start_idx_val:end_idx_val,:,:]\n",
        "        y_val = train_events[start_idx_val:end_idx_val,-1]\n",
        "        X_test = eval_eeg\n",
        "        y_test = eval_events[:,-1]\n",
        "\n",
        "    # Modify the input data and its label\n",
        "    X_train = data_for_EEGNET(X_train)\n",
        "    X_val = data_for_EEGNET(X_val)\n",
        "    X_test = data_for_EEGNET(X_test)\n",
        "\n",
        "    y_train = y_train - 1 # Start with 0\n",
        "    y_val = y_val - 1 # Start with 0\n",
        "    y_test = y_test - 1 # Start with 0\n",
        "\n",
        "    print(f\"start_idx_train: {start_idx_train}\")\n",
        "    print(f\"end_idx_train: {end_idx_train}\")\n",
        "    print(f\"start_idx_val: {start_idx_val}\")\n",
        "    print(f\"end_idx_val: {end_idx_val}\")\n",
        "    print(f\"start_idx_eval: {start_idx_eval}\")\n",
        "    print(f\"end_idx_eval: {end_idx_eval}\")\n",
        "\n",
        "    print(y_train[:10])\n",
        "    print(y_val[:10])\n",
        "    print(y_test[:10])\n",
        "\n",
        "    print('-'*100)\n",
        "    \n",
        "    # Assign a model and its hyperparameters\n",
        "    # del net\n",
        "    net = EEGNet().cuda(0)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(net.parameters())\n",
        "\n",
        "    list_training_loss = []\n",
        "    list_train_performance = []\n",
        "    list_valid_performance = []\n",
        "    list_test_performance = []\n",
        "\n",
        "    for epoch in range(100):  # loop over the dataset multiple times\n",
        "        print(\"\\nEpoch \", epoch)\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        for i in range(int((len(X_train)/batch_size-1))):\n",
        "            s = i*batch_size\n",
        "            e = i*batch_size+batch_size\n",
        "            \n",
        "            inputs = torch.from_numpy(X_train[s:e])\n",
        "            labels = torch.FloatTensor(np.array([y_train[s:e]]).T*1.0)\n",
        "            \n",
        "            # wrap them in Variable\n",
        "            inputs, labels = Variable(inputs.cuda(0)), Variable(labels.cuda(0))\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            \n",
        "            \n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            \n",
        "        # Validation accuracy\n",
        "        net.eval()\n",
        "        params = [\"acc\", \"auc\", \"fmeasure\"]\n",
        "        print(params)\n",
        "\n",
        "        e_train_performance = evaluate(net, X_train, y_train, params)\n",
        "        e_valid_performance = evaluate(net, X_val, y_val, params)\n",
        "        e_test_performance = evaluate(net, X_test, y_test, params)\n",
        "\n",
        "        print(\"Training Loss \", running_loss)\n",
        "        print(\"Train - \", e_train_performance)\n",
        "        print(\"Validation - \", e_valid_performance)\n",
        "        print(\"Test - \", e_test_performance)\n",
        "\n",
        "        list_training_loss.append(running_loss)\n",
        "        list_train_performance.append(e_train_performance)\n",
        "        list_valid_performance.append(e_valid_performance)\n",
        "        list_test_performance.append(e_test_performance)\n",
        "\n",
        "    list_training_loss = np.array(list_training_loss)\n",
        "    list_train_performance = np.array(list_train_performance)\n",
        "    list_valid_performance = np.array(list_valid_performance)\n",
        "    list_test_performance = np.array(list_test_performance)\n",
        "\n",
        "    best_acc = np.argmax(list_test_performance[:,0])\n",
        "    print(f\"Epoch with best accuracy is {best_acc}\")\n",
        "    best_test_performance = list_test_performance[best_acc,:]\n",
        "    best_test_subjs.append(best_test_performance)\n",
        "    print('='*50 + 'END OF SUBJECT {idx_e_subj+1}' + '='*50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1Yws5J8NF6g",
        "outputId": "269d1232-4701-4d54-a88f-ac8ebc51e76c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "Epoch  99\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0103688626550138\n",
            "Train -  [0.78125, 0.89453125, 0.7741935483870969]\n",
            "Validation -  [0.875, 0.9375, 0.888888888888889]\n",
            "Test -  [0.5, 0.53, 0.5833333333333334]\n",
            "Epoch with best accuracy is 4\n",
            "==================================================END OF SUBJECT {idx_e_subj+1}==================================================\n",
            "Subject 15\n",
            "start_idx_train: 560\n",
            "end_idx_train: 592\n",
            "start_idx_val: 592\n",
            "end_idx_val: 600\n",
            "start_idx_eval: 280\n",
            "end_idx_eval: 300\n",
            "[0 1 0 1 0 1 1 0 1 0]\n",
            "[1 0 0 1 0 1 0 1]\n",
            "[1 0 0 1 1 0 1 0 0 1]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Epoch  0\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.5689383745193481\n",
            "Train -  [0.5, 0.4609375, nan]\n",
            "Validation -  [0.375, 0.5, nan]\n",
            "Test -  [0.45, 0.48, nan]\n",
            "\n",
            "Epoch  1\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.3625558614730835\n",
            "Train -  [0.53125, 0.53125, 0.11764705882352941]\n",
            "Validation -  [0.5, 1.0, nan]\n",
            "Test -  [0.55, 0.66, 0.18181818181818182]\n",
            "\n",
            "Epoch  2\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.1611007452011108\n",
            "Train -  [0.5, 0.37109375, nan]\n",
            "Validation -  [0.5, 0.5, nan]\n",
            "Test -  [0.5, 0.51, nan]\n",
            "\n",
            "Epoch  3\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.3799399137496948\n",
            "Train -  [0.5, 0.58203125, nan]\n",
            "Validation -  [0.625, 0.75, 0.4]\n",
            "Test -  [0.5, 0.5299999999999999, nan]\n",
            "\n",
            "Epoch  4\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.0282891988754272\n",
            "Train -  [0.53125, 0.5703125, 0.4444444444444444]\n",
            "Validation -  [0.5, 0.5, 0.5]\n",
            "Test -  [0.5, 0.61, 0.4444444444444445]\n",
            "\n",
            "Epoch  5\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.9669517874717712\n",
            "Train -  [0.5, 0.5234375, 0.5555555555555556]\n",
            "Validation -  [0.5, 0.5, 0.6666666666666666]\n",
            "Test -  [0.3, 0.27, 0.22222222222222224]\n",
            "\n",
            "Epoch  6\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.8040494322776794\n",
            "Train -  [0.6875, 0.671875, 0.6428571428571429]\n",
            "Validation -  [0.625, 0.75, 0.7272727272727273]\n",
            "Test -  [0.55, 0.4, 0.608695652173913]\n",
            "\n",
            "Epoch  7\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.5977783501148224\n",
            "Train -  [0.46875, 0.52734375, 0.3703703703703703]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.35, 0.38000000000000006, 0.23529411764705882]\n",
            "\n",
            "Epoch  8\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.5202294290065765\n",
            "Train -  [0.5625, 0.5390625, 0.4166666666666667]\n",
            "Validation -  [0.625, 0.75, 0.5714285714285715]\n",
            "Test -  [0.45, 0.47, 0.26666666666666666]\n",
            "\n",
            "Epoch  9\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.59618079662323\n",
            "Train -  [0.5, 0.53125, 0.2727272727272727]\n",
            "Validation -  [0.5, 0.25, 0.3333333333333333]\n",
            "Test -  [0.6, 0.4600000000000001, 0.4285714285714285]\n",
            "\n",
            "Epoch  10\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.4702075272798538\n",
            "Train -  [0.5625, 0.6484375, 0.4615384615384615]\n",
            "Validation -  [0.5, 0.5625, 0.5]\n",
            "Test -  [0.7, 0.65, 0.6666666666666665]\n",
            "\n",
            "Epoch  11\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.4162904918193817\n",
            "Train -  [0.6875, 0.69921875, 0.7058823529411765]\n",
            "Validation -  [0.625, 0.6875, 0.6666666666666665]\n",
            "Test -  [0.45, 0.39999999999999997, 0.47619047619047616]\n",
            "\n",
            "Epoch  12\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.3984871357679367\n",
            "Train -  [0.6875, 0.83203125, 0.75]\n",
            "Validation -  [0.625, 0.5, 0.6666666666666665]\n",
            "Test -  [0.55, 0.5, 0.64]\n",
            "\n",
            "Epoch  13\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.3629506826400757\n",
            "Train -  [0.6875, 0.80859375, 0.7368421052631579]\n",
            "Validation -  [0.5, 0.75, 0.6666666666666666]\n",
            "Test -  [0.5, 0.53, 0.6153846153846154]\n",
            "\n",
            "Epoch  14\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.30734701454639435\n",
            "Train -  [0.5625, 0.69140625, 0.631578947368421]\n",
            "Validation -  [0.625, 0.6875, 0.6666666666666665]\n",
            "Test -  [0.45, 0.5, 0.56]\n",
            "\n",
            "Epoch  15\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.26126469671726227\n",
            "Train -  [0.71875, 0.8046875, 0.7567567567567567]\n",
            "Validation -  [0.625, 0.6875, 0.6666666666666665]\n",
            "Test -  [0.4, 0.32, 0.5]\n",
            "\n",
            "Epoch  16\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.262187696993351\n",
            "Train -  [0.8125, 0.8125, 0.823529411764706]\n",
            "Validation -  [0.5, 0.5, 0.5]\n",
            "Test -  [0.45, 0.45999999999999996, 0.47619047619047616]\n",
            "\n",
            "Epoch  17\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.21337124705314636\n",
            "Train -  [0.71875, 0.80859375, 0.7272727272727272]\n",
            "Validation -  [0.5, 0.75, 0.6]\n",
            "Test -  [0.55, 0.59, 0.5714285714285713]\n",
            "\n",
            "Epoch  18\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.1956685483455658\n",
            "Train -  [0.78125, 0.84765625, 0.7999999999999999]\n",
            "Validation -  [0.625, 0.625, 0.6666666666666665]\n",
            "Test -  [0.55, 0.44000000000000006, 0.608695652173913]\n",
            "\n",
            "Epoch  19\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.19492103159427643\n",
            "Train -  [0.71875, 0.81640625, 0.742857142857143]\n",
            "Validation -  [0.5, 0.8125, 0.6]\n",
            "Test -  [0.45, 0.45, 0.47619047619047616]\n",
            "\n",
            "Epoch  20\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.16760805994272232\n",
            "Train -  [0.6875, 0.75390625, 0.7058823529411765]\n",
            "Validation -  [0.625, 0.625, 0.6666666666666665]\n",
            "Test -  [0.5, 0.53, 0.5833333333333334]\n",
            "\n",
            "Epoch  21\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.11955729871988297\n",
            "Train -  [0.78125, 0.71484375, 0.7741935483870969]\n",
            "Validation -  [0.625, 0.75, 0.6666666666666665]\n",
            "Test -  [0.5, 0.48, 0.5833333333333334]\n",
            "\n",
            "Epoch  22\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.1311771310865879\n",
            "Train -  [0.78125, 0.82421875, 0.7999999999999999]\n",
            "Validation -  [0.625, 0.75, 0.6666666666666665]\n",
            "Test -  [0.45, 0.43999999999999995, 0.5217391304347826]\n",
            "\n",
            "Epoch  23\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.1425926834344864\n",
            "Train -  [0.75, 0.828125, 0.75]\n",
            "Validation -  [0.5, 0.6875, 0.6]\n",
            "Test -  [0.5, 0.46, 0.5833333333333334]\n",
            "\n",
            "Epoch  24\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.11601140350103378\n",
            "Train -  [0.78125, 0.8515625, 0.787878787878788]\n",
            "Validation -  [0.625, 0.5625, 0.6666666666666665]\n",
            "Test -  [0.5, 0.5, 0.5454545454545454]\n",
            "\n",
            "Epoch  25\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0838298574090004\n",
            "Train -  [0.8125, 0.8984375, 0.7999999999999999]\n",
            "Validation -  [0.625, 0.6875, 0.6666666666666665]\n",
            "Test -  [0.5, 0.41000000000000003, 0.5]\n",
            "\n",
            "Epoch  26\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.10090479999780655\n",
            "Train -  [0.78125, 0.84765625, 0.7741935483870969]\n",
            "Validation -  [0.625, 0.75, 0.6666666666666665]\n",
            "Test -  [0.55, 0.43000000000000005, 0.5714285714285713]\n",
            "\n",
            "Epoch  27\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.09138523787260056\n",
            "Train -  [0.78125, 0.86328125, 0.7741935483870969]\n",
            "Validation -  [0.625, 0.75, 0.6666666666666665]\n",
            "Test -  [0.5, 0.47, 0.5]\n",
            "\n",
            "Epoch  28\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.09715550765395164\n",
            "Train -  [0.8125, 0.84765625, 0.8125]\n",
            "Validation -  [0.625, 0.6875, 0.5714285714285715]\n",
            "Test -  [0.4, 0.44, 0.4000000000000001]\n",
            "\n",
            "Epoch  29\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.07408545911312103\n",
            "Train -  [0.75, 0.875, 0.7333333333333334]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.45, 0.49, 0.4210526315789474]\n",
            "\n",
            "Epoch  30\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.07849112153053284\n",
            "Train -  [0.71875, 0.8671875, 0.6896551724137931]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.55, 0.4600000000000001, 0.5714285714285713]\n",
            "\n",
            "Epoch  31\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.07327260449528694\n",
            "Train -  [0.75, 0.875, 0.7142857142857143]\n",
            "Validation -  [0.5, 0.6875, 0.6]\n",
            "Test -  [0.45, 0.45, 0.4210526315789474]\n",
            "\n",
            "Epoch  32\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.06590468995273113\n",
            "Train -  [0.75, 0.85546875, 0.75]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.45, 0.48000000000000004, 0.4210526315789474]\n",
            "\n",
            "Epoch  33\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.06439959816634655\n",
            "Train -  [0.75, 0.875, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.75, 0.6666666666666665]\n",
            "Test -  [0.5, 0.49000000000000005, 0.5454545454545454]\n",
            "\n",
            "Epoch  34\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.054373973980546\n",
            "Train -  [0.71875, 0.8984375, 0.6896551724137931]\n",
            "Validation -  [0.625, 0.75, 0.6666666666666665]\n",
            "Test -  [0.45, 0.51, 0.4210526315789474]\n",
            "\n",
            "Epoch  35\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.038327524438500404\n",
            "Train -  [0.8125, 0.890625, 0.7999999999999999]\n",
            "Validation -  [0.625, 0.75, 0.6666666666666665]\n",
            "Test -  [0.45, 0.54, 0.4210526315789474]\n",
            "\n",
            "Epoch  36\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.05506221018731594\n",
            "Train -  [0.78125, 0.8515625, 0.7741935483870969]\n",
            "Validation -  [0.75, 0.625, 0.75]\n",
            "Test -  [0.45, 0.48000000000000004, 0.4210526315789474]\n",
            "\n",
            "Epoch  37\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.046804554760456085\n",
            "Train -  [0.75, 0.875, 0.7333333333333334]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.55, 0.5700000000000001, 0.5714285714285713]\n",
            "\n",
            "Epoch  38\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0533025786280632\n",
            "Train -  [0.75, 0.87890625, 0.75]\n",
            "Validation -  [0.625, 0.75, 0.6666666666666665]\n",
            "Test -  [0.4, 0.47000000000000003, 0.33333333333333326]\n",
            "\n",
            "Epoch  39\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.04576494358479977\n",
            "Train -  [0.75, 0.88671875, 0.7142857142857143]\n",
            "Validation -  [0.875, 0.75, 0.8571428571428571]\n",
            "Test -  [0.45, 0.5, 0.47619047619047616]\n",
            "\n",
            "Epoch  40\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.045716630294919014\n",
            "Train -  [0.71875, 0.875, 0.6896551724137931]\n",
            "Validation -  [0.75, 0.625, 0.75]\n",
            "Test -  [0.45, 0.5, 0.4210526315789474]\n",
            "\n",
            "Epoch  41\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.049480851739645004\n",
            "Train -  [0.8125, 0.890625, 0.7999999999999999]\n",
            "Validation -  [0.625, 0.75, 0.6666666666666665]\n",
            "Test -  [0.45, 0.53, 0.4210526315789474]\n",
            "\n",
            "Epoch  42\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.042570799589157104\n",
            "Train -  [0.75, 0.84375, 0.7333333333333334]\n",
            "Validation -  [0.75, 0.6875, 0.75]\n",
            "Test -  [0.45, 0.59, 0.4210526315789474]\n",
            "\n",
            "Epoch  43\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.04501005448400974\n",
            "Train -  [0.78125, 0.8515625, 0.7586206896551724]\n",
            "Validation -  [0.875, 0.75, 0.8571428571428571]\n",
            "Test -  [0.45, 0.48, 0.3529411764705882]\n",
            "\n",
            "Epoch  44\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.04568016901612282\n",
            "Train -  [0.8125, 0.859375, 0.7999999999999999]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.45, 0.5700000000000001, 0.3529411764705882]\n",
            "\n",
            "Epoch  45\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.04308409430086613\n",
            "Train -  [0.71875, 0.84375, 0.6896551724137931]\n",
            "Validation -  [0.75, 0.6875, 0.75]\n",
            "Test -  [0.4, 0.5, 0.33333333333333326]\n",
            "\n",
            "Epoch  46\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03839750215411186\n",
            "Train -  [0.71875, 0.90234375, 0.6896551724137931]\n",
            "Validation -  [0.625, 0.625, 0.6666666666666665]\n",
            "Test -  [0.4, 0.47, 0.33333333333333326]\n",
            "\n",
            "Epoch  47\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.034570006653666496\n",
            "Train -  [0.75, 0.89453125, 0.7333333333333334]\n",
            "Validation -  [0.875, 0.75, 0.8571428571428571]\n",
            "Test -  [0.35, 0.47, 0.23529411764705882]\n",
            "\n",
            "Epoch  48\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.035787103697657585\n",
            "Train -  [0.78125, 0.87890625, 0.7586206896551724]\n",
            "Validation -  [0.875, 0.75, 0.8571428571428571]\n",
            "Test -  [0.4, 0.47, 0.33333333333333326]\n",
            "\n",
            "Epoch  49\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.029944438487291336\n",
            "Train -  [0.75, 0.83203125, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.75, 0.6666666666666665]\n",
            "Test -  [0.45, 0.49, 0.4210526315789474]\n",
            "\n",
            "Epoch  50\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03667212650179863\n",
            "Train -  [0.75, 0.859375, 0.7142857142857143]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.4, 0.45000000000000007, 0.33333333333333326]\n",
            "\n",
            "Epoch  51\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0261590126901865\n",
            "Train -  [0.75, 0.87109375, 0.7333333333333334]\n",
            "Validation -  [0.875, 0.75, 0.8571428571428571]\n",
            "Test -  [0.4, 0.48, 0.33333333333333326]\n",
            "\n",
            "Epoch  52\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.038185869343578815\n",
            "Train -  [0.75, 0.85546875, 0.7333333333333334]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.45, 0.44, 0.4210526315789474]\n",
            "\n",
            "Epoch  53\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02559586800634861\n",
            "Train -  [0.78125, 0.875, 0.7741935483870969]\n",
            "Validation -  [0.75, 0.6875, 0.75]\n",
            "Test -  [0.45, 0.51, 0.4210526315789474]\n",
            "\n",
            "Epoch  54\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.022921372205018997\n",
            "Train -  [0.78125, 0.87890625, 0.7586206896551724]\n",
            "Validation -  [0.75, 0.6875, 0.75]\n",
            "Test -  [0.4, 0.53, 0.25]\n",
            "\n",
            "Epoch  55\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02491680346429348\n",
            "Train -  [0.75, 0.84765625, 0.7142857142857143]\n",
            "Validation -  [0.625, 0.6875, 0.5714285714285715]\n",
            "Test -  [0.4, 0.51, 0.33333333333333326]\n",
            "\n",
            "Epoch  56\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.024205668829381466\n",
            "Train -  [0.78125, 0.91796875, 0.7586206896551724]\n",
            "Validation -  [0.75, 0.625, 0.75]\n",
            "Test -  [0.35, 0.52, 0.23529411764705882]\n",
            "\n",
            "Epoch  57\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.030595852062106133\n",
            "Train -  [0.71875, 0.88671875, 0.6896551724137931]\n",
            "Validation -  [0.625, 0.625, 0.5714285714285715]\n",
            "Test -  [0.5, 0.54, 0.4444444444444445]\n",
            "\n",
            "Epoch  58\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02639302983880043\n",
            "Train -  [0.78125, 0.88671875, 0.7407407407407406]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.4, 0.51, 0.25]\n",
            "\n",
            "Epoch  59\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.022177312523126602\n",
            "Train -  [0.75, 0.87109375, 0.7142857142857143]\n",
            "Validation -  [0.75, 0.6875, 0.75]\n",
            "Test -  [0.45, 0.52, 0.3529411764705882]\n",
            "\n",
            "Epoch  60\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0215834379196167\n",
            "Train -  [0.71875, 0.88671875, 0.6896551724137931]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.45, 0.52, 0.4210526315789474]\n",
            "\n",
            "Epoch  61\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02269021887332201\n",
            "Train -  [0.75, 0.8984375, 0.7142857142857143]\n",
            "Validation -  [0.75, 0.6875, 0.75]\n",
            "Test -  [0.45, 0.48000000000000004, 0.4210526315789474]\n",
            "\n",
            "Epoch  62\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02449810691177845\n",
            "Train -  [0.78125, 0.8671875, 0.7407407407407406]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.4, 0.41, 0.33333333333333326]\n",
            "\n",
            "Epoch  63\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01776698138564825\n",
            "Train -  [0.71875, 0.875, 0.6896551724137931]\n",
            "Validation -  [0.875, 0.75, 0.8571428571428571]\n",
            "Test -  [0.4, 0.45, 0.25]\n",
            "\n",
            "Epoch  64\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.019847789779305458\n",
            "Train -  [0.78125, 0.87109375, 0.7407407407407406]\n",
            "Validation -  [0.75, 0.75, 0.6666666666666666]\n",
            "Test -  [0.35, 0.49, 0.23529411764705882]\n",
            "\n",
            "Epoch  65\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.020981711335480213\n",
            "Train -  [0.75, 0.86328125, 0.7142857142857143]\n",
            "Validation -  [0.75, 0.6875, 0.6666666666666666]\n",
            "Test -  [0.5, 0.48, 0.4444444444444445]\n",
            "\n",
            "Epoch  66\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.020426458679139614\n",
            "Train -  [0.8125, 0.87109375, 0.7857142857142857]\n",
            "Validation -  [0.5, 0.5625, 0.5]\n",
            "Test -  [0.4, 0.51, 0.33333333333333326]\n",
            "\n",
            "Epoch  67\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.014668445568531752\n",
            "Train -  [0.75, 0.875, 0.7142857142857143]\n",
            "Validation -  [0.625, 0.625, 0.6666666666666665]\n",
            "Test -  [0.4, 0.45999999999999996, 0.33333333333333326]\n",
            "\n",
            "Epoch  68\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.021371610462665558\n",
            "Train -  [0.75, 0.84765625, 0.7142857142857143]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.45, 0.44, 0.3529411764705882]\n",
            "\n",
            "Epoch  69\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.016272163949906826\n",
            "Train -  [0.71875, 0.8828125, 0.6896551724137931]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.5, 0.45, 0.5]\n",
            "\n",
            "Epoch  70\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.015631663613021374\n",
            "Train -  [0.78125, 0.90234375, 0.7586206896551724]\n",
            "Validation -  [0.75, 0.6875, 0.75]\n",
            "Test -  [0.45, 0.52, 0.4210526315789474]\n",
            "\n",
            "Epoch  71\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.017367848195135593\n",
            "Train -  [0.78125, 0.90625, 0.7586206896551724]\n",
            "Validation -  [0.75, 0.625, 0.75]\n",
            "Test -  [0.4, 0.51, 0.33333333333333326]\n",
            "\n",
            "Epoch  72\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01924214418977499\n",
            "Train -  [0.75, 0.86328125, 0.7142857142857143]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.4, 0.52, 0.33333333333333326]\n",
            "\n",
            "Epoch  73\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01664378447458148\n",
            "Train -  [0.71875, 0.87890625, 0.6896551724137931]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.4, 0.5700000000000001, 0.33333333333333326]\n",
            "\n",
            "Epoch  74\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01638047583401203\n",
            "Train -  [0.71875, 0.87890625, 0.6896551724137931]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.55, 0.53, 0.47058823529411764]\n",
            "\n",
            "Epoch  75\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.014243214391171932\n",
            "Train -  [0.78125, 0.8828125, 0.7586206896551724]\n",
            "Validation -  [0.75, 0.6875, 0.75]\n",
            "Test -  [0.45, 0.52, 0.3529411764705882]\n",
            "\n",
            "Epoch  76\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.020862005650997162\n",
            "Train -  [0.71875, 0.875, 0.6896551724137931]\n",
            "Validation -  [0.625, 0.75, 0.5714285714285715]\n",
            "Test -  [0.45, 0.54, 0.4210526315789474]\n",
            "\n",
            "Epoch  77\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.016560185234993696\n",
            "Train -  [0.78125, 0.8984375, 0.7586206896551724]\n",
            "Validation -  [0.625, 0.6875, 0.6666666666666665]\n",
            "Test -  [0.45, 0.47, 0.4210526315789474]\n",
            "\n",
            "Epoch  78\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.011514001991599798\n",
            "Train -  [0.71875, 0.8671875, 0.6896551724137931]\n",
            "Validation -  [0.75, 0.6875, 0.75]\n",
            "Test -  [0.4, 0.52, 0.33333333333333326]\n",
            "\n",
            "Epoch  79\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01613914268091321\n",
            "Train -  [0.75, 0.90234375, 0.7142857142857143]\n",
            "Validation -  [0.75, 0.75, 0.6666666666666666]\n",
            "Test -  [0.4, 0.44, 0.33333333333333326]\n",
            "\n",
            "Epoch  80\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.013334875460714102\n",
            "Train -  [0.8125, 0.8828125, 0.7999999999999999]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.4, 0.46, 0.25]\n",
            "\n",
            "Epoch  81\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.010327055118978024\n",
            "Train -  [0.78125, 0.86328125, 0.7407407407407406]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.45, 0.51, 0.4210526315789474]\n",
            "\n",
            "Epoch  82\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.014568313490599394\n",
            "Train -  [0.75, 0.87890625, 0.7142857142857143]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.4, 0.54, 0.33333333333333326]\n",
            "\n",
            "Epoch  83\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.015134557615965605\n",
            "Train -  [0.75, 0.86328125, 0.7142857142857143]\n",
            "Validation -  [0.875, 0.75, 0.8571428571428571]\n",
            "Test -  [0.4, 0.51, 0.33333333333333326]\n",
            "\n",
            "Epoch  84\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.011257118545472622\n",
            "Train -  [0.75, 0.88671875, 0.7142857142857143]\n",
            "Validation -  [0.875, 0.75, 0.8571428571428571]\n",
            "Test -  [0.4, 0.52, 0.33333333333333326]\n",
            "\n",
            "Epoch  85\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.014574939850717783\n",
            "Train -  [0.78125, 0.87109375, 0.7407407407407406]\n",
            "Validation -  [0.625, 0.625, 0.5714285714285715]\n",
            "Test -  [0.4, 0.49, 0.33333333333333326]\n",
            "\n",
            "Epoch  86\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.010692522395402193\n",
            "Train -  [0.75, 0.87890625, 0.7142857142857143]\n",
            "Validation -  [0.625, 0.6875, 0.5714285714285715]\n",
            "Test -  [0.45, 0.49, 0.3529411764705882]\n",
            "\n",
            "Epoch  87\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.010437760967761278\n",
            "Train -  [0.71875, 0.890625, 0.6896551724137931]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.45, 0.54, 0.4210526315789474]\n",
            "\n",
            "Epoch  88\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01187511021271348\n",
            "Train -  [0.75, 0.89453125, 0.7142857142857143]\n",
            "Validation -  [0.5, 0.625, 0.5]\n",
            "Test -  [0.45, 0.51, 0.4210526315789474]\n",
            "\n",
            "Epoch  89\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.013182688038796186\n",
            "Train -  [0.71875, 0.84375, 0.6896551724137931]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.4, 0.49, 0.33333333333333326]\n",
            "\n",
            "Epoch  90\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.012524007353931665\n",
            "Train -  [0.75, 0.90625, 0.7142857142857143]\n",
            "Validation -  [0.75, 0.6875, 0.6666666666666666]\n",
            "Test -  [0.5, 0.5, 0.4444444444444445]\n",
            "\n",
            "Epoch  91\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.010326798539608717\n",
            "Train -  [0.78125, 0.921875, 0.7586206896551724]\n",
            "Validation -  [0.875, 0.75, 0.8571428571428571]\n",
            "Test -  [0.4, 0.56, 0.33333333333333326]\n",
            "\n",
            "Epoch  92\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.009165210649371147\n",
            "Train -  [0.75, 0.90234375, 0.7333333333333334]\n",
            "Validation -  [0.75, 0.6875, 0.75]\n",
            "Test -  [0.45, 0.47000000000000003, 0.4210526315789474]\n",
            "\n",
            "Epoch  93\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.010375683661550283\n",
            "Train -  [0.75, 0.88671875, 0.7142857142857143]\n",
            "Validation -  [0.625, 0.625, 0.5714285714285715]\n",
            "Test -  [0.45, 0.5, 0.3529411764705882]\n",
            "\n",
            "Epoch  94\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.011746341362595558\n",
            "Train -  [0.75, 0.87890625, 0.7333333333333334]\n",
            "Validation -  [0.875, 0.75, 0.8571428571428571]\n",
            "Test -  [0.4, 0.51, 0.33333333333333326]\n",
            "\n",
            "Epoch  95\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.009261978790163994\n",
            "Train -  [0.75, 0.8828125, 0.7142857142857143]\n",
            "Validation -  [0.5, 0.625, 0.5]\n",
            "Test -  [0.45, 0.59, 0.3529411764705882]\n",
            "\n",
            "Epoch  96\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.011168417986482382\n",
            "Train -  [0.78125, 0.8515625, 0.7586206896551724]\n",
            "Validation -  [0.75, 0.6875, 0.75]\n",
            "Test -  [0.4, 0.5, 0.33333333333333326]\n",
            "\n",
            "Epoch  97\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.012311980593949556\n",
            "Train -  [0.75, 0.84765625, 0.7142857142857143]\n",
            "Validation -  [0.75, 0.6875, 0.75]\n",
            "Test -  [0.45, 0.54, 0.3529411764705882]\n",
            "\n",
            "Epoch  98\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.007961384719237685\n",
            "Train -  [0.71875, 0.85546875, 0.6896551724137931]\n",
            "Validation -  [0.75, 0.6875, 0.75]\n",
            "Test -  [0.45, 0.53, 0.4210526315789474]\n",
            "\n",
            "Epoch  99\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.00905221700668335\n",
            "Train -  [0.78125, 0.8984375, 0.7407407407407406]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.4, 0.55, 0.33333333333333326]\n",
            "Epoch with best accuracy is 10\n",
            "==================================================END OF SUBJECT {idx_e_subj+1}==================================================\n",
            "Subject 16\n",
            "start_idx_train: 600\n",
            "end_idx_train: 632\n",
            "start_idx_val: 632\n",
            "end_idx_val: 640\n",
            "start_idx_eval: 300\n",
            "end_idx_eval: 320\n",
            "[1 0 0 1 1 0 1 0 0 1]\n",
            "[0 1 1 0 0 1 0 1]\n",
            "[1 0 0 1 1 0 0 1 0 1]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Epoch  0\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.8989996314048767\n",
            "Train -  [0.59375, 0.47265625, 0.43478260869565216]\n",
            "Validation -  [0.625, 0.5, 0.4]\n",
            "Test -  [0.6, 0.54, 0.4285714285714285]\n",
            "\n",
            "Epoch  1\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.4680494666099548\n",
            "Train -  [0.5, 0.6328125, 0.6666666666666666]\n",
            "Validation -  [0.5, 0.8125, 0.6666666666666666]\n",
            "Test -  [0.5, 0.67, 0.6666666666666666]\n",
            "\n",
            "Epoch  2\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.3395328521728516\n",
            "Train -  [0.53125, 0.59375, 0.6808510638297872]\n",
            "Validation -  [0.5, 0.875, 0.6666666666666666]\n",
            "Test -  [0.5, 0.49, 0.6428571428571429]\n",
            "\n",
            "Epoch  3\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.15180903673172\n",
            "Train -  [0.53125, 0.625, 0.6666666666666667]\n",
            "Validation -  [0.5, 0.5625, 0.6666666666666666]\n",
            "Test -  [0.45, 0.44, 0.6206896551724138]\n",
            "\n",
            "Epoch  4\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.866719514131546\n",
            "Train -  [0.46875, 0.81640625, 0.6382978723404255]\n",
            "Validation -  [0.5, 0.375, 0.6666666666666666]\n",
            "Test -  [0.55, 0.67, 0.6666666666666667]\n",
            "\n",
            "Epoch  5\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.9046753644943237\n",
            "Train -  [0.5625, 0.5546875, 0.6956521739130436]\n",
            "Validation -  [0.5, 0.6875, 0.6666666666666666]\n",
            "Test -  [0.45, 0.44999999999999996, 0.6206896551724138]\n",
            "\n",
            "Epoch  6\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.6490038633346558\n",
            "Train -  [0.5625, 0.65234375, 0.6956521739130436]\n",
            "Validation -  [0.5, 0.4375, 0.6666666666666666]\n",
            "Test -  [0.45, 0.4, 0.6206896551724138]\n",
            "\n",
            "Epoch  7\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.7645878195762634\n",
            "Train -  [0.5, 0.6015625, 0.6666666666666666]\n",
            "Validation -  [0.5, 0.8125, 0.6666666666666666]\n",
            "Test -  [0.5, 0.58, 0.6666666666666666]\n",
            "\n",
            "Epoch  8\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.5159588754177094\n",
            "Train -  [0.5, 0.8046875, 0.6666666666666666]\n",
            "Validation -  [0.5, 0.5, 0.6666666666666666]\n",
            "Test -  [0.5, 0.56, 0.6666666666666666]\n",
            "\n",
            "Epoch  9\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.4734852910041809\n",
            "Train -  [0.53125, 0.7265625, 0.6808510638297872]\n",
            "Validation -  [0.5, 0.375, 0.6666666666666666]\n",
            "Test -  [0.55, 0.61, 0.6896551724137931]\n",
            "\n",
            "Epoch  10\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.42596176266670227\n",
            "Train -  [0.65625, 0.7890625, 0.7441860465116279]\n",
            "Validation -  [0.625, 0.4375, 0.7272727272727273]\n",
            "Test -  [0.45, 0.31, 0.6206896551724138]\n",
            "\n",
            "Epoch  11\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.4346928000450134\n",
            "Train -  [0.59375, 0.79296875, 0.7111111111111111]\n",
            "Validation -  [0.5, 0.375, 0.6666666666666666]\n",
            "Test -  [0.45, 0.46, 0.5925925925925927]\n",
            "\n",
            "Epoch  12\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.31214840710163116\n",
            "Train -  [0.53125, 0.79296875, 0.6666666666666667]\n",
            "Validation -  [0.5, 0.3125, 0.6666666666666666]\n",
            "Test -  [0.5, 0.77, 0.6428571428571429]\n",
            "\n",
            "Epoch  13\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.36649373173713684\n",
            "Train -  [0.6875, 0.84765625, 0.761904761904762]\n",
            "Validation -  [0.375, 0.375, 0.5454545454545454]\n",
            "Test -  [0.5, 0.54, 0.6666666666666666]\n",
            "\n",
            "Epoch  14\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.3203027844429016\n",
            "Train -  [0.71875, 0.859375, 0.7804878048780487]\n",
            "Validation -  [0.625, 0.3125, 0.7272727272727273]\n",
            "Test -  [0.45, 0.48, 0.6206896551724138]\n",
            "\n",
            "Epoch  15\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.25633405148983\n",
            "Train -  [0.71875, 0.921875, 0.7804878048780487]\n",
            "Validation -  [0.375, 0.375, 0.5454545454545454]\n",
            "Test -  [0.55, 0.54, 0.6896551724137931]\n",
            "\n",
            "Epoch  16\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.2472369521856308\n",
            "Train -  [0.78125, 0.88671875, 0.8205128205128205]\n",
            "Validation -  [0.375, 0.3125, 0.5454545454545454]\n",
            "Test -  [0.5, 0.51, 0.6666666666666666]\n",
            "\n",
            "Epoch  17\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.18001384288072586\n",
            "Train -  [0.84375, 0.90234375, 0.8648648648648648]\n",
            "Validation -  [0.375, 0.3125, 0.4444444444444445]\n",
            "Test -  [0.55, 0.8300000000000001, 0.6666666666666667]\n",
            "\n",
            "Epoch  18\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.1609455868601799\n",
            "Train -  [0.6875, 0.8984375, 0.761904761904762]\n",
            "Validation -  [0.375, 0.0, 0.5454545454545454]\n",
            "Test -  [0.45, 0.51, 0.5925925925925927]\n",
            "\n",
            "Epoch  19\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.1534237489104271\n",
            "Train -  [0.8125, 0.93359375, 0.8421052631578948]\n",
            "Validation -  [0.375, 0.1875, 0.5454545454545454]\n",
            "Test -  [0.5, 0.53, 0.6153846153846154]\n",
            "\n",
            "Epoch  20\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.14488016813993454\n",
            "Train -  [0.84375, 0.890625, 0.8648648648648648]\n",
            "Validation -  [0.25, 0.25, 0.4]\n",
            "Test -  [0.5, 0.54, 0.6153846153846154]\n",
            "\n",
            "Epoch  21\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.1145956888794899\n",
            "Train -  [0.84375, 0.9375, 0.8648648648648648]\n",
            "Validation -  [0.25, 0.3125, 0.4]\n",
            "Test -  [0.45, 0.52, 0.5217391304347826]\n",
            "\n",
            "Epoch  22\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.12288173288106918\n",
            "Train -  [0.875, 0.91015625, 0.888888888888889]\n",
            "Validation -  [0.375, 0.4375, 0.4444444444444445]\n",
            "Test -  [0.4, 0.47, 0.5]\n",
            "\n",
            "Epoch  23\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.1217278428375721\n",
            "Train -  [0.875, 0.92578125, 0.888888888888889]\n",
            "Validation -  [0.25, 0.3125, 0.4]\n",
            "Test -  [0.6, 0.6200000000000001, 0.6666666666666666]\n",
            "\n",
            "Epoch  24\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.09692876785993576\n",
            "Train -  [0.875, 0.921875, 0.888888888888889]\n",
            "Validation -  [0.25, 0.1875, 0.4]\n",
            "Test -  [0.45, 0.43, 0.56]\n",
            "\n",
            "Epoch  25\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.09409786760807037\n",
            "Train -  [0.90625, 0.92578125, 0.9142857142857143]\n",
            "Validation -  [0.375, 0.125, 0.5454545454545454]\n",
            "Test -  [0.45, 0.51, 0.56]\n",
            "\n",
            "Epoch  26\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0998578704893589\n",
            "Train -  [0.875, 0.92578125, 0.888888888888889]\n",
            "Validation -  [0.25, 0.1875, 0.4]\n",
            "Test -  [0.4, 0.42000000000000004, 0.45454545454545453]\n",
            "\n",
            "Epoch  27\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.09562898799777031\n",
            "Train -  [0.875, 0.9375, 0.888888888888889]\n",
            "Validation -  [0.25, 0.375, 0.4]\n",
            "Test -  [0.5, 0.5, 0.5454545454545454]\n",
            "\n",
            "Epoch  28\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.06670834124088287\n",
            "Train -  [0.875, 0.91796875, 0.888888888888889]\n",
            "Validation -  [0.25, 0.375, 0.4]\n",
            "Test -  [0.35, 0.41, 0.4347826086956522]\n",
            "\n",
            "Epoch  29\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.06686025112867355\n",
            "Train -  [0.90625, 0.90625, 0.9142857142857143]\n",
            "Validation -  [0.25, 0.1875, 0.4]\n",
            "Test -  [0.4, 0.36, 0.33333333333333326]\n",
            "\n",
            "Epoch  30\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.06871251948177814\n",
            "Train -  [0.90625, 0.9375, 0.9142857142857143]\n",
            "Validation -  [0.25, 0.25, 0.4]\n",
            "Test -  [0.55, 0.47, 0.47058823529411764]\n",
            "\n",
            "Epoch  31\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.06087496317923069\n",
            "Train -  [0.84375, 0.9375, 0.8571428571428572]\n",
            "Validation -  [0.375, 0.25, 0.28571428571428575]\n",
            "Test -  [0.4, 0.4, 0.33333333333333326]\n",
            "\n",
            "Epoch  32\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.052639275789260864\n",
            "Train -  [0.875, 0.9453125, 0.888888888888889]\n",
            "Validation -  [0.375, 0.25, 0.28571428571428575]\n",
            "Test -  [0.65, 0.49, 0.588235294117647]\n",
            "\n",
            "Epoch  33\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0559239462018013\n",
            "Train -  [0.90625, 0.94140625, 0.9142857142857143]\n",
            "Validation -  [0.25, 0.0625, 0.4]\n",
            "Test -  [0.5, 0.36, 0.37499999999999994]\n",
            "\n",
            "Epoch  34\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.05262191779911518\n",
            "Train -  [0.84375, 0.9375, 0.8648648648648648]\n",
            "Validation -  [0.25, 0.3125, 0.4]\n",
            "Test -  [0.55, 0.35, 0.4]\n",
            "\n",
            "Epoch  35\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.04707305319607258\n",
            "Train -  [0.875, 0.93359375, 0.888888888888889]\n",
            "Validation -  [0.125, 0.125, 0.22222222222222224]\n",
            "Test -  [0.5, 0.37000000000000005, 0.4444444444444445]\n",
            "\n",
            "Epoch  36\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.056939130648970604\n",
            "Train -  [0.84375, 0.91796875, 0.8648648648648648]\n",
            "Validation -  [0.25, 0.125, 0.25]\n",
            "Test -  [0.5, 0.47, 0.37499999999999994]\n",
            "\n",
            "Epoch  37\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.04172056633979082\n",
            "Train -  [0.8125, 0.9296875, 0.8333333333333334]\n",
            "Validation -  [0.375, 0.25, 0.4444444444444445]\n",
            "Test -  [0.45, 0.44, 0.3529411764705882]\n",
            "\n",
            "Epoch  38\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0371515154838562\n",
            "Train -  [0.84375, 0.94921875, 0.8648648648648648]\n",
            "Validation -  [0.375, 0.1875, 0.4444444444444445]\n",
            "Test -  [0.45, 0.47, 0.4210526315789474]\n",
            "\n",
            "Epoch  39\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.033166867680847645\n",
            "Train -  [0.875, 0.94921875, 0.888888888888889]\n",
            "Validation -  [0.125, 0.125, 0.22222222222222224]\n",
            "Test -  [0.55, 0.53, 0.5263157894736842]\n",
            "\n",
            "Epoch  40\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.038273464888334274\n",
            "Train -  [0.875, 0.94140625, 0.888888888888889]\n",
            "Validation -  [0.5, 0.25, 0.5]\n",
            "Test -  [0.4, 0.42999999999999994, 0.33333333333333326]\n",
            "\n",
            "Epoch  41\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03486648015677929\n",
            "Train -  [0.84375, 0.94140625, 0.8571428571428572]\n",
            "Validation -  [0.375, 0.1875, 0.4444444444444445]\n",
            "Test -  [0.5, 0.38, 0.37499999999999994]\n",
            "\n",
            "Epoch  42\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03524046018719673\n",
            "Train -  [0.875, 0.95703125, 0.888888888888889]\n",
            "Validation -  [0.25, 0.1875, 0.4]\n",
            "Test -  [0.5, 0.44, 0.37499999999999994]\n",
            "\n",
            "Epoch  43\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.036861538887023926\n",
            "Train -  [0.84375, 0.9453125, 0.8648648648648648]\n",
            "Validation -  [0.25, 0.1875, 0.4]\n",
            "Test -  [0.55, 0.43999999999999995, 0.47058823529411764]\n",
            "\n",
            "Epoch  44\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.029296274296939373\n",
            "Train -  [0.84375, 0.9453125, 0.8648648648648648]\n",
            "Validation -  [0.375, 0.25, 0.4444444444444445]\n",
            "Test -  [0.6, 0.52, 0.5555555555555556]\n",
            "\n",
            "Epoch  45\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.035233473405241966\n",
            "Train -  [0.875, 0.953125, 0.888888888888889]\n",
            "Validation -  [0.25, 0.25, 0.4]\n",
            "Test -  [0.4, 0.44999999999999996, 0.4000000000000001]\n",
            "\n",
            "Epoch  46\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.029527672566473484\n",
            "Train -  [0.90625, 0.9609375, 0.9142857142857143]\n",
            "Validation -  [0.5, 0.3125, 0.5]\n",
            "Test -  [0.5, 0.43000000000000005, 0.37499999999999994]\n",
            "\n",
            "Epoch  47\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.027009448036551476\n",
            "Train -  [0.84375, 0.92578125, 0.8571428571428572]\n",
            "Validation -  [0.125, 0.1875, 0.22222222222222224]\n",
            "Test -  [0.5, 0.41000000000000003, 0.37499999999999994]\n",
            "\n",
            "Epoch  48\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02848561480641365\n",
            "Train -  [0.875, 0.94140625, 0.888888888888889]\n",
            "Validation -  [0.25, 0.1875, 0.25]\n",
            "Test -  [0.5, 0.38, 0.37499999999999994]\n",
            "\n",
            "Epoch  49\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.026131502352654934\n",
            "Train -  [0.90625, 0.95703125, 0.9142857142857143]\n",
            "Validation -  [0.375, 0.25, 0.4444444444444445]\n",
            "Test -  [0.45, 0.38, 0.3529411764705882]\n",
            "\n",
            "Epoch  50\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.023380139842629433\n",
            "Train -  [0.875, 0.94140625, 0.888888888888889]\n",
            "Validation -  [0.375, 0.1875, 0.4444444444444445]\n",
            "Test -  [0.6, 0.53, 0.5]\n",
            "\n",
            "Epoch  51\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02712793182581663\n",
            "Train -  [0.84375, 0.953125, 0.8648648648648648]\n",
            "Validation -  [0.375, 0.25, 0.4444444444444445]\n",
            "Test -  [0.55, 0.5, 0.47058823529411764]\n",
            "\n",
            "Epoch  52\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.023946993984282017\n",
            "Train -  [0.875, 0.94140625, 0.888888888888889]\n",
            "Validation -  [0.25, 0.3125, 0.25]\n",
            "Test -  [0.55, 0.41000000000000003, 0.4]\n",
            "\n",
            "Epoch  53\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.022753688506782055\n",
            "Train -  [0.875, 0.9375, 0.888888888888889]\n",
            "Validation -  [0.5, 0.375, 0.5]\n",
            "Test -  [0.5, 0.43, 0.4444444444444445]\n",
            "\n",
            "Epoch  54\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.030171808786690235\n",
            "Train -  [0.875, 0.9453125, 0.888888888888889]\n",
            "Validation -  [0.375, 0.25, 0.4444444444444445]\n",
            "Test -  [0.4, 0.45999999999999996, 0.4000000000000001]\n",
            "\n",
            "Epoch  55\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.026198831386864185\n",
            "Train -  [0.875, 0.95703125, 0.888888888888889]\n",
            "Validation -  [0.375, 0.375, 0.4444444444444445]\n",
            "Test -  [0.45, 0.37, 0.3529411764705882]\n",
            "\n",
            "Epoch  56\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.027558058500289917\n",
            "Train -  [0.84375, 0.9375, 0.8571428571428572]\n",
            "Validation -  [0.25, 0.0, 0.4]\n",
            "Test -  [0.45, 0.47, 0.3529411764705882]\n",
            "\n",
            "Epoch  57\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.022158600389957428\n",
            "Train -  [0.84375, 0.9296875, 0.8571428571428572]\n",
            "Validation -  [0.25, 0.1875, 0.25]\n",
            "Test -  [0.6, 0.42000000000000004, 0.4285714285714285]\n",
            "\n",
            "Epoch  58\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.022488963790237904\n",
            "Train -  [0.84375, 0.9296875, 0.8571428571428572]\n",
            "Validation -  [0.5, 0.3125, 0.6]\n",
            "Test -  [0.5, 0.48000000000000004, 0.4444444444444445]\n",
            "\n",
            "Epoch  59\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02123149484395981\n",
            "Train -  [0.875, 0.94921875, 0.8823529411764706]\n",
            "Validation -  [0.375, 0.375, 0.4444444444444445]\n",
            "Test -  [0.5, 0.44, 0.4444444444444445]\n",
            "\n",
            "Epoch  60\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.016948055010288954\n",
            "Train -  [0.84375, 0.94921875, 0.8571428571428572]\n",
            "Validation -  [0.25, 0.125, 0.4]\n",
            "Test -  [0.45, 0.38, 0.4210526315789474]\n",
            "\n",
            "Epoch  61\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.018661516718566418\n",
            "Train -  [0.875, 0.9296875, 0.888888888888889]\n",
            "Validation -  [0.125, 0.0, 0.22222222222222224]\n",
            "Test -  [0.55, 0.49, 0.47058823529411764]\n",
            "\n",
            "Epoch  62\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.018964371643960476\n",
            "Train -  [0.90625, 0.9453125, 0.9142857142857143]\n",
            "Validation -  [0.25, 0.0625, 0.25]\n",
            "Test -  [0.45, 0.46, 0.4210526315789474]\n",
            "\n",
            "Epoch  63\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02147589484229684\n",
            "Train -  [0.875, 0.9296875, 0.8823529411764706]\n",
            "Validation -  [0.125, 0.1875, 0.22222222222222224]\n",
            "Test -  [0.45, 0.39, 0.3529411764705882]\n",
            "\n",
            "Epoch  64\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02004510723054409\n",
            "Train -  [0.875, 0.94140625, 0.888888888888889]\n",
            "Validation -  [0.375, 0.125, 0.4444444444444445]\n",
            "Test -  [0.55, 0.48, 0.4]\n",
            "\n",
            "Epoch  65\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.017892098519951105\n",
            "Train -  [0.875, 0.95703125, 0.888888888888889]\n",
            "Validation -  [0.375, 0.125, 0.4444444444444445]\n",
            "Test -  [0.5, 0.49, 0.37499999999999994]\n",
            "\n",
            "Epoch  66\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.016906287521123886\n",
            "Train -  [0.875, 0.94140625, 0.888888888888889]\n",
            "Validation -  [0.375, 0.375, 0.5454545454545454]\n",
            "Test -  [0.5, 0.43000000000000005, 0.37499999999999994]\n",
            "\n",
            "Epoch  67\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01934191584587097\n",
            "Train -  [0.84375, 0.9375, 0.8571428571428572]\n",
            "Validation -  [0.25, 0.1875, 0.4]\n",
            "Test -  [0.6, 0.45, 0.5]\n",
            "\n",
            "Epoch  68\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.013935568742454052\n",
            "Train -  [0.84375, 0.93359375, 0.8648648648648648]\n",
            "Validation -  [0.25, 0.25, 0.25]\n",
            "Test -  [0.5, 0.42000000000000004, 0.4444444444444445]\n",
            "\n",
            "Epoch  69\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01224918756633997\n",
            "Train -  [0.84375, 0.93359375, 0.8648648648648648]\n",
            "Validation -  [0.375, 0.125, 0.4444444444444445]\n",
            "Test -  [0.5, 0.45999999999999996, 0.4444444444444445]\n",
            "\n",
            "Epoch  70\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.013147808145731688\n",
            "Train -  [0.90625, 0.953125, 0.9142857142857143]\n",
            "Validation -  [0.5, 0.25, 0.5]\n",
            "Test -  [0.5, 0.44999999999999996, 0.37499999999999994]\n",
            "\n",
            "Epoch  71\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01122449804097414\n",
            "Train -  [0.84375, 0.9375, 0.8571428571428572]\n",
            "Validation -  [0.25, 0.1875, 0.4]\n",
            "Test -  [0.65, 0.6000000000000001, 0.588235294117647]\n",
            "\n",
            "Epoch  72\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.015503168571740389\n",
            "Train -  [0.875, 0.94140625, 0.888888888888889]\n",
            "Validation -  [0.25, 0.1875, 0.25]\n",
            "Test -  [0.55, 0.48, 0.47058823529411764]\n",
            "\n",
            "Epoch  73\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.00952764181420207\n",
            "Train -  [0.875, 0.94921875, 0.888888888888889]\n",
            "Validation -  [0.375, 0.25, 0.4444444444444445]\n",
            "Test -  [0.55, 0.5499999999999999, 0.5263157894736842]\n",
            "\n",
            "Epoch  74\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0103668924421072\n",
            "Train -  [0.875, 0.9375, 0.888888888888889]\n",
            "Validation -  [0.25, 0.25, 0.4]\n",
            "Test -  [0.4, 0.56, 0.33333333333333326]\n",
            "\n",
            "Epoch  75\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.010211732238531113\n",
            "Train -  [0.90625, 0.9296875, 0.9142857142857143]\n",
            "Validation -  [0.5, 0.25, 0.5]\n",
            "Test -  [0.45, 0.52, 0.4210526315789474]\n",
            "\n",
            "Epoch  76\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.011921238619834185\n",
            "Train -  [0.84375, 0.9375, 0.8571428571428572]\n",
            "Validation -  [0.25, 0.25, 0.25]\n",
            "Test -  [0.5, 0.44999999999999996, 0.37499999999999994]\n",
            "\n",
            "Epoch  77\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01096916850656271\n",
            "Train -  [0.84375, 0.9296875, 0.8571428571428572]\n",
            "Validation -  [0.25, 0.1875, 0.4]\n",
            "Test -  [0.35, 0.35, 0.3157894736842105]\n",
            "\n",
            "Epoch  78\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.012053965125232935\n",
            "Train -  [0.84375, 0.95703125, 0.8648648648648648]\n",
            "Validation -  [0.125, 0.125, 0.22222222222222224]\n",
            "Test -  [0.45, 0.44, 0.4210526315789474]\n",
            "\n",
            "Epoch  79\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.010417676530778408\n",
            "Train -  [0.875, 0.9375, 0.888888888888889]\n",
            "Validation -  [0.125, 0.125, 0.22222222222222224]\n",
            "Test -  [0.5, 0.42000000000000004, 0.37499999999999994]\n",
            "\n",
            "Epoch  80\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.009235539939254522\n",
            "Train -  [0.8125, 0.921875, 0.8333333333333334]\n",
            "Validation -  [0.375, 0.1875, 0.28571428571428575]\n",
            "Test -  [0.5, 0.37, 0.4444444444444445]\n",
            "\n",
            "Epoch  81\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.011847332585602999\n",
            "Train -  [0.90625, 0.94921875, 0.9142857142857143]\n",
            "Validation -  [0.125, 0.1875, 0.22222222222222224]\n",
            "Test -  [0.5, 0.51, 0.37499999999999994]\n",
            "\n",
            "Epoch  82\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.009122757008299232\n",
            "Train -  [0.875, 0.9375, 0.8823529411764706]\n",
            "Validation -  [0.125, 0.125, 0.22222222222222224]\n",
            "Test -  [0.45, 0.45999999999999996, 0.3529411764705882]\n",
            "\n",
            "Epoch  83\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.008580545196309686\n",
            "Train -  [0.84375, 0.9375, 0.8571428571428572]\n",
            "Validation -  [0.375, 0.3125, 0.4444444444444445]\n",
            "Test -  [0.5, 0.44, 0.4444444444444445]\n",
            "\n",
            "Epoch  84\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.010919237975031137\n",
            "Train -  [0.875, 0.94140625, 0.888888888888889]\n",
            "Validation -  [0.125, 0.0625, 0.22222222222222224]\n",
            "Test -  [0.5, 0.47000000000000003, 0.4444444444444445]\n",
            "\n",
            "Epoch  85\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.009793899487704039\n",
            "Train -  [0.90625, 0.94921875, 0.9142857142857143]\n",
            "Validation -  [0.375, 0.1875, 0.4444444444444445]\n",
            "Test -  [0.6, 0.51, 0.5555555555555556]\n",
            "\n",
            "Epoch  86\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.008500155061483383\n",
            "Train -  [0.875, 0.91796875, 0.888888888888889]\n",
            "Validation -  [0.25, 0.1875, 0.25]\n",
            "Test -  [0.5, 0.41000000000000003, 0.37499999999999994]\n",
            "\n",
            "Epoch  87\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.00988698611035943\n",
            "Train -  [0.84375, 0.92578125, 0.8571428571428572]\n",
            "Validation -  [0.25, 0.1875, 0.4]\n",
            "Test -  [0.55, 0.56, 0.4]\n",
            "\n",
            "Epoch  88\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.006370470393449068\n",
            "Train -  [0.875, 0.9375, 0.888888888888889]\n",
            "Validation -  [0.5, 0.25, 0.5]\n",
            "Test -  [0.55, 0.43, 0.4]\n",
            "\n",
            "Epoch  89\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01184079609811306\n",
            "Train -  [0.84375, 0.94140625, 0.8571428571428572]\n",
            "Validation -  [0.25, 0.1875, 0.25]\n",
            "Test -  [0.55, 0.54, 0.47058823529411764]\n",
            "\n",
            "Epoch  90\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.010383755899965763\n",
            "Train -  [0.875, 0.9375, 0.8823529411764706]\n",
            "Validation -  [0.5, 0.375, 0.6]\n",
            "Test -  [0.55, 0.56, 0.47058823529411764]\n",
            "\n",
            "Epoch  91\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.00733022834174335\n",
            "Train -  [0.84375, 0.94921875, 0.8648648648648648]\n",
            "Validation -  [0.375, 0.0, 0.5454545454545454]\n",
            "Test -  [0.5, 0.53, 0.37499999999999994]\n",
            "\n",
            "Epoch  92\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.011523562483489513\n",
            "Train -  [0.875, 0.92578125, 0.8823529411764706]\n",
            "Validation -  [0.125, 0.0625, 0.22222222222222224]\n",
            "Test -  [0.5, 0.41000000000000003, 0.37499999999999994]\n",
            "\n",
            "Epoch  93\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.009148773038759828\n",
            "Train -  [0.90625, 0.94921875, 0.9142857142857143]\n",
            "Validation -  [0.25, 0.125, 0.25]\n",
            "Test -  [0.5, 0.46, 0.4444444444444445]\n",
            "\n",
            "Epoch  94\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.009066734928637743\n",
            "Train -  [0.84375, 0.9296875, 0.8571428571428572]\n",
            "Validation -  [0.25, 0.3125, 0.4]\n",
            "Test -  [0.45, 0.42999999999999994, 0.3529411764705882]\n",
            "\n",
            "Epoch  95\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.010510995052754879\n",
            "Train -  [0.875, 0.953125, 0.888888888888889]\n",
            "Validation -  [0.375, 0.3125, 0.28571428571428575]\n",
            "Test -  [0.5, 0.47, 0.4444444444444445]\n",
            "\n",
            "Epoch  96\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.007625390542671084\n",
            "Train -  [0.875, 0.953125, 0.888888888888889]\n",
            "Validation -  [0.5, 0.3125, 0.5]\n",
            "Test -  [0.45, 0.6300000000000001, 0.3529411764705882]\n",
            "\n",
            "Epoch  97\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.009508720599114895\n",
            "Train -  [0.8125, 0.9296875, 0.8333333333333334]\n",
            "Validation -  [0.5, 0.3125, 0.5]\n",
            "Test -  [0.5, 0.56, 0.4444444444444445]\n",
            "\n",
            "Epoch  98\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.009296281728893518\n",
            "Train -  [0.875, 0.9453125, 0.888888888888889]\n",
            "Validation -  [0.25, 0.375, 0.4]\n",
            "Test -  [0.6, 0.48999999999999994, 0.5]\n",
            "\n",
            "Epoch  99\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.008007970172911882\n",
            "Train -  [0.875, 0.94140625, 0.888888888888889]\n",
            "Validation -  [0.125, 0.1875, 0.22222222222222224]\n",
            "Test -  [0.5, 0.52, 0.4444444444444445]\n",
            "Epoch with best accuracy is 32\n",
            "==================================================END OF SUBJECT {idx_e_subj+1}==================================================\n",
            "Subject 17\n",
            "start_idx_train: 640\n",
            "end_idx_train: 672\n",
            "start_idx_val: 672\n",
            "end_idx_val: 680\n",
            "start_idx_eval: 320\n",
            "end_idx_eval: 340\n",
            "[0 1 1 0 0 1 0 1 0 1]\n",
            "[0 1 1 0 0 1 0 1]\n",
            "[1 0 1 0 0 1 0 1 0 1]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Epoch  0\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  2.2580116391181946\n",
            "Train -  [0.5625, 0.609375, 0.6956521739130436]\n",
            "Validation -  [0.5, 0.4375, 0.6666666666666666]\n",
            "Test -  [0.55, 0.33, 0.6896551724137931]\n",
            "\n",
            "Epoch  1\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.40628182888031\n",
            "Train -  [0.53125, 0.55859375, 0.5161290322580646]\n",
            "Validation -  [0.375, 0.625, 0.4444444444444445]\n",
            "Test -  [0.4, 0.42, 0.45454545454545453]\n",
            "\n",
            "Epoch  2\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.755787193775177\n",
            "Train -  [0.53125, 0.46484375, 0.4444444444444444]\n",
            "Validation -  [0.625, 0.625, 0.6666666666666665]\n",
            "Test -  [0.5, 0.61, 0.37499999999999994]\n",
            "\n",
            "Epoch  3\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.2889772653579712\n",
            "Train -  [0.46875, 0.421875, 0.5641025641025642]\n",
            "Validation -  [0.25, 0.125, 0.4]\n",
            "Test -  [0.55, 0.4, 0.64]\n",
            "\n",
            "Epoch  4\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.2135885953903198\n",
            "Train -  [0.46875, 0.46484375, 0.6046511627906976]\n",
            "Validation -  [0.375, 0.4375, 0.5454545454545454]\n",
            "Test -  [0.45, 0.38, 0.6206896551724138]\n",
            "\n",
            "Epoch  5\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.17122220993042\n",
            "Train -  [0.6875, 0.72265625, 0.7222222222222223]\n",
            "Validation -  [0.375, 0.1875, 0.28571428571428575]\n",
            "Test -  [0.4, 0.39, 0.5]\n",
            "\n",
            "Epoch  6\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.0378741323947906\n",
            "Train -  [0.4375, 0.44921875, 0.3076923076923077]\n",
            "Validation -  [0.5, 0.5625, 0.3333333333333333]\n",
            "Test -  [0.4, 0.41000000000000003, 0.33333333333333326]\n",
            "\n",
            "Epoch  7\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.9935308396816254\n",
            "Train -  [0.59375, 0.5859375, 0.3157894736842105]\n",
            "Validation -  [0.5, 0.25, nan]\n",
            "Test -  [0.4, 0.59, nan]\n",
            "\n",
            "Epoch  8\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.9223953485488892\n",
            "Train -  [0.5625, 0.48046875, 0.2222222222222222]\n",
            "Validation -  [0.5, 0.6875, nan]\n",
            "Test -  [0.5, 0.37, nan]\n",
            "\n",
            "Epoch  9\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.8814646899700165\n",
            "Train -  [0.5, 0.65234375, nan]\n",
            "Validation -  [0.5, 0.75, nan]\n",
            "Test -  [0.55, 0.37, 0.18181818181818182]\n",
            "\n",
            "Epoch  10\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.7231453955173492\n",
            "Train -  [0.59375, 0.703125, 0.3157894736842105]\n",
            "Validation -  [0.5, 0.5, nan]\n",
            "Test -  [0.55, 0.51, 0.18181818181818182]\n",
            "\n",
            "Epoch  11\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.7073405683040619\n",
            "Train -  [0.46875, 0.53125, 0.10526315789473684]\n",
            "Validation -  [0.375, 0.4375, nan]\n",
            "Test -  [0.5, 0.66, nan]\n",
            "\n",
            "Epoch  12\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.5789830982685089\n",
            "Train -  [0.53125, 0.69140625, 0.11764705882352941]\n",
            "Validation -  [0.5, 0.625, nan]\n",
            "Test -  [0.4, 0.26, nan]\n",
            "\n",
            "Epoch  13\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.5626710206270218\n",
            "Train -  [0.53125, 0.65625, 0.11764705882352941]\n",
            "Validation -  [0.5, 0.8125, nan]\n",
            "Test -  [0.45, 0.19, nan]\n",
            "\n",
            "Epoch  14\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.5238906890153885\n",
            "Train -  [0.5625, 0.73046875, 0.2222222222222222]\n",
            "Validation -  [0.5, 0.375, nan]\n",
            "Test -  [0.5, 0.33, nan]\n",
            "\n",
            "Epoch  15\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.4678671211004257\n",
            "Train -  [0.5, 0.76171875, nan]\n",
            "Validation -  [0.5, 0.4375, nan]\n",
            "Test -  [0.5, 0.4, nan]\n",
            "\n",
            "Epoch  16\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.39147908985614777\n",
            "Train -  [0.5, 0.70703125, nan]\n",
            "Validation -  [0.5, 0.25, nan]\n",
            "Test -  [0.5, 0.47, nan]\n",
            "\n",
            "Epoch  17\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.3419564962387085\n",
            "Train -  [0.53125, 0.8515625, 0.11764705882352941]\n",
            "Validation -  [0.5, 0.375, nan]\n",
            "Test -  [0.5, 0.38999999999999996, nan]\n",
            "\n",
            "Epoch  18\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.36568813025951385\n",
            "Train -  [0.5, 0.7734375, 0.1111111111111111]\n",
            "Validation -  [0.5, 0.8125, nan]\n",
            "Test -  [0.5, 0.37, nan]\n",
            "\n",
            "Epoch  19\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.3571072518825531\n",
            "Train -  [0.625, 0.83203125, 0.4]\n",
            "Validation -  [0.5, 0.625, nan]\n",
            "Test -  [0.55, 0.53, 0.18181818181818182]\n",
            "\n",
            "Epoch  20\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.32229261845350266\n",
            "Train -  [0.71875, 0.8515625, 0.6086956521739131]\n",
            "Validation -  [0.375, 0.5, nan]\n",
            "Test -  [0.55, 0.39, 0.18181818181818182]\n",
            "\n",
            "Epoch  21\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.25773125141859055\n",
            "Train -  [0.71875, 0.87890625, 0.6086956521739131]\n",
            "Validation -  [0.5, 0.6875, nan]\n",
            "Test -  [0.55, 0.39, 0.18181818181818182]\n",
            "\n",
            "Epoch  22\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.24317215383052826\n",
            "Train -  [0.75, 0.85546875, 0.6666666666666666]\n",
            "Validation -  [0.25, 0.25, nan]\n",
            "Test -  [0.5, 0.53, 0.16666666666666669]\n",
            "\n",
            "Epoch  23\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.2396128922700882\n",
            "Train -  [0.78125, 0.859375, 0.72]\n",
            "Validation -  [0.375, 0.25, nan]\n",
            "Test -  [0.5, 0.53, 0.37499999999999994]\n",
            "\n",
            "Epoch  24\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.26261764764785767\n",
            "Train -  [0.78125, 0.875, 0.7407407407407406]\n",
            "Validation -  [0.5, 0.3125, 0.3333333333333333]\n",
            "Test -  [0.55, 0.55, 0.30769230769230765]\n",
            "\n",
            "Epoch  25\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.2523385360836983\n",
            "Train -  [0.75, 0.86328125, 0.6923076923076923]\n",
            "Validation -  [0.5, 0.6875, 0.3333333333333333]\n",
            "Test -  [0.5, 0.51, 0.28571428571428575]\n",
            "\n",
            "Epoch  26\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.21867654472589493\n",
            "Train -  [0.78125, 0.91015625, 0.7407407407407406]\n",
            "Validation -  [0.375, 0.5, nan]\n",
            "Test -  [0.4, 0.42000000000000004, 0.14285714285714288]\n",
            "\n",
            "Epoch  27\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.16475430130958557\n",
            "Train -  [0.78125, 0.921875, 0.7407407407407406]\n",
            "Validation -  [0.5, 0.6875, 0.3333333333333333]\n",
            "Test -  [0.45, 0.4700000000000001, 0.15384615384615383]\n",
            "\n",
            "Epoch  28\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.19084184616804123\n",
            "Train -  [0.84375, 0.875, 0.8148148148148148]\n",
            "Validation -  [0.5, 0.5625, 0.5]\n",
            "Test -  [0.5, 0.48, 0.28571428571428575]\n",
            "\n",
            "Epoch  29\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.16603050380945206\n",
            "Train -  [0.8125, 0.93359375, 0.7857142857142857]\n",
            "Validation -  [0.625, 0.5625, 0.5714285714285715]\n",
            "Test -  [0.45, 0.38, nan]\n",
            "\n",
            "Epoch  30\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.13803380727767944\n",
            "Train -  [0.78125, 0.91015625, 0.7586206896551724]\n",
            "Validation -  [0.75, 0.6875, 0.75]\n",
            "Test -  [0.35, 0.44, 0.13333333333333333]\n",
            "\n",
            "Epoch  31\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.11853190511465073\n",
            "Train -  [0.75, 0.8984375, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.6875, 0.5714285714285715]\n",
            "Test -  [0.5, 0.51, 0.37499999999999994]\n",
            "\n",
            "Epoch  32\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.13476652279496193\n",
            "Train -  [0.875, 0.9140625, 0.8571428571428571]\n",
            "Validation -  [0.625, 0.6875, 0.5714285714285715]\n",
            "Test -  [0.45, 0.4, 0.15384615384615383]\n",
            "\n",
            "Epoch  33\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.10375135391950607\n",
            "Train -  [0.78125, 0.8984375, 0.7741935483870969]\n",
            "Validation -  [0.5, 0.5625, 0.5]\n",
            "Test -  [0.45, 0.47, 0.26666666666666666]\n",
            "\n",
            "Epoch  34\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.14378264918923378\n",
            "Train -  [0.78125, 0.9140625, 0.7586206896551724]\n",
            "Validation -  [0.625, 0.5, 0.6666666666666665]\n",
            "Test -  [0.55, 0.47, 0.4]\n",
            "\n",
            "Epoch  35\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.09668591246008873\n",
            "Train -  [0.84375, 0.921875, 0.8387096774193549]\n",
            "Validation -  [0.75, 0.6875, 0.75]\n",
            "Test -  [0.55, 0.59, 0.4]\n",
            "\n",
            "Epoch  36\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.08911698125302792\n",
            "Train -  [0.78125, 0.890625, 0.7586206896551724]\n",
            "Validation -  [0.625, 0.8125, 0.6666666666666665]\n",
            "Test -  [0.55, 0.5, 0.30769230769230765]\n",
            "\n",
            "Epoch  37\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.07247264869511127\n",
            "Train -  [0.75, 0.89453125, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.5625, 0.6666666666666665]\n",
            "Test -  [0.5, 0.44, 0.37499999999999994]\n",
            "\n",
            "Epoch  38\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.06603830680251122\n",
            "Train -  [0.84375, 0.890625, 0.8387096774193549]\n",
            "Validation -  [0.625, 0.5625, 0.5714285714285715]\n",
            "Test -  [0.55, 0.51, 0.4]\n",
            "\n",
            "Epoch  39\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.08228140510618687\n",
            "Train -  [0.8125, 0.90625, 0.7999999999999999]\n",
            "Validation -  [0.5, 0.5625, 0.5]\n",
            "Test -  [0.5, 0.48, 0.28571428571428575]\n",
            "\n",
            "Epoch  40\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.06791681796312332\n",
            "Train -  [0.8125, 0.92578125, 0.7999999999999999]\n",
            "Validation -  [0.5, 0.625, 0.5]\n",
            "Test -  [0.55, 0.56, 0.4]\n",
            "\n",
            "Epoch  41\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0710175409913063\n",
            "Train -  [0.8125, 0.89453125, 0.7857142857142857]\n",
            "Validation -  [0.75, 0.6875, 0.75]\n",
            "Test -  [0.5, 0.5, 0.28571428571428575]\n",
            "\n",
            "Epoch  42\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.06387396343052387\n",
            "Train -  [0.75, 0.9140625, 0.7333333333333334]\n",
            "Validation -  [0.5, 0.5625, 0.5]\n",
            "Test -  [0.45, 0.45999999999999996, 0.15384615384615383]\n",
            "\n",
            "Epoch  43\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.06702830269932747\n",
            "Train -  [0.8125, 0.90234375, 0.7857142857142857]\n",
            "Validation -  [0.25, 0.4375, 0.25]\n",
            "Test -  [0.5, 0.45000000000000007, 0.28571428571428575]\n",
            "\n",
            "Epoch  44\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.06749624386429787\n",
            "Train -  [0.8125, 0.9296875, 0.7999999999999999]\n",
            "Validation -  [0.625, 0.5, 0.6666666666666665]\n",
            "Test -  [0.55, 0.55, 0.4]\n",
            "\n",
            "Epoch  45\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.07853529416024685\n",
            "Train -  [0.8125, 0.91796875, 0.7999999999999999]\n",
            "Validation -  [0.5, 0.625, 0.6]\n",
            "Test -  [0.45, 0.48, 0.26666666666666666]\n",
            "\n",
            "Epoch  46\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.06166200339794159\n",
            "Train -  [0.78125, 0.8984375, 0.7586206896551724]\n",
            "Validation -  [0.5, 0.5, 0.5]\n",
            "Test -  [0.5, 0.37, 0.28571428571428575]\n",
            "\n",
            "Epoch  47\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.04873884655535221\n",
            "Train -  [0.78125, 0.9296875, 0.7586206896551724]\n",
            "Validation -  [0.5, 0.5625, 0.5]\n",
            "Test -  [0.5, 0.41, 0.16666666666666669]\n",
            "\n",
            "Epoch  48\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.06322083063423634\n",
            "Train -  [0.78125, 0.890625, 0.7586206896551724]\n",
            "Validation -  [0.625, 0.625, 0.6666666666666665]\n",
            "Test -  [0.45, 0.51, 0.15384615384615383]\n",
            "\n",
            "Epoch  49\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.05149226635694504\n",
            "Train -  [0.8125, 0.9296875, 0.8125]\n",
            "Validation -  [0.5, 0.625, 0.5]\n",
            "Test -  [0.5, 0.5, 0.37499999999999994]\n",
            "\n",
            "Epoch  50\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.050472691655159\n",
            "Train -  [0.8125, 0.921875, 0.7999999999999999]\n",
            "Validation -  [0.625, 0.8125, 0.6666666666666665]\n",
            "Test -  [0.5, 0.53, 0.37499999999999994]\n",
            "\n",
            "Epoch  51\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.037480538710951805\n",
            "Train -  [0.78125, 0.92578125, 0.7741935483870969]\n",
            "Validation -  [0.5, 0.5625, 0.5]\n",
            "Test -  [0.5, 0.54, 0.28571428571428575]\n",
            "\n",
            "Epoch  52\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.05470435321331024\n",
            "Train -  [0.78125, 0.9296875, 0.7586206896551724]\n",
            "Validation -  [0.5, 0.5625, 0.5]\n",
            "Test -  [0.5, 0.5700000000000001, 0.28571428571428575]\n",
            "\n",
            "Epoch  53\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.040482623502612114\n",
            "Train -  [0.78125, 0.9140625, 0.7741935483870969]\n",
            "Validation -  [0.5, 0.5, 0.5]\n",
            "Test -  [0.55, 0.6599999999999999, 0.30769230769230765]\n",
            "\n",
            "Epoch  54\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03921256586909294\n",
            "Train -  [0.84375, 0.92578125, 0.8275862068965517]\n",
            "Validation -  [0.625, 0.875, 0.6666666666666665]\n",
            "Test -  [0.45, 0.46, 0.3529411764705882]\n",
            "\n",
            "Epoch  55\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.050134267657995224\n",
            "Train -  [0.75, 0.92578125, 0.75]\n",
            "Validation -  [0.625, 0.5625, 0.6666666666666665]\n",
            "Test -  [0.6, 0.55, 0.5]\n",
            "\n",
            "Epoch  56\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.05125518888235092\n",
            "Train -  [0.78125, 0.88671875, 0.7741935483870969]\n",
            "Validation -  [0.5, 0.6875, 0.5]\n",
            "Test -  [0.45, 0.53, 0.26666666666666666]\n",
            "\n",
            "Epoch  57\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.044469356536865234\n",
            "Train -  [0.75, 0.921875, 0.75]\n",
            "Validation -  [0.5, 0.5625, 0.5]\n",
            "Test -  [0.45, 0.52, 0.3529411764705882]\n",
            "\n",
            "Epoch  58\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03861147724092007\n",
            "Train -  [0.8125, 0.9296875, 0.8125]\n",
            "Validation -  [0.625, 0.5, 0.6666666666666665]\n",
            "Test -  [0.5, 0.47, 0.28571428571428575]\n",
            "\n",
            "Epoch  59\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0285057770088315\n",
            "Train -  [0.78125, 0.91796875, 0.7741935483870969]\n",
            "Validation -  [0.375, 0.5625, 0.28571428571428575]\n",
            "Test -  [0.45, 0.51, 0.26666666666666666]\n",
            "\n",
            "Epoch  60\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.042740242555737495\n",
            "Train -  [0.75, 0.921875, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.6875, 0.6666666666666665]\n",
            "Test -  [0.5, 0.5900000000000001, 0.37499999999999994]\n",
            "\n",
            "Epoch  61\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.04210425727069378\n",
            "Train -  [0.78125, 0.921875, 0.7741935483870969]\n",
            "Validation -  [0.625, 0.75, 0.6666666666666665]\n",
            "Test -  [0.45, 0.39, 0.26666666666666666]\n",
            "\n",
            "Epoch  62\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.029605578631162643\n",
            "Train -  [0.78125, 0.90625, 0.7741935483870969]\n",
            "Validation -  [0.625, 0.5, 0.6666666666666665]\n",
            "Test -  [0.55, 0.51, 0.4]\n",
            "\n",
            "Epoch  63\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03497915342450142\n",
            "Train -  [0.78125, 0.9296875, 0.7741935483870969]\n",
            "Validation -  [0.5, 0.625, 0.5]\n",
            "Test -  [0.5, 0.5, 0.28571428571428575]\n",
            "\n",
            "Epoch  64\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.031977723352611065\n",
            "Train -  [0.8125, 0.921875, 0.7999999999999999]\n",
            "Validation -  [0.5, 0.625, 0.5]\n",
            "Test -  [0.55, 0.37, 0.30769230769230765]\n",
            "\n",
            "Epoch  65\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03376669529825449\n",
            "Train -  [0.78125, 0.91796875, 0.7586206896551724]\n",
            "Validation -  [0.5, 0.625, 0.5]\n",
            "Test -  [0.55, 0.55, 0.4]\n",
            "\n",
            "Epoch  66\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0264173224568367\n",
            "Train -  [0.78125, 0.93359375, 0.7586206896551724]\n",
            "Validation -  [0.625, 0.875, 0.6666666666666665]\n",
            "Test -  [0.55, 0.49, 0.47058823529411764]\n",
            "\n",
            "Epoch  67\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.027213665656745434\n",
            "Train -  [0.78125, 0.91796875, 0.7741935483870969]\n",
            "Validation -  [0.625, 0.5625, 0.6666666666666665]\n",
            "Test -  [0.5, 0.5499999999999999, 0.28571428571428575]\n",
            "\n",
            "Epoch  68\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03390938322991133\n",
            "Train -  [0.8125, 0.93359375, 0.7999999999999999]\n",
            "Validation -  [0.5, 0.5625, 0.5]\n",
            "Test -  [0.5, 0.4799999999999999, 0.37499999999999994]\n",
            "\n",
            "Epoch  69\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03229668736457825\n",
            "Train -  [0.78125, 0.91796875, 0.7741935483870969]\n",
            "Validation -  [0.625, 0.625, 0.6666666666666665]\n",
            "Test -  [0.5, 0.4, 0.28571428571428575]\n",
            "\n",
            "Epoch  70\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.030561831779778004\n",
            "Train -  [0.8125, 0.92578125, 0.7999999999999999]\n",
            "Validation -  [0.5, 0.5, 0.5]\n",
            "Test -  [0.65, 0.5599999999999999, 0.588235294117647]\n",
            "\n",
            "Epoch  71\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03574283793568611\n",
            "Train -  [0.78125, 0.8984375, 0.7741935483870969]\n",
            "Validation -  [0.5, 0.5625, 0.6]\n",
            "Test -  [0.5, 0.52, 0.37499999999999994]\n",
            "\n",
            "Epoch  72\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.025227881036698818\n",
            "Train -  [0.75, 0.92578125, 0.7333333333333334]\n",
            "Validation -  [0.5, 0.625, 0.5]\n",
            "Test -  [0.4, 0.44, 0.25]\n",
            "\n",
            "Epoch  73\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.028126093558967113\n",
            "Train -  [0.75, 0.91796875, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.5, 0.6666666666666665]\n",
            "Test -  [0.5, 0.53, 0.37499999999999994]\n",
            "\n",
            "Epoch  74\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01868164585903287\n",
            "Train -  [0.75, 0.92578125, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.625, 0.6666666666666665]\n",
            "Test -  [0.45, 0.54, 0.26666666666666666]\n",
            "\n",
            "Epoch  75\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.018440662417560816\n",
            "Train -  [0.8125, 0.9296875, 0.8125]\n",
            "Validation -  [0.625, 0.8125, 0.5714285714285715]\n",
            "Test -  [0.55, 0.47, 0.4]\n",
            "\n",
            "Epoch  76\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0190347321331501\n",
            "Train -  [0.75, 0.91796875, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.625, 0.6666666666666665]\n",
            "Test -  [0.55, 0.5, 0.4]\n",
            "\n",
            "Epoch  77\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.025184880942106247\n",
            "Train -  [0.75, 0.92578125, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.5625, 0.6666666666666665]\n",
            "Test -  [0.5, 0.47000000000000003, 0.4444444444444445]\n",
            "\n",
            "Epoch  78\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.022661447525024414\n",
            "Train -  [0.78125, 0.91015625, 0.7741935483870969]\n",
            "Validation -  [0.5, 0.4375, 0.5]\n",
            "Test -  [0.5, 0.52, 0.28571428571428575]\n",
            "\n",
            "Epoch  79\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.020972372964024544\n",
            "Train -  [0.8125, 0.9296875, 0.8125]\n",
            "Validation -  [0.625, 0.75, 0.6666666666666665]\n",
            "Test -  [0.55, 0.5399999999999999, 0.4]\n",
            "\n",
            "Epoch  80\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.021617398597300053\n",
            "Train -  [0.75, 0.921875, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.5625, 0.6666666666666665]\n",
            "Test -  [0.6, 0.59, 0.5]\n",
            "\n",
            "Epoch  81\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.013569987379014492\n",
            "Train -  [0.78125, 0.921875, 0.7741935483870969]\n",
            "Validation -  [0.625, 0.75, 0.6666666666666665]\n",
            "Test -  [0.5, 0.51, 0.37499999999999994]\n",
            "\n",
            "Epoch  82\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.019710027612745762\n",
            "Train -  [0.78125, 0.91015625, 0.7586206896551724]\n",
            "Validation -  [0.375, 0.5, 0.28571428571428575]\n",
            "Test -  [0.55, 0.49, 0.4]\n",
            "\n",
            "Epoch  83\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0198781150393188\n",
            "Train -  [0.8125, 0.93359375, 0.8125]\n",
            "Validation -  [0.5, 0.6875, 0.5]\n",
            "Test -  [0.55, 0.45, 0.4]\n",
            "\n",
            "Epoch  84\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.018175343051552773\n",
            "Train -  [0.78125, 0.921875, 0.7586206896551724]\n",
            "Validation -  [0.375, 0.5625, 0.4444444444444445]\n",
            "Test -  [0.55, 0.55, 0.4]\n",
            "\n",
            "Epoch  85\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.010823861695826054\n",
            "Train -  [0.75, 0.921875, 0.7333333333333334]\n",
            "Validation -  [0.5, 0.625, 0.5]\n",
            "Test -  [0.5, 0.41999999999999993, 0.28571428571428575]\n",
            "\n",
            "Epoch  86\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.014612962491810322\n",
            "Train -  [0.78125, 0.93359375, 0.7586206896551724]\n",
            "Validation -  [0.5, 0.6875, 0.5]\n",
            "Test -  [0.55, 0.48000000000000004, 0.4]\n",
            "\n",
            "Epoch  87\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.019823030102998018\n",
            "Train -  [0.8125, 0.92578125, 0.7999999999999999]\n",
            "Validation -  [0.625, 0.625, 0.6666666666666665]\n",
            "Test -  [0.55, 0.47, 0.4]\n",
            "\n",
            "Epoch  88\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.017682871781289577\n",
            "Train -  [0.75, 0.8984375, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.875, 0.6666666666666665]\n",
            "Test -  [0.55, 0.55, 0.4]\n",
            "\n",
            "Epoch  89\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01732867257669568\n",
            "Train -  [0.75, 0.92578125, 0.7333333333333334]\n",
            "Validation -  [0.5, 0.75, 0.6]\n",
            "Test -  [0.45, 0.52, 0.26666666666666666]\n",
            "\n",
            "Epoch  90\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.015646919142454863\n",
            "Train -  [0.78125, 0.89453125, 0.7741935483870969]\n",
            "Validation -  [0.5, 0.5625, 0.5]\n",
            "Test -  [0.5, 0.47, 0.28571428571428575]\n",
            "\n",
            "Epoch  91\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.012726494576781988\n",
            "Train -  [0.75, 0.90625, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.75, 0.6666666666666665]\n",
            "Test -  [0.45, 0.47, 0.26666666666666666]\n",
            "\n",
            "Epoch  92\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.013944305945187807\n",
            "Train -  [0.8125, 0.92578125, 0.7999999999999999]\n",
            "Validation -  [0.375, 0.5625, 0.28571428571428575]\n",
            "Test -  [0.55, 0.5, 0.47058823529411764]\n",
            "\n",
            "Epoch  93\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.012567244470119476\n",
            "Train -  [0.75, 0.94140625, 0.7333333333333334]\n",
            "Validation -  [0.875, 0.8125, 0.8571428571428571]\n",
            "Test -  [0.45, 0.44999999999999996, 0.26666666666666666]\n",
            "\n",
            "Epoch  94\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01957654394209385\n",
            "Train -  [0.78125, 0.921875, 0.7586206896551724]\n",
            "Validation -  [0.625, 0.75, 0.6666666666666665]\n",
            "Test -  [0.55, 0.4, 0.4]\n",
            "\n",
            "Epoch  95\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.021380319725722075\n",
            "Train -  [0.75, 0.91796875, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.6875, 0.6666666666666665]\n",
            "Test -  [0.45, 0.41, 0.26666666666666666]\n",
            "\n",
            "Epoch  96\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.016315700486302376\n",
            "Train -  [0.75, 0.921875, 0.7333333333333334]\n",
            "Validation -  [0.5, 0.625, 0.5]\n",
            "Test -  [0.55, 0.38, 0.30769230769230765]\n",
            "\n",
            "Epoch  97\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.011919163167476654\n",
            "Train -  [0.75, 0.921875, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.75, 0.6666666666666665]\n",
            "Test -  [0.6, 0.52, 0.5]\n",
            "\n",
            "Epoch  98\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.016198077704757452\n",
            "Train -  [0.75, 0.93359375, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.5, 0.6666666666666665]\n",
            "Test -  [0.4, 0.41999999999999993, 0.25]\n",
            "\n",
            "Epoch  99\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.015122190117835999\n",
            "Train -  [0.8125, 0.9140625, 0.7999999999999999]\n",
            "Validation -  [0.625, 0.625, 0.6666666666666665]\n",
            "Test -  [0.55, 0.42, 0.4]\n",
            "Epoch with best accuracy is 70\n",
            "==================================================END OF SUBJECT {idx_e_subj+1}==================================================\n",
            "Subject 18\n",
            "start_idx_train: 680\n",
            "end_idx_train: 712\n",
            "start_idx_val: 712\n",
            "end_idx_val: 720\n",
            "start_idx_eval: 340\n",
            "end_idx_eval: 360\n",
            "[1 0 0 1 0 1 1 0 0 1]\n",
            "[1 0 1 0 1 0 1 0]\n",
            "[0 1 0 1 1 0 1 0 1 0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Epoch  0\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.584201455116272\n",
            "Train -  [0.4375, 0.4296875, 0.5263157894736842]\n",
            "Validation -  [0.375, 0.1875, 0.5454545454545454]\n",
            "Test -  [0.45, 0.39, 0.56]\n",
            "\n",
            "Epoch  1\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.7054854035377502\n",
            "Train -  [0.5, 0.47265625, 0.6666666666666666]\n",
            "Validation -  [0.5, 0.25, 0.6666666666666666]\n",
            "Test -  [0.5, 0.51, 0.6666666666666666]\n",
            "\n",
            "Epoch  2\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.2798094153404236\n",
            "Train -  [0.5, 0.38671875, 0.6363636363636364]\n",
            "Validation -  [0.5, 0.6875, 0.6666666666666666]\n",
            "Test -  [0.5, 0.5599999999999999, 0.6428571428571429]\n",
            "\n",
            "Epoch  3\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.1383288502693176\n",
            "Train -  [0.53125, 0.51171875, 0.6153846153846153]\n",
            "Validation -  [0.625, 0.6875, 0.7272727272727273]\n",
            "Test -  [0.5, 0.42999999999999994, 0.5833333333333334]\n",
            "\n",
            "Epoch  4\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.0564268827438354\n",
            "Train -  [0.53125, 0.44921875, 0.6341463414634146]\n",
            "Validation -  [0.625, 0.625, 0.7272727272727273]\n",
            "Test -  [0.6, 0.53, 0.6363636363636365]\n",
            "\n",
            "Epoch  5\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.938791036605835\n",
            "Train -  [0.4375, 0.5546875, 0.5263157894736842]\n",
            "Validation -  [0.5, 0.75, 0.6666666666666666]\n",
            "Test -  [0.65, 0.75, 0.6956521739130435]\n",
            "\n",
            "Epoch  6\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.8019858300685883\n",
            "Train -  [0.65625, 0.56640625, 0.6857142857142857]\n",
            "Validation -  [0.375, 0.5, 0.5454545454545454]\n",
            "Test -  [0.4, 0.39, 0.45454545454545453]\n",
            "\n",
            "Epoch  7\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.7530816197395325\n",
            "Train -  [0.625, 0.59765625, 0.6470588235294118]\n",
            "Validation -  [0.625, 0.6875, 0.7272727272727273]\n",
            "Test -  [0.35, 0.35, 0.4347826086956522]\n",
            "\n",
            "Epoch  8\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.6240310370922089\n",
            "Train -  [0.53125, 0.640625, 0.5454545454545455]\n",
            "Validation -  [0.625, 0.625, 0.6666666666666665]\n",
            "Test -  [0.4, 0.37, 0.5]\n",
            "\n",
            "Epoch  9\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.6217228472232819\n",
            "Train -  [0.46875, 0.48828125, 0.5142857142857142]\n",
            "Validation -  [0.375, 0.125, 0.5454545454545454]\n",
            "Test -  [0.65, 0.53, 0.6666666666666666]\n",
            "\n",
            "Epoch  10\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.4862537980079651\n",
            "Train -  [0.4375, 0.4765625, 0.39999999999999997]\n",
            "Validation -  [0.5, 0.5625, 0.3333333333333333]\n",
            "Test -  [0.35, 0.22999999999999998, 0.4347826086956522]\n",
            "\n",
            "Epoch  11\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.4907078295946121\n",
            "Train -  [0.625, 0.63671875, 0.6666666666666665]\n",
            "Validation -  [0.625, 0.625, 0.6666666666666665]\n",
            "Test -  [0.5, 0.53, 0.5833333333333334]\n",
            "\n",
            "Epoch  12\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.3953486531972885\n",
            "Train -  [0.53125, 0.56640625, 0.5161290322580646]\n",
            "Validation -  [0.375, 0.4375, 0.4444444444444445]\n",
            "Test -  [0.65, 0.68, 0.5333333333333333]\n",
            "\n",
            "Epoch  13\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.4307565838098526\n",
            "Train -  [0.5625, 0.609375, 0.5625]\n",
            "Validation -  [0.875, 0.9375, 0.888888888888889]\n",
            "Test -  [0.3, 0.32999999999999996, 0.3]\n",
            "\n",
            "Epoch  14\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.2841135114431381\n",
            "Train -  [0.8125, 0.875, 0.8125]\n",
            "Validation -  [1.0, 1.0, 1.0]\n",
            "Test -  [0.5, 0.5700000000000001, 0.5]\n",
            "\n",
            "Epoch  15\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.37445247173309326\n",
            "Train -  [0.75, 0.734375, 0.75]\n",
            "Validation -  [0.875, 1.0, 0.8571428571428571]\n",
            "Test -  [0.45, 0.54, 0.4210526315789474]\n",
            "\n",
            "Epoch  16\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.30474853515625\n",
            "Train -  [0.5625, 0.65625, 0.4615384615384615]\n",
            "Validation -  [0.625, 0.75, 0.6666666666666665]\n",
            "Test -  [0.5, 0.48000000000000004, 0.5454545454545454]\n",
            "\n",
            "Epoch  17\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.27919022738933563\n",
            "Train -  [0.78125, 0.8203125, 0.7741935483870969]\n",
            "Validation -  [0.75, 0.625, 0.8]\n",
            "Test -  [0.4, 0.45000000000000007, 0.33333333333333326]\n",
            "\n",
            "Epoch  18\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.18977954238653183\n",
            "Train -  [0.71875, 0.80859375, 0.7272727272727272]\n",
            "Validation -  [0.5, 0.375, 0.5]\n",
            "Test -  [0.35, 0.39, 0.3157894736842105]\n",
            "\n",
            "Epoch  19\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.23817332088947296\n",
            "Train -  [0.8125, 0.8984375, 0.7857142857142857]\n",
            "Validation -  [0.875, 0.9375, 0.888888888888889]\n",
            "Test -  [0.45, 0.52, 0.47619047619047616]\n",
            "\n",
            "Epoch  20\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.22512836009263992\n",
            "Train -  [0.8125, 0.8984375, 0.7999999999999999]\n",
            "Validation -  [0.75, 0.8125, 0.75]\n",
            "Test -  [0.45, 0.43999999999999995, 0.4210526315789474]\n",
            "\n",
            "Epoch  21\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.18760591000318527\n",
            "Train -  [0.8125, 0.87890625, 0.8125]\n",
            "Validation -  [0.625, 0.625, 0.7272727272727273]\n",
            "Test -  [0.5, 0.38, 0.4444444444444445]\n",
            "\n",
            "Epoch  22\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.19712061434984207\n",
            "Train -  [0.875, 0.95703125, 0.875]\n",
            "Validation -  [0.5, 0.6875, 0.6]\n",
            "Test -  [0.45, 0.42000000000000004, 0.4210526315789474]\n",
            "\n",
            "Epoch  23\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.1361229196190834\n",
            "Train -  [0.78125, 0.8828125, 0.787878787878788]\n",
            "Validation -  [0.625, 0.9375, 0.7272727272727273]\n",
            "Test -  [0.5, 0.51, 0.4444444444444445]\n",
            "\n",
            "Epoch  24\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.14873246848583221\n",
            "Train -  [0.84375, 0.8828125, 0.8484848484848485]\n",
            "Validation -  [0.75, 1.0, 0.8]\n",
            "Test -  [0.45, 0.32, 0.4210526315789474]\n",
            "\n",
            "Epoch  25\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.17803861945867538\n",
            "Train -  [0.84375, 0.9296875, 0.8484848484848485]\n",
            "Validation -  [0.625, 0.5, 0.7272727272727273]\n",
            "Test -  [0.45, 0.3, 0.4210526315789474]\n",
            "\n",
            "Epoch  26\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.12945526838302612\n",
            "Train -  [0.75, 0.890625, 0.75]\n",
            "Validation -  [0.625, 0.75, 0.7272727272727273]\n",
            "Test -  [0.45, 0.38, 0.4210526315789474]\n",
            "\n",
            "Epoch  27\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.11270913481712341\n",
            "Train -  [0.75, 0.90625, 0.7333333333333334]\n",
            "Validation -  [0.75, 0.875, 0.8]\n",
            "Test -  [0.4, 0.24, 0.33333333333333326]\n",
            "\n",
            "Epoch  28\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.09804647788405418\n",
            "Train -  [0.8125, 0.89453125, 0.823529411764706]\n",
            "Validation -  [0.875, 1.0, 0.888888888888889]\n",
            "Test -  [0.4, 0.32, 0.33333333333333326]\n",
            "\n",
            "Epoch  29\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.09626441076397896\n",
            "Train -  [0.8125, 0.90234375, 0.823529411764706]\n",
            "Validation -  [0.625, 0.8125, 0.7272727272727273]\n",
            "Test -  [0.4, 0.39, 0.4000000000000001]\n",
            "\n",
            "Epoch  30\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.11073248088359833\n",
            "Train -  [0.8125, 0.890625, 0.823529411764706]\n",
            "Validation -  [0.625, 0.8125, 0.7272727272727273]\n",
            "Test -  [0.45, 0.29000000000000004, 0.4210526315789474]\n",
            "\n",
            "Epoch  31\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.09853602200746536\n",
            "Train -  [0.8125, 0.90234375, 0.823529411764706]\n",
            "Validation -  [0.625, 0.875, 0.7272727272727273]\n",
            "Test -  [0.45, 0.33, 0.4210526315789474]\n",
            "\n",
            "Epoch  32\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.09846097603440285\n",
            "Train -  [0.8125, 0.88671875, 0.823529411764706]\n",
            "Validation -  [0.625, 0.5625, 0.7272727272727273]\n",
            "Test -  [0.35, 0.36, 0.380952380952381]\n",
            "\n",
            "Epoch  33\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.08158354833722115\n",
            "Train -  [0.8125, 0.921875, 0.823529411764706]\n",
            "Validation -  [0.625, 0.75, 0.7272727272727273]\n",
            "Test -  [0.55, 0.42000000000000004, 0.5714285714285713]\n",
            "\n",
            "Epoch  34\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.08462353050708771\n",
            "Train -  [0.8125, 0.88671875, 0.823529411764706]\n",
            "Validation -  [0.625, 0.8125, 0.7272727272727273]\n",
            "Test -  [0.35, 0.30999999999999994, 0.3157894736842105]\n",
            "\n",
            "Epoch  35\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.08984246850013733\n",
            "Train -  [0.84375, 0.9140625, 0.8571428571428572]\n",
            "Validation -  [0.75, 0.9375, 0.8]\n",
            "Test -  [0.4, 0.32, 0.4000000000000001]\n",
            "\n",
            "Epoch  36\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.07637914083898067\n",
            "Train -  [0.84375, 0.90234375, 0.8484848484848485]\n",
            "Validation -  [0.75, 0.8125, 0.8]\n",
            "Test -  [0.4, 0.38, 0.4000000000000001]\n",
            "\n",
            "Epoch  37\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.07318040914833546\n",
            "Train -  [0.8125, 0.890625, 0.823529411764706]\n",
            "Validation -  [0.625, 0.9375, 0.7272727272727273]\n",
            "Test -  [0.4, 0.36, 0.4000000000000001]\n",
            "\n",
            "Epoch  38\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.05872497893869877\n",
            "Train -  [0.8125, 0.91015625, 0.8125]\n",
            "Validation -  [0.625, 0.9375, 0.7272727272727273]\n",
            "Test -  [0.45, 0.33, 0.4210526315789474]\n",
            "\n",
            "Epoch  39\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.05745832249522209\n",
            "Train -  [0.78125, 0.90625, 0.787878787878788]\n",
            "Validation -  [0.625, 0.75, 0.7272727272727273]\n",
            "Test -  [0.45, 0.39, 0.4210526315789474]\n",
            "\n",
            "Epoch  40\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.059335725381970406\n",
            "Train -  [0.8125, 0.90234375, 0.8125]\n",
            "Validation -  [0.625, 0.9375, 0.7272727272727273]\n",
            "Test -  [0.4, 0.4, 0.4000000000000001]\n",
            "\n",
            "Epoch  41\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.052867235615849495\n",
            "Train -  [0.8125, 0.9296875, 0.823529411764706]\n",
            "Validation -  [0.625, 0.875, 0.7272727272727273]\n",
            "Test -  [0.4, 0.33, 0.4000000000000001]\n",
            "\n",
            "Epoch  42\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.04811981879174709\n",
            "Train -  [0.8125, 0.8984375, 0.823529411764706]\n",
            "Validation -  [0.75, 1.0, 0.8]\n",
            "Test -  [0.4, 0.41000000000000003, 0.4000000000000001]\n",
            "\n",
            "Epoch  43\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0485074445605278\n",
            "Train -  [0.84375, 0.90625, 0.8571428571428572]\n",
            "Validation -  [0.625, 0.75, 0.7272727272727273]\n",
            "Test -  [0.5, 0.33999999999999997, 0.5454545454545454]\n",
            "\n",
            "Epoch  44\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.06034667231142521\n",
            "Train -  [0.84375, 0.91796875, 0.8571428571428572]\n",
            "Validation -  [0.75, 1.0, 0.8]\n",
            "Test -  [0.4, 0.38, 0.4000000000000001]\n",
            "\n",
            "Epoch  45\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0477437749505043\n",
            "Train -  [0.8125, 0.8828125, 0.823529411764706]\n",
            "Validation -  [0.625, 1.0, 0.7272727272727273]\n",
            "Test -  [0.45, 0.29000000000000004, 0.47619047619047616]\n",
            "\n",
            "Epoch  46\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.04612601548433304\n",
            "Train -  [0.8125, 0.9140625, 0.823529411764706]\n",
            "Validation -  [0.625, 0.9375, 0.7272727272727273]\n",
            "Test -  [0.45, 0.35, 0.47619047619047616]\n",
            "\n",
            "Epoch  47\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.04136933013796806\n",
            "Train -  [0.8125, 0.88671875, 0.823529411764706]\n",
            "Validation -  [0.625, 0.875, 0.7272727272727273]\n",
            "Test -  [0.4, 0.33, 0.4000000000000001]\n",
            "\n",
            "Epoch  48\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.050772299990057945\n",
            "Train -  [0.84375, 0.921875, 0.8484848484848485]\n",
            "Validation -  [0.75, 0.8125, 0.8]\n",
            "Test -  [0.4, 0.26, 0.4000000000000001]\n",
            "\n",
            "Epoch  49\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.047384973615407944\n",
            "Train -  [0.8125, 0.88671875, 0.823529411764706]\n",
            "Validation -  [0.625, 1.0, 0.7272727272727273]\n",
            "Test -  [0.4, 0.36, 0.4000000000000001]\n",
            "\n",
            "Epoch  50\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.041655588895082474\n",
            "Train -  [0.84375, 0.8984375, 0.8484848484848485]\n",
            "Validation -  [0.625, 1.0, 0.7272727272727273]\n",
            "Test -  [0.45, 0.31, 0.47619047619047616]\n",
            "\n",
            "Epoch  51\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.04216313920915127\n",
            "Train -  [0.78125, 0.9140625, 0.787878787878788]\n",
            "Validation -  [0.625, 0.8125, 0.7272727272727273]\n",
            "Test -  [0.45, 0.43000000000000005, 0.4210526315789474]\n",
            "\n",
            "Epoch  52\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03163308557122946\n",
            "Train -  [0.8125, 0.92578125, 0.823529411764706]\n",
            "Validation -  [0.625, 0.875, 0.7272727272727273]\n",
            "Test -  [0.4, 0.38, 0.4000000000000001]\n",
            "\n",
            "Epoch  53\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03390127420425415\n",
            "Train -  [0.8125, 0.90625, 0.823529411764706]\n",
            "Validation -  [0.625, 0.6875, 0.7272727272727273]\n",
            "Test -  [0.45, 0.4, 0.47619047619047616]\n",
            "\n",
            "Epoch  54\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.04231542348861694\n",
            "Train -  [0.875, 0.90234375, 0.8823529411764706]\n",
            "Validation -  [0.625, 1.0, 0.7272727272727273]\n",
            "Test -  [0.4, 0.39, 0.4000000000000001]\n",
            "\n",
            "Epoch  55\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03246687725186348\n",
            "Train -  [0.84375, 0.8984375, 0.8571428571428572]\n",
            "Validation -  [0.625, 0.875, 0.7272727272727273]\n",
            "Test -  [0.35, 0.38000000000000006, 0.380952380952381]\n",
            "\n",
            "Epoch  56\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03043854422867298\n",
            "Train -  [0.8125, 0.921875, 0.823529411764706]\n",
            "Validation -  [0.625, 0.875, 0.7272727272727273]\n",
            "Test -  [0.4, 0.3500000000000001, 0.4000000000000001]\n",
            "\n",
            "Epoch  57\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03304013330489397\n",
            "Train -  [0.84375, 0.9296875, 0.8484848484848485]\n",
            "Validation -  [0.625, 0.8125, 0.7272727272727273]\n",
            "Test -  [0.45, 0.37000000000000005, 0.47619047619047616]\n",
            "\n",
            "Epoch  58\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.021337011829018593\n",
            "Train -  [0.84375, 0.91796875, 0.8571428571428572]\n",
            "Validation -  [0.75, 0.9375, 0.8]\n",
            "Test -  [0.55, 0.38, 0.608695652173913]\n",
            "\n",
            "Epoch  59\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03420940041542053\n",
            "Train -  [0.875, 0.91796875, 0.8823529411764706]\n",
            "Validation -  [0.625, 1.0, 0.7272727272727273]\n",
            "Test -  [0.4, 0.44000000000000006, 0.4000000000000001]\n",
            "\n",
            "Epoch  60\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.030831600539386272\n",
            "Train -  [0.84375, 0.91015625, 0.8484848484848485]\n",
            "Validation -  [0.625, 0.9375, 0.7272727272727273]\n",
            "Test -  [0.4, 0.37, 0.4000000000000001]\n",
            "\n",
            "Epoch  61\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.029231281951069832\n",
            "Train -  [0.84375, 0.9140625, 0.8571428571428572]\n",
            "Validation -  [0.625, 0.875, 0.7272727272727273]\n",
            "Test -  [0.45, 0.34, 0.47619047619047616]\n",
            "\n",
            "Epoch  62\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.022296879440546036\n",
            "Train -  [0.84375, 0.94140625, 0.8571428571428572]\n",
            "Validation -  [0.625, 0.875, 0.7272727272727273]\n",
            "Test -  [0.4, 0.36, 0.4000000000000001]\n",
            "\n",
            "Epoch  63\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.023588339798152447\n",
            "Train -  [0.8125, 0.91796875, 0.823529411764706]\n",
            "Validation -  [0.625, 0.75, 0.7272727272727273]\n",
            "Test -  [0.45, 0.38, 0.47619047619047616]\n",
            "\n",
            "Epoch  64\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.022142828907817602\n",
            "Train -  [0.84375, 0.9140625, 0.8571428571428572]\n",
            "Validation -  [0.625, 0.875, 0.7272727272727273]\n",
            "Test -  [0.4, 0.35, 0.45454545454545453]\n",
            "\n",
            "Epoch  65\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.018254815600812435\n",
            "Train -  [0.78125, 0.92578125, 0.787878787878788]\n",
            "Validation -  [0.625, 0.8125, 0.7272727272727273]\n",
            "Test -  [0.4, 0.36000000000000004, 0.45454545454545453]\n",
            "\n",
            "Epoch  66\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.021068229340016842\n",
            "Train -  [0.8125, 0.921875, 0.823529411764706]\n",
            "Validation -  [0.625, 0.875, 0.7272727272727273]\n",
            "Test -  [0.4, 0.38, 0.4000000000000001]\n",
            "\n",
            "Epoch  67\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01837589219212532\n",
            "Train -  [0.84375, 0.9140625, 0.8571428571428572]\n",
            "Validation -  [0.75, 1.0, 0.8]\n",
            "Test -  [0.45, 0.39, 0.47619047619047616]\n",
            "\n",
            "Epoch  68\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.019165287725627422\n",
            "Train -  [0.8125, 0.91796875, 0.823529411764706]\n",
            "Validation -  [0.75, 0.875, 0.8]\n",
            "Test -  [0.45, 0.30000000000000004, 0.47619047619047616]\n",
            "\n",
            "Epoch  69\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.023838534019887447\n",
            "Train -  [0.8125, 0.9375, 0.823529411764706]\n",
            "Validation -  [0.75, 0.875, 0.8]\n",
            "Test -  [0.4, 0.36, 0.4000000000000001]\n",
            "\n",
            "Epoch  70\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.021639665588736534\n",
            "Train -  [0.84375, 0.9296875, 0.8571428571428572]\n",
            "Validation -  [0.75, 1.0, 0.8]\n",
            "Test -  [0.45, 0.37, 0.47619047619047616]\n",
            "\n",
            "Epoch  71\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.019559666514396667\n",
            "Train -  [0.84375, 0.90625, 0.8571428571428572]\n",
            "Validation -  [0.5, 0.75, 0.6666666666666666]\n",
            "Test -  [0.45, 0.39, 0.47619047619047616]\n",
            "\n",
            "Epoch  72\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.022514536045491695\n",
            "Train -  [0.8125, 0.91015625, 0.8333333333333334]\n",
            "Validation -  [0.625, 1.0, 0.7272727272727273]\n",
            "Test -  [0.4, 0.34, 0.4000000000000001]\n",
            "\n",
            "Epoch  73\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.020161554217338562\n",
            "Train -  [0.8125, 0.91796875, 0.823529411764706]\n",
            "Validation -  [0.5, 0.875, 0.6666666666666666]\n",
            "Test -  [0.45, 0.34, 0.47619047619047616]\n",
            "\n",
            "Epoch  74\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.018047870136797428\n",
            "Train -  [0.84375, 0.94140625, 0.8571428571428572]\n",
            "Validation -  [0.5, 1.0, 0.6666666666666666]\n",
            "Test -  [0.4, 0.30000000000000004, 0.4000000000000001]\n",
            "\n",
            "Epoch  75\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01730937696993351\n",
            "Train -  [0.84375, 0.90625, 0.8571428571428572]\n",
            "Validation -  [0.5, 0.9375, 0.6666666666666666]\n",
            "Test -  [0.45, 0.33999999999999997, 0.47619047619047616]\n",
            "\n",
            "Epoch  76\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.017999880947172642\n",
            "Train -  [0.84375, 0.90625, 0.8571428571428572]\n",
            "Validation -  [0.625, 1.0, 0.7272727272727273]\n",
            "Test -  [0.45, 0.39, 0.47619047619047616]\n",
            "\n",
            "Epoch  77\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.016833296976983547\n",
            "Train -  [0.84375, 0.875, 0.8571428571428572]\n",
            "Validation -  [0.625, 0.75, 0.7272727272727273]\n",
            "Test -  [0.5, 0.33999999999999997, 0.5454545454545454]\n",
            "\n",
            "Epoch  78\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.021355673670768738\n",
            "Train -  [0.84375, 0.91015625, 0.8571428571428572]\n",
            "Validation -  [0.5, 0.8125, 0.6666666666666666]\n",
            "Test -  [0.45, 0.36, 0.47619047619047616]\n",
            "\n",
            "Epoch  79\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02448407467454672\n",
            "Train -  [0.8125, 0.91015625, 0.8333333333333334]\n",
            "Validation -  [0.625, 0.875, 0.7272727272727273]\n",
            "Test -  [0.4, 0.3400000000000001, 0.45454545454545453]\n",
            "\n",
            "Epoch  80\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.017791572958230972\n",
            "Train -  [0.84375, 0.9375, 0.8571428571428572]\n",
            "Validation -  [0.625, 1.0, 0.7272727272727273]\n",
            "Test -  [0.45, 0.37, 0.47619047619047616]\n",
            "\n",
            "Epoch  81\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01768158096820116\n",
            "Train -  [0.875, 0.92578125, 0.8823529411764706]\n",
            "Validation -  [0.625, 0.6875, 0.7272727272727273]\n",
            "Test -  [0.45, 0.35, 0.47619047619047616]\n",
            "\n",
            "Epoch  82\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.018377179745584726\n",
            "Train -  [0.8125, 0.90625, 0.823529411764706]\n",
            "Validation -  [0.625, 1.0, 0.7272727272727273]\n",
            "Test -  [0.45, 0.36, 0.47619047619047616]\n",
            "\n",
            "Epoch  83\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.016162138897925615\n",
            "Train -  [0.84375, 0.90625, 0.8571428571428572]\n",
            "Validation -  [0.5, 1.0, 0.6666666666666666]\n",
            "Test -  [0.4, 0.35, 0.4000000000000001]\n",
            "\n",
            "Epoch  84\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.014979682862758636\n",
            "Train -  [0.84375, 0.90234375, 0.8571428571428572]\n",
            "Validation -  [0.625, 0.6875, 0.7272727272727273]\n",
            "Test -  [0.4, 0.35, 0.4000000000000001]\n",
            "\n",
            "Epoch  85\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.013556475285440683\n",
            "Train -  [0.84375, 0.90234375, 0.8571428571428572]\n",
            "Validation -  [0.625, 1.0, 0.7272727272727273]\n",
            "Test -  [0.4, 0.3, 0.4000000000000001]\n",
            "\n",
            "Epoch  86\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01567294215783477\n",
            "Train -  [0.84375, 0.9296875, 0.8571428571428572]\n",
            "Validation -  [0.625, 1.0, 0.7272727272727273]\n",
            "Test -  [0.35, 0.34, 0.380952380952381]\n",
            "\n",
            "Epoch  87\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.017687364015728235\n",
            "Train -  [0.8125, 0.9140625, 0.823529411764706]\n",
            "Validation -  [0.625, 1.0, 0.7272727272727273]\n",
            "Test -  [0.4, 0.30000000000000004, 0.45454545454545453]\n",
            "\n",
            "Epoch  88\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0167042575776577\n",
            "Train -  [0.84375, 0.92578125, 0.8571428571428572]\n",
            "Validation -  [0.625, 0.625, 0.7272727272727273]\n",
            "Test -  [0.45, 0.35000000000000003, 0.47619047619047616]\n",
            "\n",
            "Epoch  89\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.012884386349469423\n",
            "Train -  [0.84375, 0.9375, 0.8571428571428572]\n",
            "Validation -  [0.625, 0.625, 0.7272727272727273]\n",
            "Test -  [0.45, 0.34, 0.47619047619047616]\n",
            "\n",
            "Epoch  90\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01477379398420453\n",
            "Train -  [0.8125, 0.9296875, 0.823529411764706]\n",
            "Validation -  [0.625, 1.0, 0.7272727272727273]\n",
            "Test -  [0.45, 0.28, 0.47619047619047616]\n",
            "\n",
            "Epoch  91\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.011436216533184052\n",
            "Train -  [0.78125, 0.875, 0.7999999999999999]\n",
            "Validation -  [0.625, 0.9375, 0.7272727272727273]\n",
            "Test -  [0.5, 0.37, 0.5454545454545454]\n",
            "\n",
            "Epoch  92\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.014779435005038977\n",
            "Train -  [0.84375, 0.8984375, 0.8571428571428572]\n",
            "Validation -  [0.5, 1.0, 0.6666666666666666]\n",
            "Test -  [0.45, 0.31000000000000005, 0.47619047619047616]\n",
            "\n",
            "Epoch  93\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.012407534755766392\n",
            "Train -  [0.8125, 0.92578125, 0.823529411764706]\n",
            "Validation -  [0.75, 0.9375, 0.8]\n",
            "Test -  [0.4, 0.36, 0.4000000000000001]\n",
            "\n",
            "Epoch  94\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.009417068678885698\n",
            "Train -  [0.84375, 0.90625, 0.8571428571428572]\n",
            "Validation -  [0.625, 1.0, 0.7272727272727273]\n",
            "Test -  [0.45, 0.31000000000000005, 0.47619047619047616]\n",
            "\n",
            "Epoch  95\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.009152759797871113\n",
            "Train -  [0.84375, 0.92578125, 0.8571428571428572]\n",
            "Validation -  [0.625, 0.8125, 0.7272727272727273]\n",
            "Test -  [0.4, 0.3, 0.45454545454545453]\n",
            "\n",
            "Epoch  96\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01106286933645606\n",
            "Train -  [0.8125, 0.91015625, 0.823529411764706]\n",
            "Validation -  [0.625, 0.9375, 0.7272727272727273]\n",
            "Test -  [0.4, 0.27, 0.4000000000000001]\n",
            "\n",
            "Epoch  97\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.016057554632425308\n",
            "Train -  [0.8125, 0.91796875, 0.8333333333333334]\n",
            "Validation -  [0.625, 0.6875, 0.7272727272727273]\n",
            "Test -  [0.45, 0.41000000000000003, 0.47619047619047616]\n",
            "\n",
            "Epoch  98\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.010649357922375202\n",
            "Train -  [0.84375, 0.93359375, 0.8571428571428572]\n",
            "Validation -  [0.625, 1.0, 0.7272727272727273]\n",
            "Test -  [0.35, 0.29, 0.380952380952381]\n",
            "\n",
            "Epoch  99\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.011261975858360529\n",
            "Train -  [0.8125, 0.94921875, 0.8333333333333334]\n",
            "Validation -  [0.625, 0.8125, 0.7272727272727273]\n",
            "Test -  [0.5, 0.42000000000000004, 0.5454545454545454]\n",
            "Epoch with best accuracy is 5\n",
            "==================================================END OF SUBJECT {idx_e_subj+1}==================================================\n",
            "Subject 19\n",
            "start_idx_train: 720\n",
            "end_idx_train: 752\n",
            "start_idx_val: 752\n",
            "end_idx_val: 760\n",
            "start_idx_eval: 360\n",
            "end_idx_eval: 380\n",
            "[1 0 1 0 1 0 0 1 1 0]\n",
            "[0 1 1 0 0 1 0 1]\n",
            "[0 1 0 1 1 0 1 0 1 0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Epoch  0\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  2.17100065946579\n",
            "Train -  [0.53125, 0.62890625, 0.6666666666666667]\n",
            "Validation -  [0.625, 0.6875, 0.7272727272727273]\n",
            "Test -  [0.55, 0.51, 0.6666666666666667]\n",
            "\n",
            "Epoch  1\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.802800476551056\n",
            "Train -  [0.5625, 0.57421875, 0.6111111111111112]\n",
            "Validation -  [0.625, 0.5625, 0.7272727272727273]\n",
            "Test -  [0.45, 0.51, 0.5925925925925927]\n",
            "\n",
            "Epoch  2\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.5388543009757996\n",
            "Train -  [0.65625, 0.67578125, 0.717948717948718]\n",
            "Validation -  [0.375, 0.4375, 0.5454545454545454]\n",
            "Test -  [0.6, 0.63, 0.6666666666666666]\n",
            "\n",
            "Epoch  3\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.4252365231513977\n",
            "Train -  [0.5625, 0.4765625, 0.5625]\n",
            "Validation -  [0.25, 0.125, 0.4]\n",
            "Test -  [0.4, 0.41999999999999993, 0.4000000000000001]\n",
            "\n",
            "Epoch  4\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.1655816733837128\n",
            "Train -  [0.46875, 0.578125, 0.41379310344827586]\n",
            "Validation -  [0.5, 0.75, 0.6]\n",
            "Test -  [0.45, 0.47, 0.47619047619047616]\n",
            "\n",
            "Epoch  5\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.1602219939231873\n",
            "Train -  [0.5625, 0.57421875, 0.5333333333333333]\n",
            "Validation -  [0.375, 0.1875, 0.5454545454545454]\n",
            "Test -  [0.65, 0.6300000000000001, 0.6956521739130435]\n",
            "\n",
            "Epoch  6\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.0233858823776245\n",
            "Train -  [0.53125, 0.546875, 0.5454545454545455]\n",
            "Validation -  [0.625, 0.75, 0.5714285714285715]\n",
            "Test -  [0.55, 0.43, 0.64]\n",
            "\n",
            "Epoch  7\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.7665161490440369\n",
            "Train -  [0.5, 0.546875, 0.6]\n",
            "Validation -  [0.875, 0.9375, 0.888888888888889]\n",
            "Test -  [0.45, 0.4599999999999999, 0.47619047619047616]\n",
            "\n",
            "Epoch  8\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.7186206877231598\n",
            "Train -  [0.40625, 0.48828125, 0.5128205128205128]\n",
            "Validation -  [0.75, 0.875, 0.8]\n",
            "Test -  [0.35, 0.27, 0.380952380952381]\n",
            "\n",
            "Epoch  9\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.6045690476894379\n",
            "Train -  [0.40625, 0.30859375, 0.5128205128205128]\n",
            "Validation -  [0.625, 0.4375, 0.7272727272727273]\n",
            "Test -  [0.5, 0.48, 0.6153846153846154]\n",
            "\n",
            "Epoch  10\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.6262372732162476\n",
            "Train -  [0.53125, 0.6640625, 0.6153846153846153]\n",
            "Validation -  [0.5, 0.5, 0.6666666666666666]\n",
            "Test -  [0.5, 0.52, 0.6153846153846154]\n",
            "\n",
            "Epoch  11\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.5010331124067307\n",
            "Train -  [0.5, 0.54296875, 0.6363636363636364]\n",
            "Validation -  [0.375, 0.375, 0.5454545454545454]\n",
            "Test -  [0.5, 0.54, 0.6428571428571429]\n",
            "\n",
            "Epoch  12\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.5110086500644684\n",
            "Train -  [0.625, 0.69140625, 0.7142857142857143]\n",
            "Validation -  [0.5, 0.375, 0.6666666666666666]\n",
            "Test -  [0.5, 0.38999999999999996, 0.6428571428571429]\n",
            "\n",
            "Epoch  13\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.40909239649772644\n",
            "Train -  [0.53125, 0.83203125, 0.6808510638297872]\n",
            "Validation -  [0.5, 0.25, 0.6666666666666666]\n",
            "Test -  [0.45, 0.38, 0.6206896551724138]\n",
            "\n",
            "Epoch  14\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.3882743716239929\n",
            "Train -  [0.59375, 0.90234375, 0.7111111111111111]\n",
            "Validation -  [0.5, 0.625, 0.6666666666666666]\n",
            "Test -  [0.5, 0.27, 0.6666666666666666]\n",
            "\n",
            "Epoch  15\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.3285239040851593\n",
            "Train -  [0.5625, 0.62890625, 0.6956521739130436]\n",
            "Validation -  [0.5, 0.75, 0.6666666666666666]\n",
            "Test -  [0.5, 0.3, 0.6666666666666666]\n",
            "\n",
            "Epoch  16\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.26559023559093475\n",
            "Train -  [0.5, 0.74609375, 0.6666666666666666]\n",
            "Validation -  [0.5, 0.8125, 0.6666666666666666]\n",
            "Test -  [0.5, 0.48, 0.6666666666666666]\n",
            "\n",
            "Epoch  17\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.2784443199634552\n",
            "Train -  [0.53125, 0.96484375, 0.6808510638297872]\n",
            "Validation -  [0.5, 0.6875, 0.6666666666666666]\n",
            "Test -  [0.5, 0.33, 0.6666666666666666]\n",
            "\n",
            "Epoch  18\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.21563565731048584\n",
            "Train -  [0.5, 0.81640625, 0.6666666666666666]\n",
            "Validation -  [0.5, 0.75, 0.6666666666666666]\n",
            "Test -  [0.5, 0.4099999999999999, 0.6666666666666666]\n",
            "\n",
            "Epoch  19\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.22232183068990707\n",
            "Train -  [0.5, 0.93359375, 0.6666666666666666]\n",
            "Validation -  [0.5, 0.625, 0.6666666666666666]\n",
            "Test -  [0.5, 0.2, 0.6666666666666666]\n",
            "\n",
            "Epoch  20\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.18669556826353073\n",
            "Train -  [0.5, 0.88671875, 0.6666666666666666]\n",
            "Validation -  [0.5, 0.8125, 0.6666666666666666]\n",
            "Test -  [0.5, 0.39, 0.6666666666666666]\n",
            "\n",
            "Epoch  21\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.20308701694011688\n",
            "Train -  [0.5625, 0.9375, 0.6956521739130436]\n",
            "Validation -  [0.5, 0.8125, 0.6666666666666666]\n",
            "Test -  [0.5, 0.29, 0.6666666666666666]\n",
            "\n",
            "Epoch  22\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.15703951567411423\n",
            "Train -  [0.59375, 0.953125, 0.7111111111111111]\n",
            "Validation -  [0.625, 0.75, 0.7272727272727273]\n",
            "Test -  [0.5, 0.26, 0.6666666666666666]\n",
            "\n",
            "Epoch  23\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.13374511525034904\n",
            "Train -  [0.65625, 0.9296875, 0.7441860465116279]\n",
            "Validation -  [0.5, 0.5625, 0.6666666666666666]\n",
            "Test -  [0.45, 0.32, 0.6206896551724138]\n",
            "\n",
            "Epoch  24\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.13759082555770874\n",
            "Train -  [0.5625, 0.96484375, 0.6956521739130436]\n",
            "Validation -  [0.5, 0.625, 0.6666666666666666]\n",
            "Test -  [0.4, 0.28, 0.5714285714285714]\n",
            "\n",
            "Epoch  25\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.12860025092959404\n",
            "Train -  [0.625, 0.94921875, 0.7272727272727273]\n",
            "Validation -  [0.5, 0.5, 0.6666666666666666]\n",
            "Test -  [0.4, 0.29999999999999993, 0.5714285714285714]\n",
            "\n",
            "Epoch  26\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.13276097923517227\n",
            "Train -  [0.6875, 0.9609375, 0.761904761904762]\n",
            "Validation -  [0.5, 0.625, 0.6666666666666666]\n",
            "Test -  [0.4, 0.32, 0.5384615384615384]\n",
            "\n",
            "Epoch  27\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.10554135590791702\n",
            "Train -  [0.75, 0.95703125, 0.7894736842105263]\n",
            "Validation -  [0.5, 0.4375, 0.6666666666666666]\n",
            "Test -  [0.35, 0.31, 0.5185185185185185]\n",
            "\n",
            "Epoch  28\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.09937649592757225\n",
            "Train -  [0.84375, 0.96484375, 0.8648648648648648]\n",
            "Validation -  [0.625, 0.8125, 0.7272727272727273]\n",
            "Test -  [0.35, 0.33999999999999997, 0.48]\n",
            "\n",
            "Epoch  29\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.08630219474434853\n",
            "Train -  [0.90625, 0.984375, 0.9142857142857143]\n",
            "Validation -  [0.75, 0.8125, 0.8]\n",
            "Test -  [0.4, 0.31000000000000005, 0.5]\n",
            "\n",
            "Epoch  30\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.08959158137440681\n",
            "Train -  [0.875, 0.96484375, 0.888888888888889]\n",
            "Validation -  [0.5, 0.625, 0.6]\n",
            "Test -  [0.3, 0.35, 0.41666666666666663]\n",
            "\n",
            "Epoch  31\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.062415340915322304\n",
            "Train -  [0.875, 0.97265625, 0.8823529411764706]\n",
            "Validation -  [0.5, 0.625, 0.5]\n",
            "Test -  [0.35, 0.27, 0.48]\n",
            "\n",
            "Epoch  32\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.07533079758286476\n",
            "Train -  [0.9375, 0.984375, 0.9411764705882353]\n",
            "Validation -  [0.5, 0.625, 0.5]\n",
            "Test -  [0.35, 0.39, 0.4347826086956522]\n",
            "\n",
            "Epoch  33\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.06767593510448933\n",
            "Train -  [0.9375, 0.9609375, 0.9411764705882353]\n",
            "Validation -  [0.375, 0.5625, 0.28571428571428575]\n",
            "Test -  [0.35, 0.32999999999999996, 0.4347826086956522]\n",
            "\n",
            "Epoch  34\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.07143425941467285\n",
            "Train -  [0.90625, 0.9609375, 0.9090909090909091]\n",
            "Validation -  [0.5, 0.5, 0.3333333333333333]\n",
            "Test -  [0.3, 0.31999999999999995, 0.3636363636363636]\n",
            "\n",
            "Epoch  35\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.050556058064103127\n",
            "Train -  [0.90625, 0.97265625, 0.9090909090909091]\n",
            "Validation -  [0.75, 0.75, 0.75]\n",
            "Test -  [0.35, 0.27, 0.380952380952381]\n",
            "\n",
            "Epoch  36\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.06095769628882408\n",
            "Train -  [0.84375, 0.953125, 0.8387096774193549]\n",
            "Validation -  [0.75, 0.6875, 0.75]\n",
            "Test -  [0.45, 0.37, 0.47619047619047616]\n",
            "\n",
            "Epoch  37\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.048308227211236954\n",
            "Train -  [0.875, 0.953125, 0.875]\n",
            "Validation -  [0.625, 0.75, 0.5714285714285715]\n",
            "Test -  [0.4, 0.36, 0.4000000000000001]\n",
            "\n",
            "Epoch  38\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.04981010593473911\n",
            "Train -  [0.875, 0.9765625, 0.875]\n",
            "Validation -  [0.625, 0.8125, 0.5714285714285715]\n",
            "Test -  [0.4, 0.32, 0.4000000000000001]\n",
            "\n",
            "Epoch  39\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.04977403208613396\n",
            "Train -  [0.875, 0.96875, 0.8666666666666666]\n",
            "Validation -  [0.5, 0.75, 0.3333333333333333]\n",
            "Test -  [0.45, 0.32999999999999996, 0.26666666666666666]\n",
            "\n",
            "Epoch  40\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.050484754145145416\n",
            "Train -  [0.875, 0.97265625, 0.8666666666666666]\n",
            "Validation -  [0.625, 0.75, 0.5714285714285715]\n",
            "Test -  [0.35, 0.28, 0.3157894736842105]\n",
            "\n",
            "Epoch  41\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.041515229269862175\n",
            "Train -  [0.84375, 0.97265625, 0.8275862068965517]\n",
            "Validation -  [0.625, 0.5625, 0.4]\n",
            "Test -  [0.35, 0.27, 0.23529411764705882]\n",
            "\n",
            "Epoch  42\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0417365413159132\n",
            "Train -  [0.78125, 0.9609375, 0.7586206896551724]\n",
            "Validation -  [0.75, 0.6875, 0.6666666666666666]\n",
            "Test -  [0.3, 0.33, 0.22222222222222224]\n",
            "\n",
            "Epoch  43\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.035385940223932266\n",
            "Train -  [0.84375, 0.95703125, 0.8387096774193549]\n",
            "Validation -  [0.625, 0.5625, 0.4]\n",
            "Test -  [0.45, 0.32000000000000006, 0.3529411764705882]\n",
            "\n",
            "Epoch  44\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03693951107561588\n",
            "Train -  [0.8125, 0.96484375, 0.7999999999999999]\n",
            "Validation -  [0.625, 0.6875, 0.4]\n",
            "Test -  [0.4, 0.36, 0.33333333333333326]\n",
            "\n",
            "Epoch  45\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03723732382059097\n",
            "Train -  [0.84375, 0.95703125, 0.8387096774193549]\n",
            "Validation -  [0.625, 0.75, 0.4]\n",
            "Test -  [0.45, 0.27, 0.3529411764705882]\n",
            "\n",
            "Epoch  46\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03132240008562803\n",
            "Train -  [0.8125, 0.96484375, 0.7999999999999999]\n",
            "Validation -  [0.625, 0.8125, 0.4]\n",
            "Test -  [0.45, 0.35, 0.26666666666666666]\n",
            "\n",
            "Epoch  47\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.035111114382743835\n",
            "Train -  [0.8125, 0.95703125, 0.7857142857142857]\n",
            "Validation -  [0.75, 0.8125, 0.6666666666666666]\n",
            "Test -  [0.35, 0.28, 0.23529411764705882]\n",
            "\n",
            "Epoch  48\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03231827635318041\n",
            "Train -  [0.875, 0.95703125, 0.8666666666666666]\n",
            "Validation -  [0.625, 0.8125, 0.4]\n",
            "Test -  [0.55, 0.37, 0.4]\n",
            "\n",
            "Epoch  49\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03139681555330753\n",
            "Train -  [0.8125, 0.95703125, 0.7999999999999999]\n",
            "Validation -  [0.625, 0.6875, 0.4]\n",
            "Test -  [0.45, 0.33, 0.26666666666666666]\n",
            "\n",
            "Epoch  50\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02280275896191597\n",
            "Train -  [0.84375, 0.9765625, 0.8387096774193549]\n",
            "Validation -  [0.625, 0.5625, 0.4]\n",
            "Test -  [0.35, 0.29000000000000004, 0.23529411764705882]\n",
            "\n",
            "Epoch  51\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03157459292560816\n",
            "Train -  [0.8125, 0.9609375, 0.7857142857142857]\n",
            "Validation -  [0.625, 0.6875, 0.4]\n",
            "Test -  [0.45, 0.36, 0.26666666666666666]\n",
            "\n",
            "Epoch  52\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03359865862876177\n",
            "Train -  [0.875, 0.97265625, 0.8666666666666666]\n",
            "Validation -  [0.625, 0.75, 0.4]\n",
            "Test -  [0.4, 0.35, 0.25]\n",
            "\n",
            "Epoch  53\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.024565893225371838\n",
            "Train -  [0.84375, 0.95703125, 0.8387096774193549]\n",
            "Validation -  [0.5, 0.625, nan]\n",
            "Test -  [0.4, 0.30000000000000004, 0.4000000000000001]\n",
            "\n",
            "Epoch  54\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02309187315404415\n",
            "Train -  [0.84375, 0.95703125, 0.8275862068965517]\n",
            "Validation -  [0.625, 0.625, 0.4]\n",
            "Test -  [0.45, 0.32, 0.26666666666666666]\n",
            "\n",
            "Epoch  55\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02415859792381525\n",
            "Train -  [0.84375, 0.9609375, 0.8275862068965517]\n",
            "Validation -  [0.625, 0.625, 0.4]\n",
            "Test -  [0.4, 0.32, 0.25]\n",
            "\n",
            "Epoch  56\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.028463547118008137\n",
            "Train -  [0.84375, 0.953125, 0.8387096774193549]\n",
            "Validation -  [0.625, 0.5625, 0.4]\n",
            "Test -  [0.35, 0.35000000000000003, 0.23529411764705882]\n",
            "\n",
            "Epoch  57\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.022146856412291527\n",
            "Train -  [0.84375, 0.9765625, 0.8387096774193549]\n",
            "Validation -  [0.625, 0.75, 0.4]\n",
            "Test -  [0.35, 0.31000000000000005, 0.23529411764705882]\n",
            "\n",
            "Epoch  58\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.020225688815116882\n",
            "Train -  [0.8125, 0.97265625, 0.7857142857142857]\n",
            "Validation -  [0.5, 0.5625, 0.3333333333333333]\n",
            "Test -  [0.5, 0.28, 0.28571428571428575]\n",
            "\n",
            "Epoch  59\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.024074804037809372\n",
            "Train -  [0.84375, 0.9765625, 0.8275862068965517]\n",
            "Validation -  [0.625, 0.5, 0.4]\n",
            "Test -  [0.35, 0.33999999999999997, 0.23529411764705882]\n",
            "\n",
            "Epoch  60\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.021034223027527332\n",
            "Train -  [0.8125, 0.9609375, 0.7999999999999999]\n",
            "Validation -  [0.625, 0.625, 0.4]\n",
            "Test -  [0.45, 0.37, 0.26666666666666666]\n",
            "\n",
            "Epoch  61\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.024686990305781364\n",
            "Train -  [0.84375, 0.9609375, 0.8275862068965517]\n",
            "Validation -  [0.625, 0.75, 0.4]\n",
            "Test -  [0.45, 0.33999999999999997, 0.26666666666666666]\n",
            "\n",
            "Epoch  62\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.021216019988059998\n",
            "Train -  [0.84375, 0.96484375, 0.8275862068965517]\n",
            "Validation -  [0.625, 0.5625, 0.4]\n",
            "Test -  [0.45, 0.41000000000000003, 0.26666666666666666]\n",
            "\n",
            "Epoch  63\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.019612174946814775\n",
            "Train -  [0.78125, 0.95703125, 0.7586206896551724]\n",
            "Validation -  [0.625, 0.6875, 0.4]\n",
            "Test -  [0.4, 0.30000000000000004, 0.25]\n",
            "\n",
            "Epoch  64\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.024655401706695557\n",
            "Train -  [0.8125, 0.9453125, 0.7999999999999999]\n",
            "Validation -  [0.625, 0.6875, 0.4]\n",
            "Test -  [0.5, 0.41000000000000003, 0.37499999999999994]\n",
            "\n",
            "Epoch  65\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02424659486860037\n",
            "Train -  [0.84375, 0.953125, 0.8275862068965517]\n",
            "Validation -  [0.5, 0.625, 0.3333333333333333]\n",
            "Test -  [0.4, 0.37, 0.25]\n",
            "\n",
            "Epoch  66\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01912516914308071\n",
            "Train -  [0.875, 0.97265625, 0.8666666666666666]\n",
            "Validation -  [0.625, 0.6875, 0.4]\n",
            "Test -  [0.45, 0.29, 0.3529411764705882]\n",
            "\n",
            "Epoch  67\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.015295916702598333\n",
            "Train -  [0.84375, 0.953125, 0.8387096774193549]\n",
            "Validation -  [0.625, 0.5625, 0.4]\n",
            "Test -  [0.5, 0.36, 0.28571428571428575]\n",
            "\n",
            "Epoch  68\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02558898739516735\n",
            "Train -  [0.8125, 0.9609375, 0.7999999999999999]\n",
            "Validation -  [0.75, 0.75, 0.6666666666666666]\n",
            "Test -  [0.4, 0.30000000000000004, 0.25]\n",
            "\n",
            "Epoch  69\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.014283822383731604\n",
            "Train -  [0.8125, 0.9765625, 0.7857142857142857]\n",
            "Validation -  [0.5, 0.75, nan]\n",
            "Test -  [0.4, 0.32999999999999996, 0.14285714285714288]\n",
            "\n",
            "Epoch  70\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.016536124050617218\n",
            "Train -  [0.84375, 0.953125, 0.8275862068965517]\n",
            "Validation -  [0.5, 0.6875, 0.3333333333333333]\n",
            "Test -  [0.45, 0.44, 0.26666666666666666]\n",
            "\n",
            "Epoch  71\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.014142239931970835\n",
            "Train -  [0.875, 0.96875, 0.8571428571428571]\n",
            "Validation -  [0.625, 0.6875, 0.4]\n",
            "Test -  [0.45, 0.32, 0.26666666666666666]\n",
            "\n",
            "Epoch  72\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.019003162160515785\n",
            "Train -  [0.8125, 0.9765625, 0.7857142857142857]\n",
            "Validation -  [0.625, 0.625, 0.4]\n",
            "Test -  [0.35, 0.35, 0.23529411764705882]\n",
            "\n",
            "Epoch  73\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02022621128708124\n",
            "Train -  [0.8125, 0.95703125, 0.7999999999999999]\n",
            "Validation -  [0.75, 0.5625, 0.6666666666666666]\n",
            "Test -  [0.4, 0.38, 0.25]\n",
            "\n",
            "Epoch  74\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.015206227544695139\n",
            "Train -  [0.78125, 0.95703125, 0.7586206896551724]\n",
            "Validation -  [0.625, 0.6875, 0.4]\n",
            "Test -  [0.5, 0.38, 0.28571428571428575]\n",
            "\n",
            "Epoch  75\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0208127498626709\n",
            "Train -  [0.78125, 0.9609375, 0.7586206896551724]\n",
            "Validation -  [0.625, 0.625, 0.4]\n",
            "Test -  [0.5, 0.37, 0.4444444444444445]\n",
            "\n",
            "Epoch  76\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01562993135303259\n",
            "Train -  [0.84375, 0.95703125, 0.8148148148148148]\n",
            "Validation -  [0.625, 0.625, 0.4]\n",
            "Test -  [0.5, 0.36, 0.28571428571428575]\n",
            "\n",
            "Epoch  77\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01711524138227105\n",
            "Train -  [0.8125, 0.9609375, 0.7857142857142857]\n",
            "Validation -  [0.5, 0.6875, nan]\n",
            "Test -  [0.5, 0.37, 0.28571428571428575]\n",
            "\n",
            "Epoch  78\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.012696488294750452\n",
            "Train -  [0.78125, 0.95703125, 0.7586206896551724]\n",
            "Validation -  [0.625, 0.75, 0.4]\n",
            "Test -  [0.4, 0.32999999999999996, 0.25]\n",
            "\n",
            "Epoch  79\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.015758430119603872\n",
            "Train -  [0.84375, 0.97265625, 0.8275862068965517]\n",
            "Validation -  [0.625, 0.8125, 0.4]\n",
            "Test -  [0.4, 0.39, 0.25]\n",
            "\n",
            "Epoch  80\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.012419085018336773\n",
            "Train -  [0.84375, 0.96875, 0.8275862068965517]\n",
            "Validation -  [0.625, 0.6875, 0.4]\n",
            "Test -  [0.4, 0.36, 0.25]\n",
            "\n",
            "Epoch  81\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.014596106950193644\n",
            "Train -  [0.8125, 0.96875, 0.7857142857142857]\n",
            "Validation -  [0.625, 0.625, 0.4]\n",
            "Test -  [0.5, 0.38, 0.37499999999999994]\n",
            "\n",
            "Epoch  82\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0103215416893363\n",
            "Train -  [0.90625, 0.96484375, 0.896551724137931]\n",
            "Validation -  [0.75, 0.8125, 0.6666666666666666]\n",
            "Test -  [0.5, 0.39999999999999997, 0.28571428571428575]\n",
            "\n",
            "Epoch  83\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01194808492437005\n",
            "Train -  [0.78125, 0.953125, 0.7586206896551724]\n",
            "Validation -  [0.625, 0.75, 0.4]\n",
            "Test -  [0.45, 0.36, 0.3529411764705882]\n",
            "\n",
            "Epoch  84\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.015769705176353455\n",
            "Train -  [0.8125, 0.95703125, 0.7999999999999999]\n",
            "Validation -  [0.5, 0.5625, nan]\n",
            "Test -  [0.4, 0.35, 0.25]\n",
            "\n",
            "Epoch  85\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.011626692488789558\n",
            "Train -  [0.875, 0.96484375, 0.8666666666666666]\n",
            "Validation -  [0.5, 0.6875, 0.3333333333333333]\n",
            "Test -  [0.45, 0.30000000000000004, 0.26666666666666666]\n",
            "\n",
            "Epoch  86\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.011591142509132624\n",
            "Train -  [0.875, 0.96875, 0.8666666666666666]\n",
            "Validation -  [0.625, 0.625, 0.4]\n",
            "Test -  [0.4, 0.36, 0.33333333333333326]\n",
            "\n",
            "Epoch  87\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.012471222784370184\n",
            "Train -  [0.78125, 0.9609375, 0.7586206896551724]\n",
            "Validation -  [0.625, 0.75, 0.4]\n",
            "Test -  [0.45, 0.33999999999999997, 0.3529411764705882]\n",
            "\n",
            "Epoch  88\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.012281553819775581\n",
            "Train -  [0.84375, 0.96484375, 0.8387096774193549]\n",
            "Validation -  [0.625, 0.625, 0.4]\n",
            "Test -  [0.4, 0.38, 0.25]\n",
            "\n",
            "Epoch  89\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.009606998413801193\n",
            "Train -  [0.84375, 0.97265625, 0.8275862068965517]\n",
            "Validation -  [0.625, 0.625, 0.4]\n",
            "Test -  [0.45, 0.35, 0.3529411764705882]\n",
            "\n",
            "Epoch  90\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.010442541912198067\n",
            "Train -  [0.8125, 0.95703125, 0.7857142857142857]\n",
            "Validation -  [0.75, 0.6875, 0.6666666666666666]\n",
            "Test -  [0.45, 0.33, 0.26666666666666666]\n",
            "\n",
            "Epoch  91\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.011215891223400831\n",
            "Train -  [0.8125, 0.953125, 0.7857142857142857]\n",
            "Validation -  [0.625, 0.6875, 0.4]\n",
            "Test -  [0.5, 0.35, 0.4444444444444445]\n",
            "\n",
            "Epoch  92\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.011381836608052254\n",
            "Train -  [0.8125, 0.9609375, 0.7999999999999999]\n",
            "Validation -  [0.625, 0.5, 0.4]\n",
            "Test -  [0.4, 0.41, 0.25]\n",
            "\n",
            "Epoch  93\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.011730669531971216\n",
            "Train -  [0.84375, 0.97265625, 0.8275862068965517]\n",
            "Validation -  [0.625, 0.6875, 0.4]\n",
            "Test -  [0.4, 0.35, 0.25]\n",
            "\n",
            "Epoch  94\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.008025250630453229\n",
            "Train -  [0.84375, 0.96875, 0.8275862068965517]\n",
            "Validation -  [0.625, 0.5625, 0.4]\n",
            "Test -  [0.5, 0.4, 0.37499999999999994]\n",
            "\n",
            "Epoch  95\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.009812232572585344\n",
            "Train -  [0.84375, 0.96875, 0.8275862068965517]\n",
            "Validation -  [0.625, 0.5625, 0.4]\n",
            "Test -  [0.45, 0.36, 0.3529411764705882]\n",
            "\n",
            "Epoch  96\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.010958387982100248\n",
            "Train -  [0.8125, 0.9609375, 0.7999999999999999]\n",
            "Validation -  [0.625, 0.625, 0.4]\n",
            "Test -  [0.5, 0.43000000000000005, 0.4444444444444445]\n",
            "\n",
            "Epoch  97\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01000510435551405\n",
            "Train -  [0.84375, 0.96484375, 0.8275862068965517]\n",
            "Validation -  [0.625, 0.625, 0.4]\n",
            "Test -  [0.45, 0.33999999999999997, 0.3529411764705882]\n",
            "\n",
            "Epoch  98\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.011654374189674854\n",
            "Train -  [0.8125, 0.96484375, 0.7857142857142857]\n",
            "Validation -  [0.75, 0.75, 0.6666666666666666]\n",
            "Test -  [0.45, 0.37, 0.26666666666666666]\n",
            "\n",
            "Epoch  99\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.009746159426867962\n",
            "Train -  [0.84375, 0.97265625, 0.8275862068965517]\n",
            "Validation -  [0.5, 0.625, nan]\n",
            "Test -  [0.35, 0.35, 0.23529411764705882]\n",
            "Epoch with best accuracy is 5\n",
            "==================================================END OF SUBJECT {idx_e_subj+1}==================================================\n",
            "Subject 20\n",
            "start_idx_train: 760\n",
            "end_idx_train: 792\n",
            "start_idx_val: 792\n",
            "end_idx_val: 800\n",
            "start_idx_eval: 380\n",
            "end_idx_eval: 400\n",
            "[1 0 1 0 0 1 0 1 1 0]\n",
            "[0 1 1 0 0 1 0 1]\n",
            "[0 1 0 1 1 0 1 0 1 0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Epoch  0\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.543098509311676\n",
            "Train -  [0.5, 0.44140625, nan]\n",
            "Validation -  [0.5, 0.5625, nan]\n",
            "Test -  [0.5, 0.22999999999999998, nan]\n",
            "\n",
            "Epoch  1\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.3872125744819641\n",
            "Train -  [0.5, 0.62109375, nan]\n",
            "Validation -  [0.5, 0.1875, nan]\n",
            "Test -  [0.5, 0.28, nan]\n",
            "\n",
            "Epoch  2\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.1828863024711609\n",
            "Train -  [0.5, 0.55078125, nan]\n",
            "Validation -  [0.5, 0.625, nan]\n",
            "Test -  [0.5, 0.6799999999999999, nan]\n",
            "\n",
            "Epoch  3\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.1105594038963318\n",
            "Train -  [0.5, 0.515625, nan]\n",
            "Validation -  [0.5, 0.375, nan]\n",
            "Test -  [0.5, 0.23, nan]\n",
            "\n",
            "Epoch  4\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  1.0831564962863922\n",
            "Train -  [0.5, 0.5234375, nan]\n",
            "Validation -  [0.5, 1.0, nan]\n",
            "Test -  [0.5, 0.49, nan]\n",
            "\n",
            "Epoch  5\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.8463937044143677\n",
            "Train -  [0.5, 0.5859375, nan]\n",
            "Validation -  [0.5, 0.5, nan]\n",
            "Test -  [0.5, 0.55, nan]\n",
            "\n",
            "Epoch  6\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.7095478475093842\n",
            "Train -  [0.53125, 0.578125, 0.11764705882352941]\n",
            "Validation -  [0.5, 0.1875, nan]\n",
            "Test -  [0.45, 0.32000000000000006, nan]\n",
            "\n",
            "Epoch  7\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.6835410594940186\n",
            "Train -  [0.46875, 0.66796875, nan]\n",
            "Validation -  [0.5, 0.5, nan]\n",
            "Test -  [0.5, 0.65, nan]\n",
            "\n",
            "Epoch  8\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.5142444670200348\n",
            "Train -  [0.5625, 0.8046875, 0.2222222222222222]\n",
            "Validation -  [0.5, 0.6875, nan]\n",
            "Test -  [0.45, 0.37, nan]\n",
            "\n",
            "Epoch  9\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.6050825417041779\n",
            "Train -  [0.53125, 0.80078125, 0.21052631578947367]\n",
            "Validation -  [0.5, 0.6875, nan]\n",
            "Test -  [0.5, 0.36, nan]\n",
            "\n",
            "Epoch  10\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.46390393376350403\n",
            "Train -  [0.59375, 0.78515625, 0.3157894736842105]\n",
            "Validation -  [0.5, 0.4375, nan]\n",
            "Test -  [0.45, 0.27999999999999997, nan]\n",
            "\n",
            "Epoch  11\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.4673060476779938\n",
            "Train -  [0.5625, 0.8828125, 0.2222222222222222]\n",
            "Validation -  [0.5, 0.5625, nan]\n",
            "Test -  [0.55, 0.34, 0.18181818181818182]\n",
            "\n",
            "Epoch  12\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.3370317071676254\n",
            "Train -  [0.625, 0.828125, 0.4]\n",
            "Validation -  [0.5, 0.625, nan]\n",
            "Test -  [0.5, 0.4, nan]\n",
            "\n",
            "Epoch  13\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.35355305671691895\n",
            "Train -  [0.53125, 0.79296875, 0.2857142857142857]\n",
            "Validation -  [0.5, 0.4375, nan]\n",
            "Test -  [0.55, 0.32999999999999996, 0.18181818181818182]\n",
            "\n",
            "Epoch  14\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.3055633530020714\n",
            "Train -  [0.65625, 0.91796875, 0.47619047619047616]\n",
            "Validation -  [0.5, 0.25, nan]\n",
            "Test -  [0.55, 0.39, 0.18181818181818182]\n",
            "\n",
            "Epoch  15\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.20570380985736847\n",
            "Train -  [0.78125, 0.91015625, 0.7407407407407406]\n",
            "Validation -  [0.625, 0.5, 0.4]\n",
            "Test -  [0.55, 0.33999999999999997, 0.18181818181818182]\n",
            "\n",
            "Epoch  16\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.25084400922060013\n",
            "Train -  [0.71875, 0.8984375, 0.64]\n",
            "Validation -  [0.625, 0.5, 0.4]\n",
            "Test -  [0.5, 0.37, 0.28571428571428575]\n",
            "\n",
            "Epoch  17\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.19151732325553894\n",
            "Train -  [0.75, 0.90234375, 0.6923076923076923]\n",
            "Validation -  [0.625, 0.3125, 0.4]\n",
            "Test -  [0.55, 0.35000000000000003, 0.18181818181818182]\n",
            "\n",
            "Epoch  18\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.19985448569059372\n",
            "Train -  [0.75, 0.890625, 0.6923076923076923]\n",
            "Validation -  [0.625, 0.5625, 0.4]\n",
            "Test -  [0.4, 0.21, nan]\n",
            "\n",
            "Epoch  19\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.18511981517076492\n",
            "Train -  [0.78125, 0.921875, 0.7407407407407406]\n",
            "Validation -  [0.625, 0.5, 0.4]\n",
            "Test -  [0.35, 0.24, 0.13333333333333333]\n",
            "\n",
            "Epoch  20\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.1337439827620983\n",
            "Train -  [0.84375, 0.94921875, 0.8148148148148148]\n",
            "Validation -  [0.5, 0.3125, 0.3333333333333333]\n",
            "Test -  [0.45, 0.38, 0.15384615384615383]\n",
            "\n",
            "Epoch  21\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.17883910238742828\n",
            "Train -  [0.8125, 0.921875, 0.7857142857142857]\n",
            "Validation -  [0.625, 0.375, 0.4]\n",
            "Test -  [0.35, 0.13, 0.13333333333333333]\n",
            "\n",
            "Epoch  22\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.11158012971282005\n",
            "Train -  [0.8125, 0.93359375, 0.7857142857142857]\n",
            "Validation -  [0.625, 0.4375, 0.4]\n",
            "Test -  [0.4, 0.32, 0.14285714285714288]\n",
            "\n",
            "Epoch  23\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.10877270996570587\n",
            "Train -  [0.75, 0.890625, 0.7333333333333334]\n",
            "Validation -  [0.375, 0.5, 0.28571428571428575]\n",
            "Test -  [0.4, 0.24, 0.14285714285714288]\n",
            "\n",
            "Epoch  24\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.08074688538908958\n",
            "Train -  [0.84375, 0.93359375, 0.8275862068965517]\n",
            "Validation -  [0.625, 0.5625, 0.4]\n",
            "Test -  [0.3, 0.32999999999999996, 0.125]\n",
            "\n",
            "Epoch  25\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0863284021615982\n",
            "Train -  [0.78125, 0.92578125, 0.7586206896551724]\n",
            "Validation -  [0.5, 0.5625, 0.3333333333333333]\n",
            "Test -  [0.35, 0.27, 0.13333333333333333]\n",
            "\n",
            "Epoch  26\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0915585309267044\n",
            "Train -  [0.84375, 0.95703125, 0.8275862068965517]\n",
            "Validation -  [0.625, 0.4375, 0.4]\n",
            "Test -  [0.4, 0.29000000000000004, 0.14285714285714288]\n",
            "\n",
            "Epoch  27\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.07753110863268375\n",
            "Train -  [0.78125, 0.9296875, 0.7586206896551724]\n",
            "Validation -  [0.75, 0.5625, 0.6666666666666666]\n",
            "Test -  [0.4, 0.32, 0.25]\n",
            "\n",
            "Epoch  28\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.05995821766555309\n",
            "Train -  [0.78125, 0.92578125, 0.7741935483870969]\n",
            "Validation -  [0.75, 0.625, 0.6666666666666666]\n",
            "Test -  [0.3, 0.28, 0.125]\n",
            "\n",
            "Epoch  29\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.06730999052524567\n",
            "Train -  [0.78125, 0.92578125, 0.7586206896551724]\n",
            "Validation -  [0.625, 0.375, 0.4]\n",
            "Test -  [0.4, 0.30999999999999994, 0.25]\n",
            "\n",
            "Epoch  30\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.06646166741847992\n",
            "Train -  [0.75, 0.92578125, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.5625, 0.5714285714285715]\n",
            "Test -  [0.35, 0.27999999999999997, 0.13333333333333333]\n",
            "\n",
            "Epoch  31\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.07834705337882042\n",
            "Train -  [0.78125, 0.9140625, 0.7586206896551724]\n",
            "Validation -  [0.5, 0.3125, 0.3333333333333333]\n",
            "Test -  [0.4, 0.32, 0.25]\n",
            "\n",
            "Epoch  32\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0468460563570261\n",
            "Train -  [0.78125, 0.9375, 0.7741935483870969]\n",
            "Validation -  [0.5, 0.5, 0.3333333333333333]\n",
            "Test -  [0.3, 0.27999999999999997, 0.125]\n",
            "\n",
            "Epoch  33\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.04743852838873863\n",
            "Train -  [0.75, 0.92578125, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.6875, 0.4]\n",
            "Test -  [0.3, 0.30000000000000004, 0.125]\n",
            "\n",
            "Epoch  34\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.05474724806845188\n",
            "Train -  [0.8125, 0.921875, 0.7999999999999999]\n",
            "Validation -  [0.625, 0.5, 0.5714285714285715]\n",
            "Test -  [0.3, 0.22999999999999998, 0.125]\n",
            "\n",
            "Epoch  35\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.05058213323354721\n",
            "Train -  [0.84375, 0.93359375, 0.8387096774193549]\n",
            "Validation -  [0.5, 0.4375, 0.3333333333333333]\n",
            "Test -  [0.35, 0.26, 0.23529411764705882]\n",
            "\n",
            "Epoch  36\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.050160499289631844\n",
            "Train -  [0.75, 0.9296875, 0.7333333333333334]\n",
            "Validation -  [0.5, 0.5, 0.3333333333333333]\n",
            "Test -  [0.35, 0.26999999999999996, 0.23529411764705882]\n",
            "\n",
            "Epoch  37\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.04227075167000294\n",
            "Train -  [0.75, 0.92578125, 0.7333333333333334]\n",
            "Validation -  [0.5, 0.5, 0.3333333333333333]\n",
            "Test -  [0.35, 0.30999999999999994, 0.13333333333333333]\n",
            "\n",
            "Epoch  38\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03615618869662285\n",
            "Train -  [0.75, 0.90234375, 0.7333333333333334]\n",
            "Validation -  [0.375, 0.375, 0.28571428571428575]\n",
            "Test -  [0.3, 0.27, 0.125]\n",
            "\n",
            "Epoch  39\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.04211805574595928\n",
            "Train -  [0.75, 0.91015625, 0.75]\n",
            "Validation -  [0.375, 0.375, 0.28571428571428575]\n",
            "Test -  [0.35, 0.18, 0.23529411764705882]\n",
            "\n",
            "Epoch  40\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.033149030059576035\n",
            "Train -  [0.78125, 0.9453125, 0.787878787878788]\n",
            "Validation -  [0.625, 0.5, 0.4]\n",
            "Test -  [0.25, 0.21999999999999997, 0.11764705882352941]\n",
            "\n",
            "Epoch  41\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03640287183225155\n",
            "Train -  [0.75, 0.91015625, 0.75]\n",
            "Validation -  [0.5, 0.375, 0.5]\n",
            "Test -  [0.35, 0.24, 0.13333333333333333]\n",
            "\n",
            "Epoch  42\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.031131775118410587\n",
            "Train -  [0.71875, 0.91015625, 0.7272727272727272]\n",
            "Validation -  [0.5, 0.3125, 0.3333333333333333]\n",
            "Test -  [0.35, 0.22, 0.23529411764705882]\n",
            "\n",
            "Epoch  43\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03175278287380934\n",
            "Train -  [0.75, 0.91015625, 0.75]\n",
            "Validation -  [0.5, 0.4375, 0.3333333333333333]\n",
            "Test -  [0.35, 0.24000000000000002, 0.23529411764705882]\n",
            "\n",
            "Epoch  44\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.030380412936210632\n",
            "Train -  [0.78125, 0.90625, 0.7741935483870969]\n",
            "Validation -  [0.5, 0.4375, 0.3333333333333333]\n",
            "Test -  [0.35, 0.27999999999999997, 0.23529411764705882]\n",
            "\n",
            "Epoch  45\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.0328928679227829\n",
            "Train -  [0.75, 0.9296875, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.5, 0.4]\n",
            "Test -  [0.35, 0.36, 0.13333333333333333]\n",
            "\n",
            "Epoch  46\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02774037793278694\n",
            "Train -  [0.78125, 0.9140625, 0.7741935483870969]\n",
            "Validation -  [0.625, 0.625, 0.5714285714285715]\n",
            "Test -  [0.3, 0.24000000000000002, 0.125]\n",
            "\n",
            "Epoch  47\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.026773647405207157\n",
            "Train -  [0.75, 0.921875, 0.75]\n",
            "Validation -  [0.625, 0.5, 0.4]\n",
            "Test -  [0.4, 0.3, 0.14285714285714288]\n",
            "\n",
            "Epoch  48\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02870777528733015\n",
            "Train -  [0.78125, 0.92578125, 0.7586206896551724]\n",
            "Validation -  [0.5, 0.4375, 0.3333333333333333]\n",
            "Test -  [0.35, 0.31000000000000005, 0.13333333333333333]\n",
            "\n",
            "Epoch  49\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.025119771249592304\n",
            "Train -  [0.75, 0.921875, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.5, 0.4]\n",
            "Test -  [0.45, 0.26, 0.26666666666666666]\n",
            "\n",
            "Epoch  50\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.027633100748062134\n",
            "Train -  [0.8125, 0.9296875, 0.7999999999999999]\n",
            "Validation -  [0.625, 0.5, 0.4]\n",
            "Test -  [0.35, 0.26, 0.13333333333333333]\n",
            "\n",
            "Epoch  51\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.027502644807100296\n",
            "Train -  [0.78125, 0.92578125, 0.7741935483870969]\n",
            "Validation -  [0.5, 0.5, 0.3333333333333333]\n",
            "Test -  [0.35, 0.22999999999999998, 0.13333333333333333]\n",
            "\n",
            "Epoch  52\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02446541003882885\n",
            "Train -  [0.8125, 0.92578125, 0.7999999999999999]\n",
            "Validation -  [0.5, 0.4375, 0.3333333333333333]\n",
            "Test -  [0.4, 0.30000000000000004, 0.25]\n",
            "\n",
            "Epoch  53\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.03215169347822666\n",
            "Train -  [0.78125, 0.91796875, 0.7586206896551724]\n",
            "Validation -  [0.5, 0.4375, 0.3333333333333333]\n",
            "Test -  [0.45, 0.32000000000000006, 0.26666666666666666]\n",
            "\n",
            "Epoch  54\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.027145656757056713\n",
            "Train -  [0.75, 0.921875, 0.7333333333333334]\n",
            "Validation -  [0.5, 0.625, 0.3333333333333333]\n",
            "Test -  [0.35, 0.19, 0.13333333333333333]\n",
            "\n",
            "Epoch  55\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.023602512665092945\n",
            "Train -  [0.78125, 0.91015625, 0.7741935483870969]\n",
            "Validation -  [0.5, 0.4375, 0.3333333333333333]\n",
            "Test -  [0.4, 0.32, 0.25]\n",
            "\n",
            "Epoch  56\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.018207718152552843\n",
            "Train -  [0.78125, 0.9140625, 0.7741935483870969]\n",
            "Validation -  [0.5, 0.4375, 0.3333333333333333]\n",
            "Test -  [0.25, 0.2, 0.11764705882352941]\n",
            "\n",
            "Epoch  57\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.019219912588596344\n",
            "Train -  [0.84375, 0.94140625, 0.8275862068965517]\n",
            "Validation -  [0.625, 0.5625, 0.5714285714285715]\n",
            "Test -  [0.4, 0.24, 0.25]\n",
            "\n",
            "Epoch  58\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02027298230677843\n",
            "Train -  [0.75, 0.91796875, 0.75]\n",
            "Validation -  [0.5, 0.5625, 0.3333333333333333]\n",
            "Test -  [0.35, 0.22999999999999998, 0.23529411764705882]\n",
            "\n",
            "Epoch  59\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02054223045706749\n",
            "Train -  [0.8125, 0.92578125, 0.8125]\n",
            "Validation -  [0.5, 0.375, 0.3333333333333333]\n",
            "Test -  [0.35, 0.20000000000000004, 0.13333333333333333]\n",
            "\n",
            "Epoch  60\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.022734327241778374\n",
            "Train -  [0.75, 0.91796875, 0.7333333333333334]\n",
            "Validation -  [0.375, 0.4375, 0.28571428571428575]\n",
            "Test -  [0.4, 0.24, 0.25]\n",
            "\n",
            "Epoch  61\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.021114232949912548\n",
            "Train -  [0.875, 0.9296875, 0.8571428571428571]\n",
            "Validation -  [0.625, 0.5, 0.5714285714285715]\n",
            "Test -  [0.4, 0.28, 0.25]\n",
            "\n",
            "Epoch  62\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.02020573616027832\n",
            "Train -  [0.78125, 0.93359375, 0.7741935483870969]\n",
            "Validation -  [0.5, 0.5625, 0.5]\n",
            "Test -  [0.25, 0.15999999999999998, 0.11764705882352941]\n",
            "\n",
            "Epoch  63\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.021245084702968597\n",
            "Train -  [0.75, 0.90625, 0.75]\n",
            "Validation -  [0.5, 0.5625, 0.3333333333333333]\n",
            "Test -  [0.25, 0.27, 0.11764705882352941]\n",
            "\n",
            "Epoch  64\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.014797252137213945\n",
            "Train -  [0.75, 0.921875, 0.75]\n",
            "Validation -  [0.625, 0.4375, 0.5714285714285715]\n",
            "Test -  [0.35, 0.25, 0.23529411764705882]\n",
            "\n",
            "Epoch  65\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01505697937682271\n",
            "Train -  [0.84375, 0.9453125, 0.8387096774193549]\n",
            "Validation -  [0.5, 0.375, 0.3333333333333333]\n",
            "Test -  [0.35, 0.28, 0.23529411764705882]\n",
            "\n",
            "Epoch  66\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.012953246012330055\n",
            "Train -  [0.8125, 0.91796875, 0.7999999999999999]\n",
            "Validation -  [0.5, 0.5, 0.3333333333333333]\n",
            "Test -  [0.35, 0.21999999999999997, 0.23529411764705882]\n",
            "\n",
            "Epoch  67\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01528023136779666\n",
            "Train -  [0.75, 0.91015625, 0.75]\n",
            "Validation -  [0.375, 0.4375, 0.28571428571428575]\n",
            "Test -  [0.3, 0.28, 0.125]\n",
            "\n",
            "Epoch  68\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.017967855092138052\n",
            "Train -  [0.78125, 0.93359375, 0.7741935483870969]\n",
            "Validation -  [0.5, 0.375, 0.3333333333333333]\n",
            "Test -  [0.35, 0.17, 0.13333333333333333]\n",
            "\n",
            "Epoch  69\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.015197154134511948\n",
            "Train -  [0.78125, 0.91796875, 0.7586206896551724]\n",
            "Validation -  [0.375, 0.5, 0.28571428571428575]\n",
            "Test -  [0.35, 0.23, 0.13333333333333333]\n",
            "\n",
            "Epoch  70\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.012521110475063324\n",
            "Train -  [0.78125, 0.91015625, 0.7741935483870969]\n",
            "Validation -  [0.625, 0.5625, 0.4]\n",
            "Test -  [0.35, 0.28, 0.13333333333333333]\n",
            "\n",
            "Epoch  71\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01355710718780756\n",
            "Train -  [0.75, 0.92578125, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.5, 0.4]\n",
            "Test -  [0.45, 0.27, 0.26666666666666666]\n",
            "\n",
            "Epoch  72\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.012319633737206459\n",
            "Train -  [0.71875, 0.90625, 0.7096774193548386]\n",
            "Validation -  [0.5, 0.5, 0.3333333333333333]\n",
            "Test -  [0.4, 0.26, 0.25]\n",
            "\n",
            "Epoch  73\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.013947282917797565\n",
            "Train -  [0.78125, 0.9140625, 0.7586206896551724]\n",
            "Validation -  [0.5, 0.375, 0.3333333333333333]\n",
            "Test -  [0.4, 0.24, 0.14285714285714288]\n",
            "\n",
            "Epoch  74\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.01736533734947443\n",
            "Train -  [0.8125, 0.9140625, 0.7999999999999999]\n",
            "Validation -  [0.5, 0.5, 0.3333333333333333]\n",
            "Test -  [0.35, 0.21000000000000002, 0.13333333333333333]\n",
            "\n",
            "Epoch  75\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.009672340471297503\n",
            "Train -  [0.8125, 0.9296875, 0.7999999999999999]\n",
            "Validation -  [0.5, 0.5, 0.3333333333333333]\n",
            "Test -  [0.3, 0.29000000000000004, 0.125]\n",
            "\n",
            "Epoch  76\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.010552132036536932\n",
            "Train -  [0.8125, 0.91796875, 0.7999999999999999]\n",
            "Validation -  [0.5, 0.5, 0.3333333333333333]\n",
            "Test -  [0.35, 0.21000000000000002, 0.13333333333333333]\n",
            "\n",
            "Epoch  77\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.017110748682171106\n",
            "Train -  [0.8125, 0.9296875, 0.7999999999999999]\n",
            "Validation -  [0.5, 0.5, 0.3333333333333333]\n",
            "Test -  [0.35, 0.30000000000000004, 0.23529411764705882]\n",
            "\n",
            "Epoch  78\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.011195701081305742\n",
            "Train -  [0.84375, 0.94921875, 0.8275862068965517]\n",
            "Validation -  [0.5, 0.375, 0.3333333333333333]\n",
            "Test -  [0.35, 0.23, 0.23529411764705882]\n",
            "\n",
            "Epoch  79\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.014608488883823156\n",
            "Train -  [0.8125, 0.9140625, 0.7999999999999999]\n",
            "Validation -  [0.625, 0.4375, 0.4]\n",
            "Test -  [0.3, 0.27, 0.125]\n",
            "\n",
            "Epoch  80\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.014285361394286156\n",
            "Train -  [0.78125, 0.9375, 0.7741935483870969]\n",
            "Validation -  [0.625, 0.4375, 0.4]\n",
            "Test -  [0.4, 0.33, 0.25]\n",
            "\n",
            "Epoch  81\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.012417479883879423\n",
            "Train -  [0.78125, 0.92578125, 0.7586206896551724]\n",
            "Validation -  [0.5, 0.4375, 0.3333333333333333]\n",
            "Test -  [0.45, 0.25, 0.26666666666666666]\n",
            "\n",
            "Epoch  82\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.013282429426908493\n",
            "Train -  [0.84375, 0.93359375, 0.8275862068965517]\n",
            "Validation -  [0.5, 0.5, 0.3333333333333333]\n",
            "Test -  [0.45, 0.25, 0.26666666666666666]\n",
            "\n",
            "Epoch  83\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.010357028804719448\n",
            "Train -  [0.8125, 0.94140625, 0.7999999999999999]\n",
            "Validation -  [0.375, 0.375, 0.28571428571428575]\n",
            "Test -  [0.35, 0.2, 0.13333333333333333]\n",
            "\n",
            "Epoch  84\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.010376858059316874\n",
            "Train -  [0.75, 0.921875, 0.75]\n",
            "Validation -  [0.5, 0.4375, 0.3333333333333333]\n",
            "Test -  [0.35, 0.24, 0.13333333333333333]\n",
            "\n",
            "Epoch  85\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.010009997058659792\n",
            "Train -  [0.78125, 0.91796875, 0.7741935483870969]\n",
            "Validation -  [0.5, 0.4375, 0.3333333333333333]\n",
            "Test -  [0.4, 0.2, 0.14285714285714288]\n",
            "\n",
            "Epoch  86\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.010354010853916407\n",
            "Train -  [0.8125, 0.92578125, 0.8125]\n",
            "Validation -  [0.5, 0.375, 0.5]\n",
            "Test -  [0.4, 0.18, 0.25]\n",
            "\n",
            "Epoch  87\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.008820130955427885\n",
            "Train -  [0.75, 0.91015625, 0.75]\n",
            "Validation -  [0.5, 0.4375, 0.3333333333333333]\n",
            "Test -  [0.4, 0.21, 0.25]\n",
            "\n",
            "Epoch  88\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.012467401567846537\n",
            "Train -  [0.71875, 0.91796875, 0.7096774193548386]\n",
            "Validation -  [0.375, 0.5625, 0.28571428571428575]\n",
            "Test -  [0.35, 0.18, 0.13333333333333333]\n",
            "\n",
            "Epoch  89\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.010446004569530487\n",
            "Train -  [0.78125, 0.9296875, 0.7741935483870969]\n",
            "Validation -  [0.375, 0.4375, 0.28571428571428575]\n",
            "Test -  [0.3, 0.23, 0.125]\n",
            "\n",
            "Epoch  90\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.011691150721162558\n",
            "Train -  [0.75, 0.9140625, 0.75]\n",
            "Validation -  [0.375, 0.4375, 0.28571428571428575]\n",
            "Test -  [0.4, 0.28, 0.25]\n",
            "\n",
            "Epoch  91\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.014140460640192032\n",
            "Train -  [0.75, 0.9375, 0.75]\n",
            "Validation -  [0.5, 0.4375, 0.3333333333333333]\n",
            "Test -  [0.45, 0.31000000000000005, 0.26666666666666666]\n",
            "\n",
            "Epoch  92\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.00988493487238884\n",
            "Train -  [0.75, 0.90234375, 0.7333333333333334]\n",
            "Validation -  [0.375, 0.4375, 0.28571428571428575]\n",
            "Test -  [0.3, 0.23, 0.125]\n",
            "\n",
            "Epoch  93\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.009027167689055204\n",
            "Train -  [0.8125, 0.921875, 0.7999999999999999]\n",
            "Validation -  [0.5, 0.375, 0.3333333333333333]\n",
            "Test -  [0.35, 0.27, 0.13333333333333333]\n",
            "\n",
            "Epoch  94\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.009317688876762986\n",
            "Train -  [0.75, 0.91015625, 0.7333333333333334]\n",
            "Validation -  [0.625, 0.4375, 0.4]\n",
            "Test -  [0.45, 0.24, 0.26666666666666666]\n",
            "\n",
            "Epoch  95\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.009108714293688536\n",
            "Train -  [0.8125, 0.9296875, 0.7999999999999999]\n",
            "Validation -  [0.5, 0.4375, 0.3333333333333333]\n",
            "Test -  [0.35, 0.28, 0.13333333333333333]\n",
            "\n",
            "Epoch  96\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.00907279271632433\n",
            "Train -  [0.8125, 0.94140625, 0.7999999999999999]\n",
            "Validation -  [0.5, 0.4375, 0.3333333333333333]\n",
            "Test -  [0.4, 0.25, 0.14285714285714288]\n",
            "\n",
            "Epoch  97\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.007880412740632892\n",
            "Train -  [0.8125, 0.9140625, 0.7999999999999999]\n",
            "Validation -  [0.5, 0.5, 0.3333333333333333]\n",
            "Test -  [0.45, 0.27, 0.26666666666666666]\n",
            "\n",
            "Epoch  98\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.008949562441557646\n",
            "Train -  [0.8125, 0.93359375, 0.7999999999999999]\n",
            "Validation -  [0.5, 0.5625, 0.3333333333333333]\n",
            "Test -  [0.35, 0.24, 0.13333333333333333]\n",
            "\n",
            "Epoch  99\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  0.00818535778671503\n",
            "Train -  [0.75, 0.91796875, 0.7333333333333334]\n",
            "Validation -  [0.5, 0.5, 0.3333333333333333]\n",
            "Test -  [0.4, 0.29000000000000004, 0.14285714285714288]\n",
            "Epoch with best accuracy is 11\n",
            "==================================================END OF SUBJECT {idx_e_subj+1}==================================================\n",
            "All Subjects\n",
            "start_idx_train: 0\n",
            "end_idx_train: 640\n",
            "start_idx_val: 640\n",
            "end_idx_val: 800\n",
            "start_idx_eval: 0\n",
            "end_idx_eval: 400\n",
            "[0 1 0 1 0 1 0 1 1 0]\n",
            "[0 1 1 0 0 1 0 1 0 1]\n",
            "[0 1 1 0 1 0 0 1 0 1]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Epoch  0\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  46.90227770805359\n",
            "Train -  [0.6015625, 0.6219238281250001, 0.6222222222222222]\n",
            "Validation -  [0.4625, 0.47140624999999997, 0.5]\n",
            "Test -  [0.4875, 0.5068, 0.5012165450121654]\n",
            "\n",
            "Epoch  1\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  42.06495672464371\n",
            "Train -  [0.6078125, 0.668955078125, 0.6666666666666666]\n",
            "Validation -  [0.4875, 0.44296874999999997, 0.5393258426966292]\n",
            "Test -  [0.49, 0.5026, 0.5545851528384279]\n",
            "\n",
            "Epoch  2\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  40.2663114964962\n",
            "Train -  [0.6625, 0.743349609375, 0.7142857142857143]\n",
            "Validation -  [0.48125, 0.47093749999999995, 0.5870646766169154]\n",
            "Test -  [0.4825, 0.48265, 0.5678496868475991]\n",
            "\n",
            "Epoch  3\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  38.26092490553856\n",
            "Train -  [0.665625, 0.7755273437500002, 0.7256410256410256]\n",
            "Validation -  [0.53125, 0.505625, 0.6268656716417911]\n",
            "Test -  [0.4975, 0.5183, 0.5838509316770185]\n",
            "\n",
            "Epoch  4\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  36.113316267728806\n",
            "Train -  [0.7078125, 0.7952832031249999, 0.7434842249657065]\n",
            "Validation -  [0.525, 0.5303125, 0.5777777777777778]\n",
            "Test -  [0.55, 0.5478000000000001, 0.6120689655172413]\n",
            "\n",
            "Epoch  5\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  33.42769446969032\n",
            "Train -  [0.7453125, 0.83740234375, 0.76410998552822]\n",
            "Validation -  [0.5, 0.5123437499999999, 0.5604395604395604]\n",
            "Test -  [0.555, 0.5557, 0.6061946902654868]\n",
            "\n",
            "Epoch  6\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  31.167465895414352\n",
            "Train -  [0.71875, 0.8446386718750001, 0.7692307692307693]\n",
            "Validation -  [0.55625, 0.5642187500000001, 0.6570048309178744]\n",
            "Test -  [0.5275, 0.5553500000000001, 0.6197183098591549]\n",
            "\n",
            "Epoch  7\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  29.42080995440483\n",
            "Train -  [0.7734375, 0.865126953125, 0.7994467496542185]\n",
            "Validation -  [0.56875, 0.5801562499999999, 0.6229508196721311]\n",
            "Test -  [0.545, 0.5656249999999999, 0.6127659574468085]\n",
            "\n",
            "Epoch  8\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  27.254303589463234\n",
            "Train -  [0.7328125, 0.86099609375, 0.7782101167315175]\n",
            "Validation -  [0.54375, 0.53859375, 0.6217616580310882]\n",
            "Test -  [0.4925, 0.530225, 0.593186372745491]\n",
            "\n",
            "Epoch  9\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  26.533927515149117\n",
            "Train -  [0.759375, 0.8860351562500001, 0.7941176470588236]\n",
            "Validation -  [0.525, 0.54890625, 0.5824175824175825]\n",
            "Test -  [0.5175, 0.525275, 0.5867237687366167]\n",
            "\n",
            "Epoch  10\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  24.491820581257343\n",
            "Train -  [0.7953125, 0.88892578125, 0.804185351270553]\n",
            "Validation -  [0.51875, 0.5275000000000001, 0.46896551724137936]\n",
            "Test -  [0.525, 0.533475, 0.5454545454545454]\n",
            "\n",
            "Epoch  11\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  24.006174936890602\n",
            "Train -  [0.771875, 0.8618359375, 0.7598684210526317]\n",
            "Validation -  [0.51875, 0.53421875, 0.4539007092198582]\n",
            "Test -  [0.5675, 0.565325, 0.5435356200527706]\n",
            "\n",
            "Epoch  12\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  22.644815385341644\n",
            "Train -  [0.7875, 0.8597656250000001, 0.7901234567901235]\n",
            "Validation -  [0.55, 0.55421875, 0.5]\n",
            "Test -  [0.535, 0.561325, 0.5130890052356021]\n",
            "\n",
            "Epoch  13\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  22.822702810168266\n",
            "Train -  [0.8, 0.92060546875, 0.8241758241758242]\n",
            "Validation -  [0.55625, 0.56953125, 0.6033519553072625]\n",
            "Test -  [0.54, 0.562675, 0.5982532751091704]\n",
            "\n",
            "Epoch  14\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  20.120798103511333\n",
            "Train -  [0.75, 0.89193359375, 0.7855227882037534]\n",
            "Validation -  [0.53125, 0.56953125, 0.5562130177514791]\n",
            "Test -  [0.555, 0.581075, 0.611353711790393]\n",
            "\n",
            "Epoch  15\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  19.93373568356037\n",
            "Train -  [0.8265625, 0.913388671875, 0.8350668647845467]\n",
            "Validation -  [0.51875, 0.54265625, 0.5217391304347826]\n",
            "Test -  [0.53, 0.5689500000000001, 0.5566037735849056]\n",
            "\n",
            "Epoch  16\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  16.149297147989273\n",
            "Train -  [0.8109375, 0.9205078125, 0.8212703101920237]\n",
            "Validation -  [0.53125, 0.541875, 0.5161290322580646]\n",
            "Test -  [0.53, 0.5487249999999999, 0.5414634146341464]\n",
            "\n",
            "Epoch  17\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  17.890060983598232\n",
            "Train -  [0.821875, 0.940859375, 0.8416666666666667]\n",
            "Validation -  [0.6, 0.60484375, 0.6404494382022472]\n",
            "Test -  [0.5075, 0.558725, 0.5631929046563193]\n",
            "\n",
            "Epoch  18\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  16.89190512895584\n",
            "Train -  [0.83125, 0.918779296875, 0.8388059701492538]\n",
            "Validation -  [0.55, 0.5823437499999999, 0.5324675324675324]\n",
            "Test -  [0.57, 0.5795, 0.5721393034825871]\n",
            "\n",
            "Epoch  19\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  16.381668835878372\n",
            "Train -  [0.8234375, 0.9203515625, 0.8310911808669655]\n",
            "Validation -  [0.5375, 0.5710937500000001, 0.5316455696202531]\n",
            "Test -  [0.5325, 0.565325, 0.5472154963680387]\n",
            "\n",
            "Epoch  20\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  17.956760823726654\n",
            "Train -  [0.8125, 0.918369140625, 0.8309859154929576]\n",
            "Validation -  [0.5125, 0.5328124999999999, 0.5185185185185186]\n",
            "Test -  [0.5425, 0.570675, 0.5924276169265034]\n",
            "\n",
            "Epoch  21\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  19.072547547519207\n",
            "Train -  [0.81875, 0.923994140625, 0.8375350140056023]\n",
            "Validation -  [0.50625, 0.53390625, 0.5485714285714287]\n",
            "Test -  [0.5275, 0.569525, 0.5917926565874729]\n",
            "\n",
            "Epoch  22\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  17.714264824986458\n",
            "Train -  [0.7765625, 0.9375683593749999, 0.8145265888456551]\n",
            "Validation -  [0.55, 0.54703125, 0.6250000000000001]\n",
            "Test -  [0.52, 0.574425, 0.625]\n",
            "\n",
            "Epoch  23\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  13.633713517338037\n",
            "Train -  [0.7921875, 0.93470703125, 0.821954484605087]\n",
            "Validation -  [0.525, 0.5804687499999999, 0.5824175824175825]\n",
            "Test -  [0.52, 0.552475, 0.6033057851239669]\n",
            "\n",
            "Epoch  24\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  16.79773206822574\n",
            "Train -  [0.7859375, 0.9264160156250001, 0.8175765645805593]\n",
            "Validation -  [0.5875, 0.5871875, 0.6562499999999999]\n",
            "Test -  [0.5025, 0.5579500000000001, 0.5995975855130784]\n",
            "\n",
            "Epoch  25\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  16.836792819201946\n",
            "Train -  [0.7921875, 0.935087890625, 0.8256880733944955]\n",
            "Validation -  [0.5375, 0.5800000000000001, 0.6105263157894736]\n",
            "Test -  [0.53, 0.577725, 0.6163265306122448]\n",
            "\n",
            "Epoch  26\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  14.293840412050486\n",
            "Train -  [0.834375, 0.92892578125, 0.8494318181818182]\n",
            "Validation -  [0.50625, 0.551875, 0.5325443786982248]\n",
            "Test -  [0.5275, 0.566225, 0.5752808988764045]\n",
            "\n",
            "Epoch  27\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  13.0222586132586\n",
            "Train -  [0.8421875, 0.923955078125, 0.8448540706605222]\n",
            "Validation -  [0.55, 0.581875, 0.5]\n",
            "Test -  [0.535, 0.557825, 0.5373134328358209]\n",
            "\n",
            "Epoch  28\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  11.390294890850782\n",
            "Train -  [0.85, 0.952470703125, 0.8628571428571428]\n",
            "Validation -  [0.58125, 0.6074999999999999, 0.5838509316770186]\n",
            "Test -  [0.525, 0.5706499999999999, 0.5539906103286385]\n",
            "\n",
            "Epoch  29\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  12.867790218442678\n",
            "Train -  [0.803125, 0.9302832031249999, 0.8292682926829268]\n",
            "Validation -  [0.49375, 0.55375, 0.5371428571428571]\n",
            "Test -  [0.55, 0.568375, 0.6017699115044247]\n",
            "\n",
            "Epoch  30\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  10.008968506008387\n",
            "Train -  [0.8125, 0.950546875, 0.839142091152815]\n",
            "Validation -  [0.55, 0.6207812500000001, 0.6210526315789474]\n",
            "Test -  [0.53, 0.56315, 0.6083333333333334]\n",
            "\n",
            "Epoch  31\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  12.137349719181657\n",
            "Train -  [0.81875, 0.95208984375, 0.8440860215053763]\n",
            "Validation -  [0.5625, 0.6009375, 0.5833333333333333]\n",
            "Test -  [0.5375, 0.568675, 0.6137787056367432]\n",
            "\n",
            "Epoch  32\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  7.9453577399253845\n",
            "Train -  [0.8234375, 0.945029296875, 0.8419580419580419]\n",
            "Validation -  [0.53125, 0.5426562500000001, 0.5398773006134969]\n",
            "Test -  [0.5375, 0.5875, 0.5916114790286977]\n",
            "\n",
            "Epoch  33\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  8.149424561299384\n",
            "Train -  [0.8515625, 0.927197265625, 0.8536209553158705]\n",
            "Validation -  [0.5625, 0.5771875, 0.5394736842105262]\n",
            "Test -  [0.5475, 0.57815, 0.5486284289276808]\n",
            "\n",
            "Epoch  34\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  9.154275183333084\n",
            "Train -  [0.8609375, 0.938193359375, 0.8615863141524106]\n",
            "Validation -  [0.55, 0.5790625, 0.52]\n",
            "Test -  [0.59, 0.6029249999999999, 0.5816326530612245]\n",
            "\n",
            "Epoch  35\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  10.009199955500662\n",
            "Train -  [0.828125, 0.942197265625, 0.8433048433048435]\n",
            "Validation -  [0.5375, 0.5603125, 0.5542168674698795]\n",
            "Test -  [0.5475, 0.57675, 0.5914221218961625]\n",
            "\n",
            "Epoch  36\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  8.724165205843747\n",
            "Train -  [0.8546875, 0.944150390625, 0.8646288209606987]\n",
            "Validation -  [0.55, 0.5603125, 0.5714285714285713]\n",
            "Test -  [0.5425, 0.5713750000000001, 0.5773672055427251]\n",
            "\n",
            "Epoch  37\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  8.469530275091529\n",
            "Train -  [0.8578125, 0.928603515625, 0.8647845468053492]\n",
            "Validation -  [0.55, 0.5917187500000001, 0.55]\n",
            "Test -  [0.525, 0.54645, 0.5497630331753554]\n",
            "\n",
            "Epoch  38\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  8.442980559542775\n",
            "Train -  [0.8515625, 0.9376562500000001, 0.8562783661119516]\n",
            "Validation -  [0.50625, 0.5871875, 0.4697986577181208]\n",
            "Test -  [0.535, 0.54585, 0.5396039603960396]\n",
            "\n",
            "Epoch  39\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  7.029927100986242\n",
            "Train -  [0.8328125, 0.946396484375, 0.8524137931034482]\n",
            "Validation -  [0.5, 0.51546875, 0.5061728395061729]\n",
            "Test -  [0.56, 0.5786749999999999, 0.6018099547511313]\n",
            "\n",
            "Epoch  40\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  8.826568115968257\n",
            "Train -  [0.8, 0.95037109375, 0.830238726790451]\n",
            "Validation -  [0.56875, 0.56109375, 0.6270270270270271]\n",
            "Test -  [0.5375, 0.567475, 0.6105263157894736]\n",
            "\n",
            "Epoch  41\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  11.07587943226099\n",
            "Train -  [0.86875, 0.94173828125, 0.8719512195121951]\n",
            "Validation -  [0.53125, 0.5662499999999999, 0.4966442953020134]\n",
            "Test -  [0.515, 0.5362750000000001, 0.5125628140703518]\n",
            "\n",
            "Epoch  42\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  10.74804866546765\n",
            "Train -  [0.8359375, 0.95423828125, 0.8531468531468531]\n",
            "Validation -  [0.55625, 0.5740624999999999, 0.5895953757225433]\n",
            "Test -  [0.5575, 0.5846750000000001, 0.604026845637584]\n",
            "\n",
            "Epoch  43\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  8.77888236194849\n",
            "Train -  [0.859375, 0.942587890625, 0.861963190184049]\n",
            "Validation -  [0.55, 0.5834374999999999, 0.52]\n",
            "Test -  [0.5325, 0.5499750000000001, 0.519280205655527]\n",
            "\n",
            "Epoch  44\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  8.920095625566319\n",
            "Train -  [0.85625, 0.941640625, 0.866279069767442]\n",
            "Validation -  [0.50625, 0.5484374999999999, 0.4968152866242038]\n",
            "Test -  [0.555, 0.570275, 0.580188679245283]\n",
            "\n",
            "Epoch  45\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  9.134122035466135\n",
            "Train -  [0.865625, 0.953994140625, 0.8764367816091954]\n",
            "Validation -  [0.5, 0.51796875, 0.5348837209302325]\n",
            "Test -  [0.52, 0.5408625, 0.5733333333333334]\n",
            "\n",
            "Epoch  46\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  8.958381497301161\n",
            "Train -  [0.85, 0.960703125, 0.8659217877094972]\n",
            "Validation -  [0.525, 0.5701562499999999, 0.5529411764705883]\n",
            "Test -  [0.5375, 0.567025, 0.5861297539149889]\n",
            "\n",
            "Epoch  47\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  7.229502737522125\n",
            "Train -  [0.8, 0.9460546875, 0.8279569892473119]\n",
            "Validation -  [0.49375, 0.5621875000000001, 0.5317919075144508]\n",
            "Test -  [0.5125, 0.5592750000000001, 0.5945945945945946]\n",
            "\n",
            "Epoch  48\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  9.262555999215692\n",
            "Train -  [0.8140625, 0.928935546875, 0.8367626886145404]\n",
            "Validation -  [0.54375, 0.5564062500000001, 0.562874251497006]\n",
            "Test -  [0.54, 0.571275, 0.5874439461883407]\n",
            "\n",
            "Epoch  49\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  6.445115671958774\n",
            "Train -  [0.7828125, 0.9523486328125, 0.817824377457405]\n",
            "Validation -  [0.56875, 0.579375, 0.6229508196721311]\n",
            "Test -  [0.5225, 0.5597, 0.6125760649087222]\n",
            "\n",
            "Epoch  50\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  8.012105226516724\n",
            "Train -  [0.7265625, 0.9423437499999999, 0.7820672478206725]\n",
            "Validation -  [0.55625, 0.59796875, 0.6395939086294417]\n",
            "Test -  [0.5525, 0.61255, 0.6510721247563354]\n",
            "\n",
            "Epoch  51\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  10.816474782535806\n",
            "Train -  [0.8203125, 0.9492968749999999, 0.8426812585499317]\n",
            "Validation -  [0.5375, 0.585625, 0.5747126436781609]\n",
            "Test -  [0.5425, 0.566875, 0.6114649681528662]\n",
            "\n",
            "Epoch  52\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  6.851369552663527\n",
            "Train -  [0.7890625, 0.9541796874999999, 0.8239895697522817]\n",
            "Validation -  [0.51875, 0.5762499999999999, 0.5837837837837838]\n",
            "Test -  [0.5275, 0.5676375, 0.6257425742574257]\n",
            "\n",
            "Epoch  53\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  7.2503747954033315\n",
            "Train -  [0.8140625, 0.9617578125, 0.8389715832205683]\n",
            "Validation -  [0.575, 0.62734375, 0.6136363636363636]\n",
            "Test -  [0.5275, 0.5772250000000001, 0.5935483870967743]\n",
            "\n",
            "Epoch  54\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  6.10249673970975\n",
            "Train -  [0.8125, 0.9612304687499998, 0.839142091152815]\n",
            "Validation -  [0.5625, 0.6109374999999999, 0.631578947368421]\n",
            "Test -  [0.5425, 0.5884, 0.6147368421052631]\n",
            "\n",
            "Epoch  55\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  8.999858245253563\n",
            "Train -  [0.834375, 0.952119140625, 0.8543956043956045]\n",
            "Validation -  [0.5125, 0.5582812500000001, 0.5714285714285715]\n",
            "Test -  [0.545, 0.5746249999999999, 0.606060606060606]\n",
            "\n",
            "Epoch  56\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  7.248159309383482\n",
            "Train -  [0.8625, 0.95482421875, 0.8750000000000001]\n",
            "Validation -  [0.54375, 0.5871875, 0.5730994152046783]\n",
            "Test -  [0.5325, 0.5826500000000001, 0.589010989010989]\n",
            "\n",
            "Epoch  57\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  6.849625536240637\n",
            "Train -  [0.825, 0.9488769531249999, 0.8431372549019607]\n",
            "Validation -  [0.5875, 0.61875, 0.6292134831460674]\n",
            "Test -  [0.53, 0.55675, 0.606694560669456]\n",
            "\n",
            "Epoch  58\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  7.96398616489023\n",
            "Train -  [0.8703125, 0.9415625, 0.8688783570300158]\n",
            "Validation -  [0.59375, 0.599375, 0.5911949685534591]\n",
            "Test -  [0.535, 0.5808500000000001, 0.5279187817258884]\n",
            "\n",
            "Epoch  59\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  9.48302125360351\n",
            "Train -  [0.871875, 0.9444531249999999, 0.8757575757575757]\n",
            "Validation -  [0.4875, 0.54796875, 0.47435897435897445]\n",
            "Test -  [0.5625, 0.57935, 0.5742092457420924]\n",
            "\n",
            "Epoch  60\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  8.59639236354269\n",
            "Train -  [0.8953125, 0.962021484375, 0.895148669796557]\n",
            "Validation -  [0.475, 0.54125, 0.4473684210526316]\n",
            "Test -  [0.5375, 0.5676, 0.5316455696202531]\n",
            "\n",
            "Epoch  61\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  6.651309508131817\n",
            "Train -  [0.859375, 0.9539453125, 0.8721590909090909]\n",
            "Validation -  [0.525, 0.5721875000000001, 0.525]\n",
            "Test -  [0.56, 0.5823, 0.6000000000000001]\n",
            "\n",
            "Epoch  62\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  5.994530790951103\n",
            "Train -  [0.8765625, 0.959619140625, 0.8873038516405136]\n",
            "Validation -  [0.5375, 0.58125, 0.5542168674698795]\n",
            "Test -  [0.54, 0.582375, 0.574074074074074]\n",
            "\n",
            "Epoch  63\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  6.017587000038475\n",
            "Train -  [0.875, 0.957646484375, 0.8787878787878787]\n",
            "Validation -  [0.51875, 0.56921875, 0.5217391304347826]\n",
            "Test -  [0.5475, 0.5766749999999999, 0.5486284289276808]\n",
            "\n",
            "Epoch  64\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  5.899724242161028\n",
            "Train -  [0.8390625, 0.9644824218749999, 0.8567454798331015]\n",
            "Validation -  [0.525, 0.56046875, 0.5581395348837209]\n",
            "Test -  [0.53, 0.5704625, 0.5688073394495413]\n",
            "\n",
            "Epoch  65\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  5.386449167155661\n",
            "Train -  [0.8078125, 0.962509765625, 0.8362183754993342]\n",
            "Validation -  [0.58125, 0.5971875, 0.6256983240223464]\n",
            "Test -  [0.53, 0.5842875000000001, 0.6099585062240664]\n",
            "\n",
            "Epoch  66\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  5.785603559110314\n",
            "Train -  [0.8671875, 0.96048828125, 0.8780487804878049]\n",
            "Validation -  [0.475, 0.510625, 0.47500000000000003]\n",
            "Test -  [0.555, 0.5738749999999999, 0.5898617511520738]\n",
            "\n",
            "Epoch  67\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  6.065312804887071\n",
            "Train -  [0.83125, 0.9601171875000001, 0.8528610354223433]\n",
            "Validation -  [0.54375, 0.575625, 0.5828571428571427]\n",
            "Test -  [0.535, 0.5780375, 0.6008583690987124]\n",
            "\n",
            "Epoch  68\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  5.456016813928727\n",
            "Train -  [0.8625, 0.956904296875, 0.8735632183908046]\n",
            "Validation -  [0.5125, 0.543125, 0.5357142857142858]\n",
            "Test -  [0.545, 0.57535, 0.5787037037037037]\n",
            "\n",
            "Epoch  69\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  4.260433235089295\n",
            "Train -  [0.8015625, 0.941728515625, 0.8299866131191433]\n",
            "Validation -  [0.4875, 0.528125, 0.5340909090909091]\n",
            "Test -  [0.5475, 0.5926125000000001, 0.6124197002141327]\n",
            "\n",
            "Epoch  70\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  5.19999297731556\n",
            "Train -  [0.8046875, 0.956259765625, 0.833555259653795]\n",
            "Validation -  [0.4875, 0.550859375, 0.5543478260869564]\n",
            "Test -  [0.5425, 0.5776625000000001, 0.6147368421052631]\n",
            "\n",
            "Epoch  71\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  4.609645660035312\n",
            "Train -  [0.8484375, 0.954326171875, 0.8631875881523273]\n",
            "Validation -  [0.5, 0.50859375, 0.5180722891566264]\n",
            "Test -  [0.555, 0.59795, 0.6008968609865469]\n",
            "\n",
            "Epoch  72\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  4.360954891424626\n",
            "Train -  [0.8609375, 0.9480078125, 0.8737588652482269]\n",
            "Validation -  [0.53125, 0.56640625, 0.5341614906832298]\n",
            "Test -  [0.535, 0.5937125, 0.5654205607476636]\n",
            "\n",
            "Epoch  73\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  4.309233486856101\n",
            "Train -  [0.8328125, 0.963203125, 0.8532235939643348]\n",
            "Validation -  [0.53125, 0.55421875, 0.5901639344262296]\n",
            "Test -  [0.51, 0.560875, 0.5829787234042553]\n",
            "\n",
            "Epoch  74\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  4.772412733815145\n",
            "Train -  [0.875, 0.9560839843749999, 0.8773006134969326]\n",
            "Validation -  [0.525, 0.5471874999999999, 0.525]\n",
            "Test -  [0.55, 0.586625, 0.5588235294117646]\n",
            "\n",
            "Epoch  75\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  4.009938213508576\n",
            "Train -  [0.84375, 0.95001953125, 0.8603351955307262]\n",
            "Validation -  [0.56875, 0.57546875, 0.5660377358490567]\n",
            "Test -  [0.505, 0.5463375, 0.5520361990950226]\n",
            "\n",
            "Epoch  76\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  3.544840647256933\n",
            "Train -  [0.7921875, 0.959443359375, 0.8247694334650856]\n",
            "Validation -  [0.55625, 0.571484375, 0.6162162162162163]\n",
            "Test -  [0.57, 0.5788625000000001, 0.638655462184874]\n",
            "\n",
            "Epoch  77\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  4.790677977784071\n",
            "Train -  [0.840625, 0.9407812500000001, 0.8555240793201133]\n",
            "Validation -  [0.5625, 0.5988281249999999, 0.5679012345679012]\n",
            "Test -  [0.5425, 0.5758875, 0.5906040268456376]\n",
            "\n",
            "Epoch  78\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  8.006510792067274\n",
            "Train -  [0.834375, 0.9425, 0.8539944903581268]\n",
            "Validation -  [0.54375, 0.5689062500000001, 0.5966850828729282]\n",
            "Test -  [0.555, 0.5979625000000001, 0.6130434782608695]\n",
            "\n",
            "Epoch  79\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  4.712207354605198\n",
            "Train -  [0.8296875, 0.95486328125, 0.8488210818307906]\n",
            "Validation -  [0.525, 0.56296875, 0.5529411764705883]\n",
            "Test -  [0.555, 0.5880624999999999, 0.6061946902654868]\n",
            "\n",
            "Epoch  80\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  6.077398838853696\n",
            "Train -  [0.8578125, 0.956064453125, 0.8698140200286123]\n",
            "Validation -  [0.5125, 0.538125, 0.5301204819277109]\n",
            "Test -  [0.545, 0.579, 0.5919282511210762]\n",
            "\n",
            "Epoch  81\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  4.902857106528245\n",
            "Train -  [0.840625, 0.9573339843750001, 0.8571428571428571]\n",
            "Validation -  [0.525, 0.55484375, 0.5476190476190476]\n",
            "Test -  [0.5275, 0.5614375, 0.5771812080536913]\n",
            "\n",
            "Epoch  82\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  5.763593883486465\n",
            "Train -  [0.834375, 0.9599999999999999, 0.8551912568306012]\n",
            "Validation -  [0.54375, 0.56359375, 0.5921787709497206]\n",
            "Test -  [0.575, 0.6020625, 0.6255506607929516]\n",
            "\n",
            "Epoch  83\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  5.127650081733009\n",
            "Train -  [0.8046875, 0.9382910156250001, 0.8331108144192257]\n",
            "Validation -  [0.50625, 0.503359375, 0.5683060109289617]\n",
            "Test -  [0.5425, 0.5805125, 0.6030368763557484]\n",
            "\n",
            "Epoch  84\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  5.645830019377172\n",
            "Train -  [0.8546875, 0.953173828125, 0.8702928870292888]\n",
            "Validation -  [0.5875, 0.58984375, 0.6292134831460674]\n",
            "Test -  [0.5475, 0.5978874999999999, 0.5895691609977324]\n",
            "\n",
            "Epoch  85\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  4.67701649130322\n",
            "Train -  [0.840625, 0.9548046875, 0.8579387186629527]\n",
            "Validation -  [0.5125, 0.5446875, 0.5714285714285715]\n",
            "Test -  [0.5575, 0.610425, 0.6143790849673202]\n",
            "\n",
            "Epoch  86\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  3.711408324423246\n",
            "Train -  [0.8734375, 0.9563769531249999, 0.8841201716738197]\n",
            "Validation -  [0.5375, 0.5475, 0.5747126436781609]\n",
            "Test -  [0.575, 0.5953125, 0.6136363636363636]\n",
            "\n",
            "Epoch  87\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  4.937059059768217\n",
            "Train -  [0.8015625, 0.9546874999999999, 0.8331143232588698]\n",
            "Validation -  [0.525, 0.5521093749999999, 0.6]\n",
            "Test -  [0.52, 0.5813999999999999, 0.611336032388664]\n",
            "\n",
            "Epoch  88\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  4.23276897528558\n",
            "Train -  [0.85625, 0.9677343749999999, 0.8722222222222223]\n",
            "Validation -  [0.53125, 0.56265625, 0.5714285714285714]\n",
            "Test -  [0.55, 0.5935750000000001, 0.6069868995633187]\n",
            "\n",
            "Epoch  89\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  4.469884940306656\n",
            "Train -  [0.834375, 0.9574218750000001, 0.8539944903581268]\n",
            "Validation -  [0.5125, 0.574375, 0.5666666666666667]\n",
            "Test -  [0.565, 0.618975, 0.6233766233766234]\n",
            "\n",
            "Epoch  90\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  3.9488262511149514\n",
            "Train -  [0.8375, 0.96423828125, 0.859078590785908]\n",
            "Validation -  [0.525, 0.55484375, 0.5777777777777778]\n",
            "Test -  [0.5475, 0.5884, 0.6056644880174292]\n",
            "\n",
            "Epoch  91\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  4.236327172315214\n",
            "Train -  [0.8328125, 0.9562890625, 0.8520055325034578]\n",
            "Validation -  [0.5625, 0.57609375, 0.6067415730337078]\n",
            "Test -  [0.555, 0.5882125, 0.611353711790393]\n",
            "\n",
            "Epoch  92\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  3.289819020254072\n",
            "Train -  [0.8453125, 0.960107421875, 0.8630705394190872]\n",
            "Validation -  [0.5625, 0.556875, 0.6276595744680851]\n",
            "Test -  [0.5575, 0.5859375, 0.600451467268623]\n",
            "\n",
            "Epoch  93\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  3.719952652230859\n",
            "Train -  [0.85, 0.961806640625, 0.8647887323943662]\n",
            "Validation -  [0.56875, 0.5915625, 0.5714285714285714]\n",
            "Test -  [0.53, 0.5838875, 0.5707762557077626]\n",
            "\n",
            "Epoch  94\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  5.647623874116107\n",
            "Train -  [0.859375, 0.94923828125, 0.8691860465116279]\n",
            "Validation -  [0.5375, 0.589453125, 0.5487804878048781]\n",
            "Test -  [0.5475, 0.5911125, 0.5876993166287016]\n",
            "\n",
            "Epoch  95\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  4.4427721636602655\n",
            "Train -  [0.8015625, 0.9139697265625001, 0.8286099865047233]\n",
            "Validation -  [0.59375, 0.57765625, 0.6368715083798883]\n",
            "Test -  [0.535, 0.5672375, 0.6008583690987124]\n",
            "\n",
            "Epoch  96\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  4.6117207002826035\n",
            "Train -  [0.8328125, 0.957841796875, 0.854024556616644]\n",
            "Validation -  [0.54375, 0.5633593750000001, 0.5921787709497206]\n",
            "Test -  [0.535, 0.585025, 0.6025641025641025]\n",
            "\n",
            "Epoch  97\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  3.5099678770639002\n",
            "Train -  [0.8453125, 0.962421875, 0.8638239339752407]\n",
            "Validation -  [0.525, 0.5526562500000001, 0.5476190476190476]\n",
            "Test -  [0.575, 0.607375, 0.6255506607929516]\n",
            "\n",
            "Epoch  98\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  3.8103417509119026\n",
            "Train -  [0.8328125, 0.950625, 0.8532235939643348]\n",
            "Validation -  [0.55625, 0.6006249999999999, 0.5942857142857143]\n",
            "Test -  [0.53, 0.586625, 0.591304347826087]\n",
            "\n",
            "Epoch  99\n",
            "['acc', 'auc', 'fmeasure']\n",
            "Training Loss  4.244058212527307\n",
            "Train -  [0.815625, 0.966103515625, 0.8426666666666667]\n",
            "Validation -  [0.5625, 0.5590624999999999, 0.6236559139784946]\n",
            "Test -  [0.5425, 0.57955, 0.6242299794661191]\n",
            "Epoch with best accuracy is 34\n",
            "==================================================END OF SUBJECT {idx_e_subj+1}==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list_train_performance[:,0])\n",
        "plt.plot(list_valid_performance[:,0])\n",
        "plt.plot(list_test_performance[:,0])\n",
        "plt.title(\"EEGNET's performance on all epochs\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "2CmKPWccWZXm",
        "outputId": "53f0517e-f919-4fbb-8212-a006205dda82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_test_subjs = np.array(best_test_subjs)\n",
        "best_test_subjs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87rW6KuYkps2",
        "outputId": "40d953d1-4a4d-4c07-d231-84deb0370854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7       , 0.65      , 0.7       ],\n",
              "       [0.55      , 0.61      , 0.47058824],\n",
              "       [0.55      , 0.45      , 0.52631579],\n",
              "       [0.75      , 0.73      , 0.70588235],\n",
              "       [0.65      , 0.51      , 0.46153846],\n",
              "       [0.75      , 0.75      , 0.76190476],\n",
              "       [0.65      , 0.66      , 0.63157895],\n",
              "       [0.7       , 0.6       , 0.72727273],\n",
              "       [0.75      , 0.79      , 0.8       ],\n",
              "       [0.65      , 0.54      , 0.69565217],\n",
              "       [0.55      , 0.48      , 0.68965517],\n",
              "       [0.55      , 0.46      , 0.68965517],\n",
              "       [0.8       , 0.82      , 0.8       ],\n",
              "       [0.55      , 0.51      , 0.66666667],\n",
              "       [0.7       , 0.65      , 0.66666667],\n",
              "       [0.65      , 0.49      , 0.58823529],\n",
              "       [0.65      , 0.56      , 0.58823529],\n",
              "       [0.65      , 0.75      , 0.69565217],\n",
              "       [0.65      , 0.63      , 0.69565217],\n",
              "       [0.55      , 0.34      , 0.18181818],\n",
              "       [0.59      , 0.602925  , 0.58163265]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_test_subjs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDQvDlGBEGqv",
        "outputId": "1837b63a-f103-456b-a178-44216311293c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save data"
      ],
      "metadata": {
        "id": "MRWWTOMImvDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change to Percentage\n",
        "best_test_subjs = best_test_subjs * 100\n",
        "# Create DataFrame\n",
        "df_model_metrics = pd.DataFrame(data=best_test_subjs, \n",
        "                      index= list_subjs_names,\n",
        "                      columns=params)\n",
        "\n",
        "df_model_metrics"
      ],
      "metadata": {
        "id": "5L-en6kWmRAn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "outputId": "cc30a29a-86cc-4d0a-a08d-fcda4798e005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               acc      auc   fmeasure\n",
              "Subject 1     70.0  65.0000  70.000000\n",
              "Subject 2     55.0  61.0000  47.058824\n",
              "Subject 3     55.0  45.0000  52.631579\n",
              "Subject 4     75.0  73.0000  70.588235\n",
              "Subject 5     65.0  51.0000  46.153846\n",
              "Subject 6     75.0  75.0000  76.190476\n",
              "Subject 7     65.0  66.0000  63.157895\n",
              "Subject 8     70.0  60.0000  72.727273\n",
              "Subject 9     75.0  79.0000  80.000000\n",
              "Subject 10    65.0  54.0000  69.565217\n",
              "Subject 11    55.0  48.0000  68.965517\n",
              "Subject 12    55.0  46.0000  68.965517\n",
              "Subject 13    80.0  82.0000  80.000000\n",
              "Subject 14    55.0  51.0000  66.666667\n",
              "Subject 15    70.0  65.0000  66.666667\n",
              "Subject 16    65.0  49.0000  58.823529\n",
              "Subject 17    65.0  56.0000  58.823529\n",
              "Subject 18    65.0  75.0000  69.565217\n",
              "Subject 19    65.0  63.0000  69.565217\n",
              "Subject 20    55.0  34.0000  18.181818\n",
              "All Subjects  59.0  60.2925  58.163265"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-181a5044-8077-4572-a209-52a058109a34\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc</th>\n",
              "      <th>auc</th>\n",
              "      <th>fmeasure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Subject 1</th>\n",
              "      <td>70.0</td>\n",
              "      <td>65.0000</td>\n",
              "      <td>70.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subject 2</th>\n",
              "      <td>55.0</td>\n",
              "      <td>61.0000</td>\n",
              "      <td>47.058824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subject 3</th>\n",
              "      <td>55.0</td>\n",
              "      <td>45.0000</td>\n",
              "      <td>52.631579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subject 4</th>\n",
              "      <td>75.0</td>\n",
              "      <td>73.0000</td>\n",
              "      <td>70.588235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subject 5</th>\n",
              "      <td>65.0</td>\n",
              "      <td>51.0000</td>\n",
              "      <td>46.153846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subject 6</th>\n",
              "      <td>75.0</td>\n",
              "      <td>75.0000</td>\n",
              "      <td>76.190476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subject 7</th>\n",
              "      <td>65.0</td>\n",
              "      <td>66.0000</td>\n",
              "      <td>63.157895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subject 8</th>\n",
              "      <td>70.0</td>\n",
              "      <td>60.0000</td>\n",
              "      <td>72.727273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subject 9</th>\n",
              "      <td>75.0</td>\n",
              "      <td>79.0000</td>\n",
              "      <td>80.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subject 10</th>\n",
              "      <td>65.0</td>\n",
              "      <td>54.0000</td>\n",
              "      <td>69.565217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subject 11</th>\n",
              "      <td>55.0</td>\n",
              "      <td>48.0000</td>\n",
              "      <td>68.965517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subject 12</th>\n",
              "      <td>55.0</td>\n",
              "      <td>46.0000</td>\n",
              "      <td>68.965517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subject 13</th>\n",
              "      <td>80.0</td>\n",
              "      <td>82.0000</td>\n",
              "      <td>80.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subject 14</th>\n",
              "      <td>55.0</td>\n",
              "      <td>51.0000</td>\n",
              "      <td>66.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subject 15</th>\n",
              "      <td>70.0</td>\n",
              "      <td>65.0000</td>\n",
              "      <td>66.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subject 16</th>\n",
              "      <td>65.0</td>\n",
              "      <td>49.0000</td>\n",
              "      <td>58.823529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subject 17</th>\n",
              "      <td>65.0</td>\n",
              "      <td>56.0000</td>\n",
              "      <td>58.823529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subject 18</th>\n",
              "      <td>65.0</td>\n",
              "      <td>75.0000</td>\n",
              "      <td>69.565217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subject 19</th>\n",
              "      <td>65.0</td>\n",
              "      <td>63.0000</td>\n",
              "      <td>69.565217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subject 20</th>\n",
              "      <td>55.0</td>\n",
              "      <td>34.0000</td>\n",
              "      <td>18.181818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All Subjects</th>\n",
              "      <td>59.0</td>\n",
              "      <td>60.2925</td>\n",
              "      <td>58.163265</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-181a5044-8077-4572-a209-52a058109a34')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-181a5044-8077-4572-a209-52a058109a34 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-181a5044-8077-4572-a209-52a058109a34');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_model_metrics.to_csv(path_or_buf=f'result/MI/MI_acc_EEGNET-{EOG_ref}-{ECG_ref}.csv', \n",
        "#                         sep=',', float_format=None)"
      ],
      "metadata": {
        "id": "0_srsju8XIRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xLt5lACdZb-5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}